import datetime as dt
import hashlib
import html as html_module
import io
import json
import logging
import random
import re
import time
import zipfile
from dataclasses import dataclass
from pathlib import Path
from string import Template
from typing import (TYPE_CHECKING, Callable, Dict, List, Optional, Sequence, Set,
                    Tuple)
from urllib.parse import quote_plus

import numpy as np
import pandas as pd
import streamlit as st
from streamlit.components.v1 import html as st_html
from rapidfuzz import fuzz
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sqlalchemy import (JSON, Column, Date, DateTime, Float, Integer, MetaData,
                        String, Table, UniqueConstraint, create_engine, func,
                        select, tuple_)
from sqlalchemy import inspect
from sqlalchemy.engine import Engine
from sqlalchemy.exc import IntegrityError, OperationalError
from sqlalchemy.dialects.sqlite import insert as sqlite_insert
from sqlalchemy.sql import insert as sa_insert, text, update

from law_updates import (DEFAULT_LAW_SOURCES, LawRevisionAnalyzer,
                         LawUpdateResult, LawUpdateSyncService)
from integrations import (GoogleCalendarClient, GoogleCalendarConfig,
                          IntegrationConfigError, IntegrationError,
                          NotionClient, NotionConfig, OAuthCredentials)

DATA_DIR = Path("data")
DB_PATH = DATA_DIR / "takken.db"
UPLOAD_DIR = DATA_DIR / "uploads"
REJECT_DIR = DATA_DIR / "rejects"
OFFLINE_EXPORT_DIR = DATA_DIR / "offline_exports"
MAPPING_KIND_QUESTIONS = "questions"
MAPPING_KIND_ANSWERS = "answers"
SCHEMA_GUIDE_PATH = Path("docs") / "data_schema.md"

MAPPING_KIND_LABELS = {
    MAPPING_KIND_QUESTIONS: "è¨­å•ãƒ‡ãƒ¼ã‚¿",
    MAPPING_KIND_ANSWERS: "æ­£ç­”ãƒ‡ãƒ¼ã‚¿",
}
DEFAULT_CATEGORY_MAP = {
    "å®…å»ºæ¥­æ³•": "å®…å»ºæ¥­æ³•",
    "æ¥­æ³•": "å®…å»ºæ¥­æ³•",
    "æ¨©åˆ©é–¢ä¿‚": "æ¨©åˆ©é–¢ä¿‚",
    "æ°‘æ³•": "æ¨©åˆ©é–¢ä¿‚",
    "æ³•ä»¤ä¸Šã®åˆ¶é™": "æ³•ä»¤ä¸Šã®åˆ¶é™",
    "åˆ¶é™": "æ³•ä»¤ä¸Šã®åˆ¶é™",
    "ç¨ãƒ»ãã®ä»–": "ç¨ãƒ»ãã®ä»–",
    "ç¨ãã®ä»–": "ç¨ãƒ»ãã®ä»–",
}
CATEGORY_CHOICES = ["å®…å»ºæ¥­æ³•", "æ¨©åˆ©é–¢ä¿‚", "æ³•ä»¤ä¸Šã®åˆ¶é™", "ç¨ãƒ»ãã®ä»–"]
CATEGORY_BADGE_STYLE = {
    "å®…å»ºæ¥­æ³•": {"icon": "ğŸ¢", "class": "takken-tag--category-business"},
    "æ¨©åˆ©é–¢ä¿‚": {"icon": "âš–ï¸", "class": "takken-tag--category-rights"},
    "æ³•ä»¤ä¸Šã®åˆ¶é™": {"icon": "ğŸ›£ï¸", "class": "takken-tag--category-regulation"},
    "ç¨ãƒ»ãã®ä»–": {"icon": "ğŸ’°", "class": "takken-tag--category-tax"},
}
CATEGORY_BADGE_DEFAULT = {"icon": "ğŸ“˜", "class": "takken-tag--category-default"}
DIFFICULTY_DEFAULT = 3
LAW_REFERENCE_BASE_URL = "https://elaws.e-gov.go.jp/search?q={query}"

LAW_NAME_SUFFIXES = (
    "æ³•",
    "æ¡ä¾‹",
    "è¦å‰‡",
    "è¦ç¨‹",
    "åŸºæº–",
    "å‘Šç¤º",
    "æŒ‡é‡",
    "è¦ç¶±",
    "åˆ¤ä¾‹",
)
LAW_NAME_KEYWORDS = {
    "å®…å»ºæ¥­æ³•",
    "å®…åœ°å»ºç‰©å–å¼•æ¥­æ³•",
    "æ°‘æ³•",
    "å€Ÿåœ°å€Ÿå®¶æ³•",
    "ä¸å‹•ç”£ç™»è¨˜æ³•",
    "åŒºåˆ†æ‰€æœ‰æ³•",
    "éƒ½å¸‚è¨ˆç”»æ³•",
    "å»ºç¯‰åŸºæº–æ³•",
    "è¾²åœ°æ³•",
    "å›½åœŸåˆ©ç”¨è¨ˆç”»æ³•",
    "ä½å®…ç‘•ç–µæ‹…ä¿å±¥è¡Œæ³•",
    "æ™¯å“è¡¨ç¤ºæ³•",
}
LAW_NAME_PATTERN = re.compile(
    r"(?P<law>[ä¸€-é¾ A-Za-z0-9ãƒ»ï¼ˆï¼‰()]+?(?:æ³•|æ¡ä¾‹|è¦å‰‡|è¦ç¨‹|åŸºæº–|å‘Šç¤º|æŒ‡é‡|è¦ç¶±|åˆ¤ä¾‹))"
)
OUTLINE_CACHE_KEY = "_outline_insights_cache"

FONT_SIZE_SCALE = {
    "ã‚„ã‚„å°ã•ã„": 0.95,
    "æ¨™æº–": 1.0,
    "ã‚„ã‚„å¤§ãã„": 1.1,
    "å¤§ãã„": 1.2,
}


logger = logging.getLogger(__name__)
if not logging.getLogger().handlers:
    logging.basicConfig(level=logging.INFO)

SUBJECT_PRESETS = {
    "ãƒãƒ©ãƒ³ã‚¹ã‚ˆã10å•": {
        "categories": CATEGORY_CHOICES,
        "difficulty": (1, 5),
        "review_only": False,
        "topics": [],
    },
    "æ°‘æ³•ãƒ»æ¨©åˆ©é–¢ä¿‚ã‚’é›†ä¸­æ¼”ç¿’": {
        "categories": ["æ¨©åˆ©é–¢ä¿‚"],
        "difficulty": (2, 5),
        "review_only": False,
        "topics": [],
    },
    "å¼±ç‚¹å¾©ç¿’ã«é›†ä¸­": {
        "categories": CATEGORY_CHOICES,
        "difficulty": (1, 4),
        "review_only": True,
        "topics": [],
    },
}

metadata = MetaData()

questions_table = Table(
    "questions",
    metadata,
    Column("id", String, primary_key=True),
    Column("year", Integer, nullable=False),
    Column("q_no", Integer, nullable=False),
    Column("category", String, nullable=False),
    Column("topic", String),
    Column("question", String, nullable=False),
    Column("choice1", String, nullable=False),
    Column("choice2", String, nullable=False),
    Column("choice3", String, nullable=False),
    Column("choice4", String, nullable=False),
    Column("correct", Integer),
    Column("explanation", String),
    Column("difficulty", Integer, default=DIFFICULTY_DEFAULT),
    Column("tags", String),
    Column("dup_note", String),
    UniqueConstraint("year", "q_no", name="uq_questions_year_qno"),
)

predicted_questions_table = Table(
    "predicted_questions",
    metadata,
    Column("id", String, primary_key=True),
    Column("label", String),
    Column("year", String),
    Column("q_no", String),
    Column("category", String),
    Column("topic", String),
    Column("source", String),
    Column("question", String, nullable=False),
    Column("choice1", String, nullable=False),
    Column("choice2", String, nullable=False),
    Column("choice3", String, nullable=False),
    Column("choice4", String, nullable=False),
    Column("correct", Integer),
    Column("explanation", String),
    Column("difficulty", Integer, default=DIFFICULTY_DEFAULT),
    Column("tags", String),
    Column("auto_summary", String),
    Column("auto_cloze", String),
    Column("review_status", String, default="pending"),
    Column("reviewed_at", DateTime),
    Column("generated_from", String),
    Column("fetched_at", DateTime),
    Column("created_at", DateTime, server_default=func.now()),
)

law_revision_questions_table = Table(
    "law_revision_questions",
    metadata,
    Column("id", String, primary_key=True),
    Column("label", String),
    Column("law_name", String),
    Column("revision_year", Integer),
    Column("effective_date", String),
    Column("category", String),
    Column("topic", String),
    Column("source", String),
    Column("question", String, nullable=False),
    Column("choice1", String, nullable=False),
    Column("choice2", String, nullable=False),
    Column("choice3", String, nullable=False),
    Column("choice4", String, nullable=False),
    Column("correct", Integer),
    Column("explanation", String),
    Column("difficulty", Integer, default=DIFFICULTY_DEFAULT),
    Column("tags", String),
    Column("created_at", DateTime, server_default=func.now()),
)

law_revision_sync_logs_table = Table(
    "law_revision_sync_logs",
    metadata,
    Column("id", Integer, primary_key=True, autoincrement=True),
    Column("source", String, nullable=False),
    Column("fetched_at", DateTime),
    Column("status", String, nullable=False),
    Column("message", String),
    Column("revisions_detected", Integer, default=0),
    Column("questions_generated", Integer, default=0),
    Column("created_at", DateTime, server_default=func.now()),
)

attempts_table = Table(
    "attempts",
    metadata,
    Column("id", Integer, primary_key=True, autoincrement=True),
    Column("question_id", String, nullable=False),
    Column("selected", Integer),
    Column("is_correct", Integer),
    Column("seconds", Integer),
    Column("mode", String),
    Column("exam_id", Integer),
    Column("confidence", Integer),
    Column("grade", Integer),
    Column("created_at", DateTime, server_default=func.now()),
)

outline_notes_table = Table(
    "outline_notes",
    metadata,
    Column("id", Integer, primary_key=True, autoincrement=True),
    Column("question_id", String, nullable=False),
    Column("summary", String, nullable=False),
    Column("law_references", JSON),
    Column("question_label", String),
    Column("tags", String),
    Column("created_at", DateTime, server_default=func.now()),
    Column("updated_at", DateTime, server_default=func.now(), onupdate=func.now()),
    UniqueConstraint("question_id", "summary", name="uq_outline_notes_question_summary"),
)

exams_table = Table(
    "exams",
    metadata,
    Column("id", Integer, primary_key=True, autoincrement=True),
    Column("name", String),
    Column("started_at", DateTime),
    Column("finished_at", DateTime),
    Column("year_mode", String),
    Column("score", Integer),
)

srs_table = Table(
    "questions_srs",
    metadata,
    Column("question_id", String, primary_key=True),
    Column("repetition", Integer, default=0),
    Column("interval", Integer, default=1),
    Column("ease", Float, default=2.5),
    Column("due_date", Date),
    Column("last_grade", Integer),
    Column("updated_at", DateTime, server_default=func.now(), onupdate=func.now()),
)

import_logs_table = Table(
    "import_logs",
    metadata,
    Column("id", Integer, primary_key=True, autoincrement=True),
    Column("started_at", DateTime),
    Column("finished_at", DateTime),
    Column("files", Integer),
    Column("inserted", Integer),
    Column("updated", Integer),
    Column("rejected", Integer),
    Column("conflicts", Integer),
    Column("seconds", Float),
    Column("policy", String),
)

mapping_profiles_table = Table(
    "mapping_profiles",
    metadata,
    Column("id", Integer, primary_key=True, autoincrement=True),
    Column("name", String, nullable=False),
    Column("kind", String, nullable=False),
    Column("mapping_json", JSON, nullable=False),
    Column("created_at", DateTime, server_default=func.now()),
)

if TYPE_CHECKING:
    from streamlit.runtime.uploaded_file_manager import UploadedFile


def ensure_directories() -> None:
    DATA_DIR.mkdir(exist_ok=True)
    UPLOAD_DIR.mkdir(exist_ok=True)
    REJECT_DIR.mkdir(exist_ok=True)
    OFFLINE_EXPORT_DIR.mkdir(exist_ok=True)


def inject_style(css: str, style_id: str) -> None:
    sanitized_css = css.strip()
    if not sanitized_css:
        return
    css_payload = json.dumps(sanitized_css)
    style_id_payload = json.dumps(style_id)
    script = Template(
        """
        <script>
        (function() {
            const css = $css;
            const styleId = $style_id;
            const doc = window.parent ? window.parent.document : document;
            let styleTag = doc.getElementById(styleId);
            if (!styleTag) {
                styleTag = doc.createElement('style');
                styleTag.id = styleId;
                doc.head.appendChild(styleTag);
            }
            styleTag.innerHTML = css;
        })();
        </script>
        """
    ).substitute(css=css_payload, style_id=style_id_payload)
    st_html(script, height=0)


def ensure_schema_migrations(engine: Engine) -> None:
    inspector = inspect(engine)
    with engine.begin() as conn:
        existing_tables = set(inspector.get_table_names())
        for table in metadata.sorted_tables:
            if table.name not in existing_tables:
                table.create(conn)
                existing_tables.add(table.name)

        if attempts_table.name not in existing_tables:
            attempts_table.create(conn)
            existing_tables.add(attempts_table.name)

        if outline_notes_table.name not in existing_tables:
            outline_notes_table.create(conn)
            existing_tables.add(outline_notes_table.name)

        conn_inspector = inspect(conn)
        attempt_columns = {col["name"] for col in conn_inspector.get_columns("attempts")}

        if "confidence" not in attempt_columns:
            conn.execute(text("ALTER TABLE attempts ADD COLUMN confidence INTEGER"))
        if "grade" not in attempt_columns:
            conn.execute(text("ALTER TABLE attempts ADD COLUMN grade INTEGER"))

        if "outline_notes" in existing_tables:
            outline_columns = {
                col["name"] for col in conn_inspector.get_columns("outline_notes")
            }
            outline_schema_updates = {
                "question_label": "TEXT",
                "tags": "TEXT",
            }
            for column_name, sql_type in outline_schema_updates.items():
                if column_name not in outline_columns:
                    conn.execute(
                        text(
                            f"ALTER TABLE outline_notes ADD COLUMN {column_name} {sql_type}"
                        )
                    )

            if "updated_at" not in outline_columns:
                conn.execute(
                    text("ALTER TABLE outline_notes ADD COLUMN updated_at DATETIME")
                )
                conn.execute(
                    text(
                        "UPDATE outline_notes SET updated_at = created_at WHERE updated_at IS NULL"
                    )
                )

        if "law_revision_questions" in existing_tables:
            lr_columns = {
                col["name"] for col in conn_inspector.get_columns("law_revision_questions")
            }
            schema_updates = {
                "auto_summary": "TEXT",
                "auto_cloze": "TEXT",
                "review_status": "TEXT",
                "reviewed_at": "TEXT",
                "generated_from": "TEXT",
                "fetched_at": "TEXT",
            }
            for column_name, sql_type in schema_updates.items():
                if column_name not in lr_columns:
                    conn.execute(
                        text(
                            f"ALTER TABLE law_revision_questions ADD COLUMN {column_name} {sql_type}"
                        )
                    )

        if "law_revision_sync_logs" not in existing_tables:
            law_revision_sync_logs_table.create(conn)


def build_theme_css(theme: str) -> str:
    if theme == "ãƒ€ãƒ¼ã‚¯":
        return """
:root {
    color-scheme: dark;
    --takken-color-bg: #1c1c1e;
    --takken-color-bg-sidebar: rgba(28, 28, 30, 0.92);
    --takken-color-surface: rgba(44, 44, 46, 0.94);
    --takken-color-surface-elevated: rgba(58, 58, 60, 0.94);
    --takken-color-border: rgba(255, 255, 255, 0.08);
    --takken-color-text: #f5f5f7;
    --takken-color-text-secondary: rgba(235, 235, 245, 0.6);
    --takken-color-text-tertiary: rgba(235, 235, 245, 0.38);
    --takken-color-accent: #0a84ff;
    --takken-color-accent-soft: rgba(10, 132, 255, 0.18);
    --takken-color-positive: #30d158;
    --takken-color-negative: #ff453a;
    --takken-focus-ring: 0 0 0 3px rgba(10, 132, 255, 0.45);
    --takken-shadow-strong: 0 24px 60px rgba(0, 0, 0, 0.55);
    --takken-radius-large: 18px;
}
body {
    background-color: var(--takken-color-bg);
    color: var(--takken-color-text);
    font-family: "SF Pro JP", "SF Pro Text", -apple-system, BlinkMacSystemFont, "Segoe UI", "Hiragino Kaku Gothic ProN", "Yu Gothic", sans-serif;
    font-feature-settings: "palt";
}
[data-testid="stAppViewContainer"] {
    background: var(--takken-color-bg);
    color: var(--takken-color-text);
}
[data-testid="stAppViewContainer"] a {
    color: var(--takken-color-accent);
}
[data-testid="stSidebar"] {
    background: var(--takken-color-bg-sidebar);
    color: var(--takken-color-text);
    border-right: 1px solid var(--takken-color-border);
    backdrop-filter: blur(24px);
}
[data-testid="stSidebar"] .stRadio label,
[data-testid="stSidebar"] .stCheckbox label,
[data-testid="stSidebar"] span,
[data-testid="stSidebar"] p {
    color: var(--takken-color-text-secondary);
}
.stTabs [data-baseweb="tab"] {
    background: transparent;
    border-radius: 999px;
    color: var(--takken-color-text-tertiary);
    border: 1px solid transparent;
    transition: color 0.2s ease, background 0.2s ease, border-color 0.2s ease;
}
.stTabs [data-baseweb="tab"][aria-selected="true"] {
    background: var(--takken-color-accent-soft);
    color: var(--takken-color-text);
    border-color: rgba(10, 132, 255, 0.4);
}
.stTabs [data-baseweb="tab"]:hover {
    color: var(--takken-color-text);
    border-color: rgba(10, 132, 255, 0.25);
}
.stMetric,
.stAlert,
.stDataFrame,
.stTable,
.stExpander,
[data-testid="stMarkdownContainer"] {
    background: var(--takken-color-surface);
    border-radius: var(--takken-radius-large);
    border: 1px solid var(--takken-color-border);
    box-shadow: var(--takken-shadow-strong);
}
.stExpander > div:first-child {
    background: transparent;
    color: var(--takken-color-text);
}
.element-container > .stMetric,
.element-container > .stAlert {
    padding: 1.1rem 1.2rem;
}
.home-dropzone-card {
    background: rgba(10, 132, 255, 0.12);
    border: 1px solid rgba(10, 132, 255, 0.48);
    box-shadow: 0 22px 60px rgba(10, 132, 255, 0.25);
}
.home-data-card {
    background: var(--takken-color-surface);
    border: 1px solid var(--takken-color-border);
    box-shadow: var(--takken-shadow-strong);
}
.takken-choice-button button,
.stButton > button {
    background: linear-gradient(135deg, #0a84ff 0%, #64d2ff 100%);
    color: #ffffff;
    border: none;
    border-radius: 14px;
    font-weight: 600;
    box-shadow: 0 16px 40px rgba(10, 132, 255, 0.28);
    transition: transform 0.2s ease, box-shadow 0.2s ease, background 0.3s ease;
}
.takken-choice-button button:hover,
.stButton > button:hover {
    transform: translateY(-1px);
    box-shadow: 0 20px 48px rgba(10, 132, 255, 0.38);
}
.takken-choice-button button:focus,
.stButton > button:focus {
    outline: none;
    box-shadow: var(--takken-focus-ring);
}
.takken-choice-button.is-correct button {
    background: linear-gradient(135deg, #30d158 0%, #63e6b3 100%);
    box-shadow: 0 18px 46px rgba(48, 209, 88, 0.32);
}
.takken-choice-button.is-incorrect button,
.stButton > button.is-error {
    background: linear-gradient(135deg, #ff453a 0%, #ff9f0a 100%);
    box-shadow: 0 18px 46px rgba(255, 69, 58, 0.3);
}
input[type="text"],
input[type="number"],
input[type="password"],
input[type="email"],
textarea,
select {
    background: var(--takken-color-surface-elevated);
    border: 1px solid var(--takken-color-border);
    color: var(--takken-color-text);
    border-radius: 14px;
    padding: 0.55rem 0.9rem;
    transition: border-color 0.2s ease, box-shadow 0.2s ease;
}
input[type="text"]::placeholder,
input[type="number"]::placeholder,
input[type="password"]::placeholder,
input[type="email"]::placeholder,
textarea::placeholder {
    color: var(--takken-color-text-tertiary);
}
input[type="text"]:focus,
input[type="number"]:focus,
input[type="password"]:focus,
input[type="email"]:focus,
textarea:focus,
select:focus {
    outline: none;
    border-color: var(--takken-color-accent);
    box-shadow: var(--takken-focus-ring);
}
label, legend {
    color: var(--takken-color-text-secondary);
}
code, pre {
    background: rgba(44, 44, 46, 0.9);
    color: var(--takken-color-text);
    border-radius: 12px;
    border: 1px solid var(--takken-color-border);
}
[data-testid="stDataFrame"] table,
[data-testid="stTable"] table {
    background: transparent;
    color: var(--takken-color-text);
}
[data-testid="stDataFrame"] table thead th,
[data-testid="stTable"] table thead th {
    background: rgba(255, 255, 255, 0.04);
    color: var(--takken-color-text-secondary);
    font-weight: 600;
}
[data-testid="stDataFrame"] table tbody td,
[data-testid="stTable"] table tbody td {
    border-color: var(--takken-color-border);
}
.stProgress > div > div {
    background: var(--takken-color-accent);
}
.stProgress > div {
    background: rgba(10, 132, 255, 0.12);
}
.stSlider > div > div > div[data-baseweb="slider"] > div:first-child {
    background: rgba(255, 255, 255, 0.08);
}
.stSlider > div > div > div[data-baseweb="slider"] > div:nth-child(2) {
    background: var(--takken-color-accent);
}
.stSlider > div > div > div[data-baseweb="slider"] > div:nth-child(4) {
    color: var(--takken-color-text-secondary);
}
.stMarkdown h1,
.stMarkdown h2,
.stMarkdown h3,
.stMarkdown h4,
.stMarkdown h5 {
    color: var(--takken-color-text);
    letter-spacing: 0.02em;
}
.stMarkdown p,
.stMarkdown li {
    color: var(--takken-color-text-secondary);
}
hr {
    border-color: rgba(255, 255, 255, 0.08);
}
"""
    if theme == "ã‚»ãƒ”ã‚¢":
        return """
[data-testid="stAppViewContainer"] {
    background-color: #f3e9d2;
    color: #4a3f35;
}
[data-testid="stSidebar"] {
    background-color: #f9f1e0;
}
.stMetric, .stAlert {
    background-color: rgba(74, 63, 53, 0.06);
}
"""
    return """
[data-testid="stAppViewContainer"] {
    background-color: #f8fafc;
    color: #1f2933;
}
[data-testid="stSidebar"] {
    background-color: #ffffff;
}
"""


def apply_user_preferences() -> None:
    settings = st.session_state.get("settings", {})
    theme = settings.get("theme", "ã‚»ãƒ”ã‚¢")
    font_label = settings.get("font_size", "æ¨™æº–")
    scale = FONT_SIZE_SCALE.get(font_label, 1.0)
    base_css = f"""
:root {{
    --takken-font-scale: {scale};
}}
[data-testid="stAppViewContainer"] * {{
    font-size: calc(1rem * var(--takken-font-scale));
}}
body {{
    font-family: "SF Pro JP", "SF Pro Text", -apple-system, BlinkMacSystemFont, "Segoe UI", "Hiragino Kaku Gothic ProN", "Yu Gothic", sans-serif;
}}
.takken-search-suggestions .stButton>button {{
    width: 100%;
    margin-bottom: 0.35rem;
}}
.takken-search-suggestions .stButton>button:hover {{
    border-color: #6366f1;
}}
"""
    theme_css = build_theme_css(theme)
    inject_style(base_css + theme_css, "takken-theme-styles")


def safe_rerun() -> None:
    rerun = getattr(st, "rerun", None)
    experimental_rerun = getattr(st, "experimental_rerun", None)
    if callable(rerun):
        rerun()
    elif callable(experimental_rerun):
        experimental_rerun()



def with_rerun(callback: Callable[..., None], *args, **kwargs) -> Callable[[], None]:
    def _inner() -> None:
        callback(*args, **kwargs)

    return _inner


def handle_nav_change() -> None:
    st.session_state["nav"] = st.session_state.get("_nav_widget", "ãƒ›ãƒ¼ãƒ ")


def navigate_to(section: str) -> None:
    st.session_state["nav"] = section
    st.session_state["_nav_widget"] = section
    safe_rerun()


def render_specialized_header(parent_label: str, current_label: str, key_suffix: str) -> None:
    breadcrumb = f"{parent_label} ï¼ {current_label}"
    cols = st.columns([5, 1])
    with cols[0]:
        st.markdown(f"**{breadcrumb}**")
    with cols[1]:
        st.button(
            "æˆ»ã‚‹",
            key=f"back_{key_suffix}",
            use_container_width=True,
            help=f"{parent_label}ã«æˆ»ã‚Šã¾ã™ã€‚",
            on_click=with_rerun(navigate_to, parent_label),
        )


QUESTION_TEMPLATE_COLUMNS = [
    "year",
    "q_no",
    "category",
    "topic",
    "question",
    "choice1",
    "choice2",
    "choice3",
    "choice4",
    "explanation",
    "difficulty",
    "tags",
]

ANSWER_TEMPLATE_COLUMNS = [
    "year",
    "q_no",
    "correct_number",
    "correct_label",
    "correct_text",
    "explanation",
    "difficulty",
    "tags",
]

PREDICTED_TEMPLATE_COLUMNS = [
    "label",
    "category",
    "topic",
    "source",
    "question",
    "choice1",
    "choice2",
    "choice3",
    "choice4",
    "correct",
    "explanation",
    "year",
    "q_no",
    "difficulty",
    "tags",
]

LAW_REVISION_TEMPLATE_COLUMNS = [
    "label",
    "law_name",
    "revision_year",
    "effective_date",
    "category",
    "topic",
    "source",
    "question",
    "choice1",
    "choice2",
    "choice3",
    "choice4",
    "correct",
    "explanation",
    "difficulty",
    "tags",
    "auto_summary",
    "auto_cloze",
    "review_status",
    "reviewed_at",
    "generated_from",
    "fetched_at",
]


@st.cache_data(show_spinner=False)
def get_template_archive() -> bytes:
    question_template = pd.DataFrame(
        [
            {
                "year": dt.datetime.now().year,
                "q_no": 1,
                "category": CATEGORY_CHOICES[0],
                "topic": "å°åˆ†é¡ã®ä¾‹",
                "question": "ã“ã“ã«å•é¡Œæ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
                "choice1": "é¸æŠè‚¢1",
                "choice2": "é¸æŠè‚¢2",
                "choice3": "é¸æŠè‚¢3",
                "choice4": "é¸æŠè‚¢4",
                "explanation": "è§£èª¬ã‚’å…¥åŠ›ã§ãã¾ã™ã€‚",
                "difficulty": DIFFICULTY_DEFAULT,
                "tags": "ã‚¿ã‚°1;ã‚¿ã‚°2",
            }
        ],
        columns=QUESTION_TEMPLATE_COLUMNS,
    )
    answer_template = pd.DataFrame(
        [
            {
                "year": dt.datetime.now().year,
                "q_no": 1,
                "correct_number": 1,
                "correct_label": "A",
                "correct_text": "é¸æŠè‚¢1",
                "explanation": "æ­£ç­”ã®è§£èª¬ã‚’å…¥åŠ›ã§ãã¾ã™ã€‚",
                "difficulty": DIFFICULTY_DEFAULT,
                "tags": "ã‚¿ã‚°1;ã‚¿ã‚°2",
            }
        ],
        columns=ANSWER_TEMPLATE_COLUMNS,
    )
    predicted_template = pd.DataFrame(
        [
            {
                "label": "äºˆæƒ³å•é¡Œ001",
                "category": CATEGORY_CHOICES[0],
                "topic": "ç›´å‰å¯¾ç­–",
                "source": "è¬›å¸«äºˆæƒ³",
                "question": "ã“ã“ã«äºˆæƒ³å•é¡Œã®æœ¬æ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
                "choice1": "é¸æŠè‚¢1",
                "choice2": "é¸æŠè‚¢2",
                "choice3": "é¸æŠè‚¢3",
                "choice4": "é¸æŠè‚¢4",
                "correct": 1,
                "explanation": "æ ¹æ‹ ã¨ãªã‚‹æ¡æ–‡ã‚„ç†ç”±ã‚’è¨˜è¼‰ã§ãã¾ã™ã€‚",
                "year": dt.datetime.now().year + 1,
                "q_no": "äºˆæƒ³1",
                "difficulty": DIFFICULTY_DEFAULT,
                "tags": "äºˆæƒ³;é‡è¦è«–ç‚¹",
            }
        ],
        columns=PREDICTED_TEMPLATE_COLUMNS,
    )
    law_revision_template = pd.DataFrame(
        [
            {
                "label": "2024å¹´æ”¹æ­£ãƒã‚¤ãƒ³ãƒˆ01",
                "law_name": "å®…å»ºæ¥­æ³•",
                "revision_year": dt.datetime.now().year,
                "effective_date": f"{dt.datetime.now().year}-04-01",
                "category": CATEGORY_CHOICES[0],
                "topic": "é‡è¦äº‹é …èª¬æ˜",
                "source": "å›½äº¤çœå‘Šç¤º",
                "question": "æœ€è¿‘ã®æ³•æ”¹æ­£å†…å®¹ã«é–¢ã™ã‚‹ç¢ºèªå•é¡Œã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
                "choice1": "æ”¹æ­£ã«ã‚ˆã‚Šé‡è¦äº‹é …èª¬æ˜æ›¸ã¸ã®è¨˜è¼‰ãŒç¾©å‹™åŒ–ã•ã‚ŒãŸã€‚",
                "choice2": "æ”¹æ­£å‰å¾Œã§æ‰‹ç¶šã¯å¤‰ã‚ã‚‰ãªã„ã€‚",
                "choice3": "æ”¹æ­£ã§å…é™¤è¦å®šãŒæ–°è¨­ã•ã‚ŒãŸã€‚",
                "choice4": "æ³•æ”¹æ­£ã¨ã¯ç„¡é–¢ä¿‚ã®è¨˜è¼‰ã§ã‚ã‚‹ã€‚",
                "correct": 1,
                "explanation": "æ”¹æ­£ãƒã‚¤ãƒ³ãƒˆã®æ¦‚è¦ã‚„æ ¹æ‹ æ¡æ–‡ã‚’è¨˜è¼‰ã—ã¾ã™ã€‚",
                "difficulty": DIFFICULTY_DEFAULT,
                "tags": "æ³•æ”¹æ­£;ç›´å‰å¯¾ç­–",
            }
        ],
        columns=LAW_REVISION_TEMPLATE_COLUMNS,
    )
    buffer = io.BytesIO()
    with zipfile.ZipFile(buffer, "w", zipfile.ZIP_DEFLATED) as zf:
        zf.writestr("questions_template.csv", question_template.to_csv(index=False))
        zf.writestr("answers_template.csv", answer_template.to_csv(index=False))
        zf.writestr("predicted_template.csv", predicted_template.to_csv(index=False))
        zf.writestr("law_revision_template.csv", law_revision_template.to_csv(index=False))
        q_excel = io.BytesIO()
        with pd.ExcelWriter(q_excel, engine="openpyxl") as writer:
            question_template.to_excel(writer, index=False, sheet_name="questions")
        zf.writestr("questions_template.xlsx", q_excel.getvalue())
        a_excel = io.BytesIO()
        with pd.ExcelWriter(a_excel, engine="openpyxl") as writer:
            answer_template.to_excel(writer, index=False, sheet_name="answers")
        zf.writestr("answers_template.xlsx", a_excel.getvalue())
        p_excel = io.BytesIO()
        with pd.ExcelWriter(p_excel, engine="openpyxl") as writer:
            predicted_template.to_excel(writer, index=False, sheet_name="predicted")
        zf.writestr("predicted_template.xlsx", p_excel.getvalue())
        lr_excel = io.BytesIO()
        with pd.ExcelWriter(lr_excel, engine="openpyxl") as writer:
            law_revision_template.to_excel(writer, index=False, sheet_name="law_revision")
        zf.writestr("law_revision_template.xlsx", lr_excel.getvalue())
        if SCHEMA_GUIDE_PATH.exists():
            zf.writestr(
                "data_schema.md",
                SCHEMA_GUIDE_PATH.read_text(encoding="utf-8"),
            )
        description = (
            "questions_template ã¯è¨­å•ãƒ‡ãƒ¼ã‚¿ã€answers_template ã¯æ­£ç­”ãƒ‡ãƒ¼ã‚¿ã€predicted_template ã¯äºˆæƒ³å•é¡Œãƒ‡ãƒ¼ã‚¿ã€"
            "law_revision_template ã¯æ³•æ”¹æ­£äºˆæƒ³å•é¡Œãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒ«ã§ã™ã€‚\n"
            "ä¸è¦ãªè¡Œã¯å‰Šé™¤ã—ã€ã”è‡ªèº«ã®ãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ã—ã¦ã‹ã‚‰ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\n"
            "å„åˆ—ã®è©³ç´°ä»•æ§˜ã¯ data_schema.md ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚"
        )
        zf.writestr("README.txt", description)
    buffer.seek(0)
    return buffer.getvalue()


@st.cache_resource
def get_engine() -> Engine:
    ensure_directories()
    engine = create_engine(f"sqlite:///{DB_PATH}", future=True)
    metadata.create_all(engine)
    ensure_schema_migrations(engine)
    return engine


class DBManager:
    def __init__(self, engine: Engine) -> None:
        self.engine = engine

    def load_dataframe(self, table: Table) -> pd.DataFrame:
        try:
            with self.engine.connect() as conn:
                df = pd.read_sql(select(table), conn)
        except OperationalError:
            column_names = [column.name for column in table.columns]
            return pd.DataFrame(columns=column_names)
        return df

    def load_predicted_questions(self) -> pd.DataFrame:
        return self.load_dataframe(predicted_questions_table)

    def load_law_revision_questions(self) -> pd.DataFrame:
        return self.load_dataframe(law_revision_questions_table)

    def load_law_revision_sync_logs(self, limit: int = 20) -> pd.DataFrame:
        with self.engine.connect() as conn:
            stmt = select(law_revision_sync_logs_table).order_by(
                law_revision_sync_logs_table.c.created_at.desc()
            )
            if limit:
                stmt = stmt.limit(limit)
            df = pd.read_sql(stmt, conn)
        return df

    def upsert_questions(self, df: pd.DataFrame) -> Tuple[int, int]:
        return self.bulk_upsert_questions(df)

    def bulk_upsert_questions(
        self,
        df: pd.DataFrame,
        batch_size: int = 200,
        on_progress: Optional[Callable[[int, int], None]] = None,
    ) -> Tuple[int, int]:
        records = df.to_dict(orient="records")
        total = len(records)
        if total == 0:
            if on_progress is not None:
                try:
                    on_progress(0, 0)
                except Exception:
                    logger.exception("Progress callback failed during empty bulk upsert")
            return 0, 0

        ids = [rec["id"] for rec in records if "id" in rec]
        year_qno_pairs = {
            (rec["year"], rec["q_no"]) for rec in records if "year" in rec and "q_no" in rec
        }

        inserted = 0
        updated = 0
        processed = 0

        with self.engine.begin() as conn:
            if ids:
                existing_ids: Set[str] = set(
                    conn.execute(
                        select(questions_table.c.id).where(questions_table.c.id.in_(ids))
                    ).scalars()
                )
            else:
                existing_ids = set()

            if year_qno_pairs:
                existing_pairs = {
                    (row.year, row.q_no): row.id
                    for row in conn.execute(
                        select(
                            questions_table.c.year,
                            questions_table.c.q_no,
                            questions_table.c.id,
                        ).where(
                            tuple_(questions_table.c.year, questions_table.c.q_no).in_(
                                list(year_qno_pairs)
                            )
                        )
                    )
                }
            else:
                existing_pairs = {}

            for start in range(0, total, max(batch_size, 1)):
                batch = records[start : start + max(batch_size, 1)]
                for rec in batch:
                    rec_id = rec.get("id")
                    year_qno = (rec.get("year"), rec.get("q_no"))
                    update_values = {k: v for k, v in rec.items() if k != "id"}

                    if rec_id in existing_ids:
                        conn.execute(
                            update(questions_table)
                            .where(questions_table.c.id == rec_id)
                            .values(**update_values)
                        )
                        updated += 1
                    elif year_qno in existing_pairs:
                        existing_id = existing_pairs[year_qno]
                        conn.execute(
                            update(questions_table)
                            .where(questions_table.c.id == existing_id)
                            .values(**update_values)
                        )
                        updated += 1
                    else:
                        conn.execute(sa_insert(questions_table).values(**rec))
                        inserted += 1
                        if rec_id:
                            existing_ids.add(rec_id)
                        if None not in year_qno:
                            existing_pairs[year_qno] = rec_id

                processed += len(batch)
                if on_progress is not None:
                    try:
                        on_progress(processed, total)
                    except Exception:
                        logger.exception("Progress callback failed during bulk upsert")

        return inserted, updated

    def upsert_predicted_questions(self, df: pd.DataFrame) -> Tuple[int, int]:
        records = df.to_dict(orient="records")
        ids = [rec["id"] for rec in records if "id" in rec]
        inserted = 0
        updated = 0
        with self.engine.begin() as conn:
            existing_ids: Set[str] = set()
            if ids:
                existing_ids = set(
                    conn.execute(
                        select(predicted_questions_table.c.id).where(
                            predicted_questions_table.c.id.in_(ids)
                        )
                    ).scalars()
                )
            for rec in records:
                rec_id = rec.get("id")
                if rec_id in existing_ids:
                    conn.execute(
                        update(predicted_questions_table)
                        .where(predicted_questions_table.c.id == rec_id)
                        .values(**{k: v for k, v in rec.items() if k != "id"})
                    )
                    updated += 1
                else:
                    conn.execute(sa_insert(predicted_questions_table).values(**rec))
                    inserted += 1
                    if rec_id:
                        existing_ids.add(rec_id)
        return inserted, updated

    def upsert_law_revision_questions(self, df: pd.DataFrame) -> Tuple[int, int]:
        records = df.to_dict(orient="records")
        ids = [rec["id"] for rec in records if "id" in rec]
        inserted = 0
        updated = 0
        with self.engine.begin() as conn:
            existing_ids: Set[str] = set()
            if ids:
                existing_ids = set(
                    conn.execute(
                        select(law_revision_questions_table.c.id).where(
                            law_revision_questions_table.c.id.in_(ids)
                        )
                    ).scalars()
                )
            for rec in records:
                rec_id = rec.get("id")
                payload = {k: v for k, v in rec.items() if k != "id"}
                if rec_id in existing_ids:
                    conn.execute(
                        update(law_revision_questions_table)
                        .where(law_revision_questions_table.c.id == rec_id)
                        .values(**payload)
                    )
                    updated += 1
                else:
                    conn.execute(sa_insert(law_revision_questions_table).values(**rec))
                    inserted += 1
                    if rec_id:
                        existing_ids.add(rec_id)
        return inserted, updated

    def update_law_revision_review_status(
        self,
        question_ids: Sequence[str],
        status: str,
        reviewer: Optional[str] = None,
    ) -> None:
        if not question_ids:
            return
        now = dt.datetime.utcnow()
        with self.engine.begin() as conn:
            conn.execute(
                update(law_revision_questions_table)
                .where(law_revision_questions_table.c.id.in_(list(question_ids)))
                .values(
                    review_status=status,
                    reviewed_at=now,
                    tags=func.trim(
                        func.replace(
                            func.coalesce(law_revision_questions_table.c.tags, ""),
                            "è¦ãƒ¬ãƒ“ãƒ¥ãƒ¼",
                            "",
                        )
                    ),
                )
            )

    def record_law_revision_sync(self, result: LawUpdateResult) -> None:
        with self.engine.begin() as conn:
            conn.execute(
                sa_insert(law_revision_sync_logs_table).values(
                    source=result.source,
                    fetched_at=result.fetched_at,
                    status=result.status,
                    message=result.message,
                    revisions_detected=result.revisions_detected,
                    questions_generated=result.questions_generated,
                )
            )

    def fetch_question(self, question_id: str) -> Optional[pd.Series]:
        with self.engine.connect() as conn:
            df = pd.read_sql(select(questions_table).where(questions_table.c.id == question_id), conn)
        if df.empty:
            return None
        return df.iloc[0]

    def record_attempt(
        self,
        question_id: str,
        selected: Optional[int],
        is_correct: bool,
        seconds: int,
        mode: str,
        exam_id: Optional[int] = None,
        confidence: Optional[int] = None,
        grade: Optional[int] = None,
    ) -> None:
        with self.engine.begin() as conn:
            conn.execute(
                sa_insert(attempts_table).values(
                    question_id=question_id,
                    selected=selected,
                    is_correct=int(is_correct),
                    seconds=seconds,
                    mode=mode,
                    exam_id=exam_id,
                    confidence=confidence,
                    grade=grade,
                )
            )

    def bulk_insert_attempts(self, attempts: Sequence[Dict[str, object]]) -> int:
        if not attempts:
            return 0
        payloads = []
        for item in attempts:
            payload = {
                "question_id": item.get("question_id"),
                "selected": item.get("selected"),
                "is_correct": item.get("is_correct"),
                "seconds": item.get("seconds"),
                "mode": item.get("mode"),
                "exam_id": item.get("exam_id"),
                "confidence": item.get("confidence"),
                "grade": item.get("grade"),
            }
            created_at = item.get("created_at")
            if created_at is not None:
                payload["created_at"] = created_at
            payloads.append(payload)
        with self.engine.begin() as conn:
            conn.execute(sa_insert(attempts_table), payloads)
        return len(payloads)

    def fetch_srs(self, question_id: str) -> Optional[pd.Series]:
        with self.engine.connect() as conn:
            df = pd.read_sql(
                select(srs_table).where(srs_table.c.question_id == question_id),
                conn,
            )
        if df.empty:
            return None
        return df.iloc[0]

    def log_exam_result(self, payload: Dict[str, object]) -> Optional[int]:
        with self.engine.begin() as conn:
            result = conn.execute(sa_insert(exams_table).values(**payload))
            inserted = result.inserted_primary_key
        if inserted:
            return inserted[0]
        return None

    def update_question_fields(
        self,
        question_id: str,
        fields: Dict[str, Optional[str]],
    ) -> None:
        with self.engine.begin() as conn:
            conn.execute(
                update(questions_table)
                .where(questions_table.c.id == question_id)
                .values(**fields)
            )

    def get_attempt_stats(self) -> pd.DataFrame:
        with self.engine.connect() as conn:
            df = pd.read_sql(
                text(
                    """
                    SELECT
                        a.question_id,
                        q.category,
                        q.topic,
                        q.year,
                        a.is_correct,
                        a.created_at,
                        a.seconds,
                        a.selected,
                        a.mode,
                        a.confidence,
                        a.grade
                    FROM attempts a
                    JOIN questions q ON q.id = a.question_id
                    """
                ),
                conn,
            )
        return df

    def get_due_srs(self, upcoming_days: int = 1) -> pd.DataFrame:
        today = dt.date.today()
        upcoming_days = max(int(upcoming_days or 0), 0)
        upcoming_limit = today + dt.timedelta(days=upcoming_days)
        with self.engine.connect() as conn:
            df = pd.read_sql(
                select(
                    srs_table,
                    questions_table.c.question,
                    questions_table.c.category,
                )
                .where(srs_table.c.question_id == questions_table.c.id)
                .where(
                    (srs_table.c.due_date <= upcoming_limit)
                    | (srs_table.c.due_date.is_(None))
                ),
                conn,
            )
        if df.empty:
            return df

        df["due_date"] = pd.to_datetime(df["due_date"])

        due_in_days: List[Optional[int]] = []
        due_status: List[str] = []
        for value in df["due_date"]:
            if pd.isna(value):
                due_in_days.append(None)
                due_status.append("unscheduled")
                continue
            if isinstance(value, pd.Timestamp):
                date_value = value.date()
            else:
                date_value = value
            delta = (date_value - today).days
            due_in_days.append(delta)
            if delta < 0:
                due_status.append("overdue")
            elif delta == 0:
                due_status.append("due_today")
            elif delta == 1:
                due_status.append("due_tomorrow")
            elif delta <= upcoming_days:
                due_status.append("upcoming")
            else:
                due_status.append("scheduled")

        df["due_in_days"] = due_in_days
        df["due_status"] = due_status
        df["due_date"] = df["due_date"].dt.date
        return df

    def fetch_outline_notes(self, question_id: Optional[str] = None) -> pd.DataFrame:
        stmt = select(outline_notes_table)
        if question_id:
            stmt = stmt.where(outline_notes_table.c.question_id == question_id)
        stmt = stmt.order_by(outline_notes_table.c.updated_at.desc())

        try:
            with self.engine.connect() as conn:
                df = pd.read_sql(stmt, conn)
        except OperationalError:
            column_names = [column.name for column in outline_notes_table.columns]
            return pd.DataFrame(columns=column_names)
        return df

    def save_outline_note(
        self,
        question_id: str,
        summary: str,
        references: Sequence[Dict[str, str]],
        question_label: Optional[str] = None,
        tags: Optional[str] = None,
    ) -> None:
        references_payload = [
            {"label": ref.get("label"), "url": ref.get("url")}
            for ref in references
            if isinstance(ref, dict)
        ]
        with self.engine.begin() as conn:
            stmt = sqlite_insert(outline_notes_table).values(
                question_id=question_id,
                summary=summary,
                law_references=references_payload,
                question_label=question_label,
                tags=tags,
            )
            do_update = stmt.on_conflict_do_update(
                index_elements=[
                    outline_notes_table.c.question_id,
                    outline_notes_table.c.summary,
                ],
                set_={
                    "law_references": stmt.excluded.law_references,
                    "question_label": stmt.excluded.question_label,
                    "tags": stmt.excluded.tags,
                    "updated_at": func.now(),
                },
            )
            conn.execute(do_update)

    def upsert_srs(self, question_id: str, payload: Dict[str, Optional[str]]) -> None:
        with self.engine.begin() as conn:
            stmt = sqlite_insert(srs_table).values(question_id=question_id, **payload)
            do_update = stmt.on_conflict_do_update(
                index_elements=[srs_table.c.question_id],
                set_={key: getattr(stmt.excluded, key) for key in payload},
            )
            conn.execute(do_update)

    def log_import(self, payload: Dict[str, Optional[str]]) -> None:
        with self.engine.begin() as conn:
            conn.execute(sa_insert(import_logs_table).values(**payload))

    def save_mapping_profile(self, name: str, kind: str, mapping: Dict[str, str]) -> None:
        with self.engine.begin() as conn:
            conn.execute(
                sa_insert(mapping_profiles_table).values(
                    name=name,
                    kind=kind,
                    mapping_json=mapping,
                )
            )

    def fetch_mapping_profiles(self, kind: Optional[str] = None) -> pd.DataFrame:
        with self.engine.connect() as conn:
            stmt = select(mapping_profiles_table)
            if kind:
                stmt = stmt.where(mapping_profiles_table.c.kind == kind)
            df = pd.read_sql(stmt, conn)
        return df

    def initialize_from_csv(self) -> None:
        with self.engine.connect() as conn:
            existing = conn.execute(select(func.count()).select_from(questions_table)).scalar()
        if existing and existing > 0:
            return
        questions_path = DATA_DIR / "questions_sample.csv"
        answers_path = DATA_DIR / "answers_sample.csv"
        if not questions_path.exists() or not answers_path.exists():
            return
        df_q = pd.read_csv(questions_path)
        df_a = pd.read_csv(answers_path)
        df_q = normalize_questions(df_q)
        df_a = normalize_answers(df_a)
        merged, *_ = merge_questions_answers(df_q, df_a, policy={"explanation": "overwrite", "tags": "merge"})
        self.upsert_questions(merged)
        rebuild_tfidf_cache()


@st.cache_data(show_spinner=False)
def load_questions_df() -> pd.DataFrame:
    engine = get_engine()
    db = DBManager(engine)
    df = db.load_dataframe(questions_table)
    return df


@st.cache_resource
def get_vectorizer() -> TfidfVectorizer:
    return TfidfVectorizer(stop_words=None, max_features=5000)


@st.cache_resource
def get_law_revision_analyzer() -> LawRevisionAnalyzer:
    return LawRevisionAnalyzer()


def get_law_update_service(db: DBManager) -> LawUpdateSyncService:
    analyzer = get_law_revision_analyzer()
    return LawUpdateSyncService(
        sources=DEFAULT_LAW_SOURCES,
        analyzer=analyzer,
        id_builder=generate_law_revision_question_id,
    )


def rebuild_tfidf_cache() -> None:
    load_questions_df.clear()
    get_vectorizer.clear()
    load_questions_df()


def get_question_texts(df: pd.DataFrame) -> pd.Series:
    return df["question"].fillna("") + "\n" + df["explanation"].fillna("")


def compute_similarity(target_id: str, top_n: int = 3) -> pd.DataFrame:
    df = load_questions_df()
    if df.empty or target_id not in df["id"].values:
        return pd.DataFrame()
    texts = get_question_texts(df)
    vectorizer = get_vectorizer()
    matrix = vectorizer.fit_transform(texts)
    index = df.index[df["id"] == target_id][0]
    target_vec = matrix[index]
    sims = cosine_similarity(target_vec, matrix).flatten()
    df = df.assign(similarity=sims)
    df = df[df["id"] != target_id].nlargest(top_n, "similarity")
    return df[["id", "year", "q_no", "category", "question", "similarity"]]


def normalize_questions(df: pd.DataFrame, mapping: Optional[Dict[str, str]] = None) -> pd.DataFrame:
    df = df.copy()
    if mapping:
        df = df.rename(columns=mapping)
    required_cols = [
        "year",
        "q_no",
        "question",
        "choice1",
        "choice2",
        "choice3",
        "choice4",
    ]
    for col in required_cols:
        if col not in df.columns:
            raise ValueError(f"å¿…è¦ãªåˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {col}")
    df["year"] = df["year"].astype(int)
    df["q_no"] = df["q_no"].astype(int)
    df["category"] = df.get("category", "").fillna("").apply(normalize_category)
    df["category"] = df["category"].replace("", CATEGORY_CHOICES[0])
    df["topic"] = df.get("topic", "").fillna("")
    df["explanation"] = df.get("explanation", "").fillna("")
    df["difficulty"] = (
        df.get("difficulty")
        .fillna(DIFFICULTY_DEFAULT)
        .replace("", DIFFICULTY_DEFAULT)
        .astype(int)
    )
    df["tags"] = df.get("tags", "").fillna("")
    if "id" not in df.columns or df["id"].isna().any():
        df["id"] = df.apply(generate_question_id, axis=1)
    df = df.drop_duplicates(subset=["id"])
    df = df[
        [
            "id",
            "year",
            "q_no",
            "category",
            "topic",
            "question",
            "choice1",
            "choice2",
            "choice3",
            "choice4",
            "explanation",
            "difficulty",
            "tags",
        ]
    ]
    return df


def normalize_answers(df: pd.DataFrame, mapping: Optional[Dict[str, str]] = None) -> pd.DataFrame:
    df = df.copy()
    if mapping:
        df = df.rename(columns=mapping)
    if "year" not in df.columns or "q_no" not in df.columns:
        raise ValueError("year ã¨ q_no ã¯å¿…é ˆã§ã™")
    df["year"] = df["year"].astype(int)
    df["q_no"] = df["q_no"].astype(int)
    for col in ["explanation", "tags"]:
        if col in df.columns:
            df[col] = df[col].fillna("")
    return df


def generate_predicted_question_id(row: pd.Series) -> str:
    base = f"predicted|{row.get('label', '')}|{str(row.get('question', ''))[:80]}"
    return hashlib.sha256(base.encode("utf-8")).hexdigest()[:16]


def generate_law_revision_question_id(row: pd.Series) -> str:
    base = (
        f"lawrev|{row.get('law_name', '')}|{row.get('revision_year', '')}|"
        f"{str(row.get('question', ''))[:80]}"
    )
    return hashlib.sha256(base.encode("utf-8")).hexdigest()[:16]


def normalize_predicted_questions(
    df: pd.DataFrame, mapping: Optional[Dict[str, str]] = None
) -> pd.DataFrame:
    df = df.copy()
    if mapping:
        df = df.rename(columns=mapping)
    required_cols = ["question", "choice1", "choice2", "choice3", "choice4"]
    for col in required_cols:
        if col not in df.columns:
            raise ValueError(f"å¿…è¦ãªåˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {col}")
    for col in required_cols:
        df[col] = df[col].fillna("").astype(str)
    df["label"] = df.get("label", "").fillna("").astype(str)
    df["category"] = df.get("category", "").fillna("").astype(str)
    df["topic"] = df.get("topic", "").fillna("").astype(str)
    df["source"] = df.get("source", "").fillna("").astype(str)
    df["year"] = df.get("year", "").fillna("").astype(str)
    df["q_no"] = df.get("q_no", "").fillna("").astype(str)
    df["explanation"] = df.get("explanation", "").fillna("").astype(str)
    df["difficulty"] = (
        df.get("difficulty")
        .fillna(DIFFICULTY_DEFAULT)
        .replace("", DIFFICULTY_DEFAULT)
        .astype(int)
    )
    df["tags"] = df.get("tags", "").fillna("").astype(str)
    if "correct" in df.columns:
        df["correct"] = (
            pd.to_numeric(df["correct"], errors="coerce")
            .where(lambda x: x.isin([1, 2, 3, 4]))
            .astype("Int64")
        )
    else:
        df["correct"] = pd.Series([pd.NA] * len(df), dtype="Int64")
    if "id" not in df.columns or df["id"].isna().any() or (df["id"].astype(str).str.strip() == "").any():
        df["id"] = df.apply(generate_predicted_question_id, axis=1)
    df["id"] = df["id"].astype(str)
    df = df.drop_duplicates(subset=["id"])
    columns = [
        "id",
        "label",
        "year",
        "q_no",
        "category",
        "topic",
        "source",
        "question",
        "choice1",
        "choice2",
        "choice3",
        "choice4",
        "correct",
        "explanation",
        "difficulty",
        "tags",
    ]
    df = df[columns]
    return df


def normalize_law_revision_questions(
    df: pd.DataFrame, mapping: Optional[Dict[str, str]] = None
) -> pd.DataFrame:
    df = df.copy()
    if mapping:
        df = df.rename(columns=mapping)
    required_cols = ["law_name", "question", "choice1", "choice2", "choice3", "choice4"]
    for col in required_cols:
        if col not in df.columns:
            raise ValueError(f"å¿…è¦ãªåˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {col}")
    for col in ["question", "choice1", "choice2", "choice3", "choice4"]:
        df[col] = df[col].fillna("").astype(str)
    df["law_name"] = df.get("law_name", "").fillna("").astype(str)
    optional_str_cols = [
        "label",
        "category",
        "topic",
        "source",
        "effective_date",
        "explanation",
        "tags",
        "auto_summary",
        "auto_cloze",
        "review_status",
        "generated_from",
        "fetched_at",
    ]
    for col in optional_str_cols:
        if col not in df.columns:
            df[col] = ""
        df[col] = df[col].fillna("").astype(str)
    if "review_status" in df.columns:
        df["review_status"] = df["review_status"].replace("", "pending")
    if "reviewed_at" not in df.columns:
        df["reviewed_at"] = ""
    df["reviewed_at"] = pd.to_datetime(df["reviewed_at"], errors="coerce")
    if "fetched_at" in df.columns:
        df["fetched_at"] = pd.to_datetime(df["fetched_at"], errors="coerce")
    df["revision_year"] = (
        pd.to_numeric(df.get("revision_year"), errors="coerce")
        .astype("Int64")
    )
    if "difficulty" not in df.columns:
        df["difficulty"] = DIFFICULTY_DEFAULT
    df["difficulty"] = (
        df.get("difficulty")
        .fillna(DIFFICULTY_DEFAULT)
        .replace("", DIFFICULTY_DEFAULT)
        .astype(int)
    )
    if "correct" in df.columns:
        df["correct"] = (
            pd.to_numeric(df["correct"], errors="coerce")
            .where(lambda x: x.isin([1, 2, 3, 4]))
            .astype("Int64")
        )
    else:
        df["correct"] = pd.Series([pd.NA] * len(df), dtype="Int64")
    if "id" not in df.columns or df["id"].isna().any() or (df["id"].astype(str).str.strip() == "").any():
        df["id"] = df.apply(generate_law_revision_question_id, axis=1)
    df["id"] = df["id"].astype(str)
    df = df.drop_duplicates(subset=["id"])
    columns = LAW_REVISION_TEMPLATE_COLUMNS.copy()
    df = df[columns]
    return df


def validate_question_records(df: pd.DataFrame) -> List[str]:
    errors: List[str] = []
    required_cols = [
        "year",
        "q_no",
        "question",
        "choice1",
        "choice2",
        "choice3",
        "choice4",
    ]
    missing = [col for col in required_cols if col not in df.columns]
    if missing:
        errors.append(f"å¿…é ˆåˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {', '.join(missing)}")
        return errors
    working = df.reset_index(drop=True)
    if "id" in working.columns:
        dup_ids = working[working["id"].notna() & working["id"].duplicated()]["id"].unique()
        if dup_ids.size > 0:
            errors.append(f"é‡è¤‡ã—ãŸIDãŒå­˜åœ¨ã—ã¾ã™: {', '.join(map(str, dup_ids[:5]))}")
    dup_keys = working.duplicated(subset=["year", "q_no"], keep=False)
    if dup_keys.any():
        duplicates = working.loc[dup_keys, ["year", "q_no"]].reset_index()
        sample = ", ".join(
            f"{row.year}å¹´å•{row.q_no} (è¡Œ{row['index'] + 2})" for _, row in duplicates.head(5).iterrows()
        )
        errors.append(f"å¹´åº¦ã¨å•ç•ªã®çµ„ã¿åˆã‚ã›ãŒé‡è¤‡ã—ã¦ã„ã¾ã™: {sample}")
    for row_number, row in enumerate(working.itertuples(index=False), start=2):
        year = getattr(row, "year", "?")
        q_no = getattr(row, "q_no", "?")
        label = f"{year}å¹´å•{q_no} (è¡Œ{row_number})"
        question_text = str(getattr(row, "question", ""))
        if not question_text.strip():
            errors.append(f"{label}ï¼šå•é¡Œæ–‡ãŒç©ºæ¬„ã§ã™ã€‚")
        choices = [str(getattr(row, f"choice{i}", "")).strip() for i in range(1, 5)]
        if any(choice == "" for choice in choices):
            errors.append(f"{label}ï¼šç©ºæ¬„ã®é¸æŠè‚¢ãŒã‚ã‚Šã¾ã™ã€‚")
        non_empty = [c for c in choices if c]
        if len(set(non_empty)) < len(non_empty):
            errors.append(f"{label}ï¼šé¸æŠè‚¢ãŒé‡è¤‡ã—ã¦ã„ã¾ã™ã€‚")
    return errors


def validate_answer_records(df: pd.DataFrame) -> List[str]:
    errors: List[str] = []
    required_cols = ["year", "q_no", "correct_number"]
    missing = [col for col in required_cols if col not in df.columns]
    if missing:
        errors.append(f"å¿…é ˆåˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {', '.join(missing)}")
        return errors
    working = df.reset_index(drop=True)
    dup_keys = working.duplicated(subset=["year", "q_no"], keep=False)
    if dup_keys.any():
        duplicates = working.loc[dup_keys, ["year", "q_no"]].reset_index()
        sample = ", ".join(
            f"{row.year}å¹´å•{row.q_no} (è¡Œ{row['index'] + 2})" for _, row in duplicates.head(5).iterrows()
        )
        errors.append(f"å¹´åº¦ã¨å•ç•ªã®çµ„ã¿åˆã‚ã›ãŒé‡è¤‡ã—ã¦ã„ã¾ã™: {sample}")
    if working["correct_number"].isna().any():
        rows = (working["correct_number"].isna().to_numpy().nonzero()[0] + 2).tolist()
        rows_text = ", ".join(map(str, rows[:5]))
        errors.append(f"correct_number ã«ç©ºæ¬„ãŒã‚ã‚Šã¾ã™ (è¡Œ {rows_text})ã€‚")
    try:
        invalid = pd.to_numeric(working["correct_number"], errors="coerce")
    except Exception:
        invalid = pd.Series([np.nan] * len(working))
    out_of_range = working[(invalid < 1) | (invalid > 4) | invalid.isna()]
    if not out_of_range.empty:
        sample_rows = ", ".join(
            f"{row.year}å¹´å•{row.q_no} (è¡Œ{row['index'] + 2})"
            for _, row in out_of_range.reset_index().head(5).iterrows()
        )
        errors.append(f"correct_number ã¯1ã€œ4ã®ç¯„å›²ã§æŒ‡å®šã—ã¦ãã ã•ã„: {sample_rows}")
    return errors


def validate_predicted_records(df: pd.DataFrame) -> List[str]:
    errors: List[str] = []
    required_cols = ["question", "choice1", "choice2", "choice3", "choice4"]
    missing = [col for col in required_cols if col not in df.columns]
    if missing:
        errors.append(f"å¿…é ˆåˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {', '.join(missing)}")
        return errors
    working = df.reset_index(drop=True)
    for row_number, row in enumerate(working.itertuples(index=False), start=2):
        label = getattr(row, "label", "") or f"è¡Œ{row_number}"
        question_text = str(getattr(row, "question", "")).strip()
        if not question_text:
            errors.append(f"{label}: å•é¡Œæ–‡ãŒç©ºæ¬„ã§ã™ã€‚")
        choices = [str(getattr(row, f"choice{i}", "")).strip() for i in range(1, 5)]
        if any(choice == "" for choice in choices):
            errors.append(f"{label}: ç©ºæ¬„ã®é¸æŠè‚¢ãŒã‚ã‚Šã¾ã™ã€‚")
        non_empty = [c for c in choices if c]
        if len(set(non_empty)) < len(non_empty):
            errors.append(f"{label}: é¸æŠè‚¢ãŒé‡è¤‡ã—ã¦ã„ã¾ã™ã€‚")
    if "id" in working.columns:
        dup_ids = working[working["id"].notna() & working["id"].astype(str).str.strip().duplicated()]["id"].unique()
        if dup_ids.size > 0:
            errors.append(f"é‡è¤‡ã—ãŸIDãŒå­˜åœ¨ã—ã¾ã™: {', '.join(map(str, dup_ids[:5]))}")
    return errors


def validate_law_revision_records(df: pd.DataFrame) -> List[str]:
    errors: List[str] = []
    required_cols = ["law_name", "question", "choice1", "choice2", "choice3", "choice4"]
    missing = [col for col in required_cols if col not in df.columns]
    if missing:
        errors.append(f"å¿…é ˆåˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {', '.join(missing)}")
        return errors
    working = df.reset_index(drop=True)
    for row_number, row in enumerate(working.itertuples(index=False), start=2):
        label = getattr(row, "label", "") or f"è¡Œ{row_number}"
        law_name = str(getattr(row, "law_name", "")).strip()
        if not law_name:
            errors.append(f"{label}: æ³•ä»¤å (law_name) ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        question_text = str(getattr(row, "question", "")).strip()
        if not question_text:
            errors.append(f"{label}: å•é¡Œæ–‡ãŒç©ºæ¬„ã§ã™ã€‚")
        choices = [str(getattr(row, f"choice{i}", "")).strip() for i in range(1, 5)]
        if any(choice == "" for choice in choices):
            errors.append(f"{label}: ç©ºæ¬„ã®é¸æŠè‚¢ãŒã‚ã‚Šã¾ã™ã€‚")
        non_empty = [c for c in choices if c]
        if len(set(non_empty)) < len(non_empty):
            errors.append(f"{label}: é¸æŠè‚¢ãŒé‡è¤‡ã—ã¦ã„ã¾ã™ã€‚")
        revision_year_value = getattr(row, "revision_year", None)
        if revision_year_value not in (None, "", pd.NA):
            try:
                int(str(revision_year_value).strip())
            except Exception:
                errors.append(f"{label}: revision_year ã¯è¥¿æš¦ã®æ•°å€¤ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        correct_value = getattr(row, "correct", None)
        if correct_value not in (None, "", pd.NA):
            try:
                numeric_correct = int(correct_value)
            except Exception:
                errors.append(f"{label}: correct ã¯1ã€œ4ã®æ•°å€¤ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            else:
                if numeric_correct not in {1, 2, 3, 4}:
                    errors.append(f"{label}: correct ã¯1ã€œ4ã®ç¯„å›²ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
    if "id" in working.columns:
        dup_ids = working[working["id"].notna() & working["id"].astype(str).str.strip().duplicated()]["id"].unique()
        if dup_ids.size > 0:
            errors.append(f"é‡è¤‡ã—ãŸIDãŒå­˜åœ¨ã—ã¾ã™: {', '.join(map(str, dup_ids[:5]))}")
    return errors


def build_answers_export(df: pd.DataFrame) -> pd.DataFrame:
    records: List[Dict[str, object]] = []
    for _, row in df.iterrows():
        correct_number = row.get("correct")
        if pd.isna(correct_number):
            correct_number = None
            correct_label = ""
            correct_text = ""
        else:
            correct_number = int(correct_number)
            correct_label = ["A", "B", "C", "D"][correct_number - 1]
            correct_text = str(row.get(f"choice{correct_number}", ""))
        records.append(
            {
                "year": row.get("year"),
                "q_no": row.get("q_no"),
                "correct_number": correct_number,
                "correct_label": correct_label,
                "correct_text": correct_text,
                "explanation": row.get("explanation", ""),
                "difficulty": row.get("difficulty"),
                "tags": row.get("tags", ""),
            }
        )
    return pd.DataFrame(records, columns=ANSWER_TEMPLATE_COLUMNS)


def build_sample_questions_csv() -> str:
    sample_rows = [
        {
            "year": 2023,
            "q_no": 1,
            "category": "å®…å»ºæ¥­æ³•",
            "topic": "å…è¨±",
            "question": "å®…åœ°å»ºç‰©å–å¼•æ¥­è€…ã®å…è¨±ã«ã¤ã„ã¦æ­£ã—ã„ã‚‚ã®ã¯ã©ã‚Œã‹ã€‚",
            "choice1": "å…è¨±æ¨©è€…ã¯å¿…ãšå›½åœŸäº¤é€šå¤§è‡£ã§ã‚ã‚‹ã€‚",
            "choice2": "æ³•äººãŒå…è¨±ã‚’å—ã‘ã‚‹å ´åˆã€å°‚ä»»å–å¼•å£«ã¯ä¸è¦ã§ã‚ã‚‹ã€‚",
            "choice3": "å…è¨±æ›¿ãˆã®éš›ã¯æ—§å…è¨±ã®æœ‰åŠ¹æœŸé–“ã‚’å¼•ãç¶™ã’ã‚‹ã€‚",
            "choice4": "çŸ¥äº‹å…è¨±æ¥­è€…ãŒäºŒä»¥ä¸Šã®éƒ½é“åºœçœŒã«äº‹å‹™æ‰€ã‚’è¨­ã‘ã‚‹ã¨ãã¯å¤§è‡£å…è¨±ãŒå¿…è¦ã§ã‚ã‚‹ã€‚",
            "explanation": "å®…å»ºæ¥­æ³•ä¸Šã€äºŒä»¥ä¸Šã®éƒ½é“åºœçœŒã«äº‹å‹™æ‰€ã‚’è¨­ã‘ã‚‹å ´åˆã¯å¤§è‡£å…è¨±ãŒå¿…è¦ã€‚",
            "difficulty": 3,
            "tags": "å®…å»ºæ¥­æ³•;å…è¨±",
        },
        {
            "year": 2023,
            "q_no": 2,
            "category": "æ¨©åˆ©é–¢ä¿‚",
            "topic": "ç‰©æ¨©å¤‰å‹•",
            "question": "ä¸å‹•ç”£ç‰©æ¨©å¤‰å‹•ã®å¯¾æŠ—è¦ä»¶ã«é–¢ã™ã‚‹è¨˜è¿°ã¨ã—ã¦æ­£ã—ã„ã‚‚ã®ã¯ã©ã‚Œã‹ã€‚",
            "choice1": "ä¸å‹•ç”£ã®è´ˆä¸ã¯å£é ­ã§ã‚‚ç¬¬ä¸‰è€…ã«å¯¾æŠ—ã§ãã‚‹ã€‚",
            "choice2": "æ‰€æœ‰æ¨©ç§»è»¢ç™»è¨˜ã‚’å‚™ãˆãªã‘ã‚Œã°ç¬¬ä¸‰è€…ã«å¯¾æŠ—ã§ããªã„ã€‚",
            "choice3": "ä»®ç™»è¨˜ã®ã¾ã¾ã§ã‚‚å¸¸ã«ç¬¬ä¸‰è€…ã«å„ªå…ˆã™ã‚‹ã€‚",
            "choice4": "åœ°ä¸Šæ¨©è¨­å®šã¯ç™»è¨˜ç°¿ã®è¨˜è¼‰ã‚’è¦ã—ãªã„ã€‚",
            "explanation": "ä¸å‹•ç”£ç‰©æ¨©å¤‰å‹•ã®å¯¾æŠ—è¦ä»¶ã¯åŸå‰‡ã¨ã—ã¦ç™»è¨˜ã§ã‚ã‚‹ã€‚",
            "difficulty": 2,
            "tags": "æ¨©åˆ©é–¢ä¿‚;ç‰©æ¨©å¤‰å‹•",
        },
    ]
    buffer = io.StringIO()
    pd.DataFrame(sample_rows, columns=QUESTION_TEMPLATE_COLUMNS).to_csv(buffer, index=False)
    return buffer.getvalue()


def build_sample_answers_csv() -> str:
    sample_rows = [
        {
            "year": 2023,
            "q_no": 1,
            "correct_number": 4,
            "correct_label": "D",
            "correct_text": "çŸ¥äº‹å…è¨±æ¥­è€…ãŒäºŒä»¥ä¸Šã®éƒ½é“åºœçœŒã«äº‹å‹™æ‰€ã‚’è¨­ã‘ã‚‹ã¨ãã¯å¤§è‡£å…è¨±ãŒå¿…è¦ã€‚",
            "explanation": "å®…å»ºæ¥­æ³•ã®å…è¨±åˆ¶åº¦ã«åŸºã¥ãã€è¤‡æ•°éƒ½é“åºœçœŒã§å–¶æ¥­ã™ã‚‹å ´åˆã¯å¤§è‡£å…è¨±ãŒå¿…è¦ã§ã™ã€‚",
            "difficulty": 3,
            "tags": "å®…å»ºæ¥­æ³•;å…è¨±",
        },
        {
            "year": 2023,
            "q_no": 2,
            "correct_number": 2,
            "correct_label": "B",
            "correct_text": "æ‰€æœ‰æ¨©ç§»è»¢ç™»è¨˜ã‚’å‚™ãˆãªã‘ã‚Œã°ç¬¬ä¸‰è€…ã«å¯¾æŠ—ã§ããªã„ã€‚",
            "explanation": "ä¸å‹•ç”£ç‰©æ¨©å¤‰å‹•ã®å¯¾æŠ—è¦ä»¶ã¯ç™»è¨˜ãŒåŸå‰‡ã§ã™ã€‚",
            "difficulty": 2,
            "tags": "æ¨©åˆ©é–¢ä¿‚;ç‰©æ¨©å¤‰å‹•",
        },
    ]
    buffer = io.StringIO()
    pd.DataFrame(sample_rows, columns=ANSWER_TEMPLATE_COLUMNS).to_csv(buffer, index=False)
    return buffer.getvalue()


def build_sample_predicted_csv() -> str:
    sample_rows = [
        {
            "label": "äºˆæƒ³å•é¡Œ001",
            "category": "å®…å»ºæ¥­æ³•",
            "topic": "é‡è¦äº‹é …èª¬æ˜",
            "source": "è¬›å¸«äºˆæƒ³",
            "question": "å®…åœ°å»ºç‰©å–å¼•æ¥­è€…ãŒé‡è¦äº‹é …èª¬æ˜ã‚’è¡Œã†éš›ã®ç•™æ„ç‚¹ã«ã¤ã„ã¦æ­£ã—ã„ã‚‚ã®ã¯ã©ã‚Œã‹ã€‚",
            "choice1": "å°‚ä»»å–å¼•å£«ä»¥å¤–ã§ã‚‚å®…å»ºå£«è¨¼ã®æç¤ºãŒã‚ã‚Œã°èª¬æ˜ã§ãã‚‹ã€‚",
            "choice2": "é‡è¦äº‹é …èª¬æ˜æ›¸ã¯é›»ç£çš„æ–¹æ³•ã§äº¤ä»˜ã§ãã‚‹ã€‚",
            "choice3": "35æ¡æ›¸é¢ã¯å£²ä¸»ãŒç›´æ¥èª¬æ˜ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚",
            "choice4": "è²·ä¸»ã®æ‰¿è«¾ãŒã‚ã‚Œã°å£é ­èª¬æ˜ã®ã¿ã§ã‚ˆã„ã€‚",
            "correct": 2,
            "explanation": "é‡è¦äº‹é …èª¬æ˜æ›¸ã¯ä¸€å®šè¦ä»¶ã®ä¸‹ã§é›»ç£çš„æ–¹æ³•ã«ã‚ˆã‚‹äº¤ä»˜ãŒèªã‚ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚",
            "year": dt.datetime.now().year + 1,
            "q_no": "äºˆæƒ³1",
            "difficulty": 3,
            "tags": "äºˆæƒ³;é‡è¦äº‹é …èª¬æ˜",
        },
        {
            "label": "äºˆæƒ³å•é¡Œ002",
            "category": "æ¨©åˆ©é–¢ä¿‚",
            "topic": "å€Ÿåœ°å€Ÿå®¶æ³•",
            "source": "æ¨¡è©¦ä½œæˆãƒãƒ¼ãƒ ",
            "question": "å®šæœŸå€Ÿå®¶å¥‘ç´„ã«é–¢ã™ã‚‹æ¬¡ã®è¨˜è¿°ã®ã†ã¡ã€é©åˆ‡ãªã‚‚ã®ã¯ã©ã‚Œã‹ã€‚",
            "choice1": "æ›¸é¢ã§å¥‘ç´„ã™ã‚Œã°æœŸé–“æº€äº†å‰ã§ã‚‚å¸¸ã«è§£ç´„ã§ãã‚‹ã€‚",
            "choice2": "æ›´æ–°ã‚’å‰æã¨ã—ãªã„æ—¨ã‚’å£é ­ã§åˆæ„ã™ã‚Œã°å®šæœŸå€Ÿå®¶ã¨ãªã‚‹ã€‚",
            "choice3": "å…¬æ­£è¨¼æ›¸ç­‰ã®æ›¸é¢ã§å¥‘ç´„ã—ãªã‘ã‚Œã°åŠ¹åŠ›ã‚’ç”Ÿã˜ãªã„ã€‚",
            "choice4": "å®šæœŸå€Ÿå®¶å¥‘ç´„ã§ã¯ä¸­é€”è§£ç´„ã¯ä¸€åˆ‡èªã‚ã‚‰ã‚Œãªã„ã€‚",
            "correct": 3,
            "explanation": "å®šæœŸå€Ÿå®¶å¥‘ç´„ã¯å…¬æ­£è¨¼æ›¸ç­‰ã®æ›¸é¢ã«ã‚ˆã‚‹å¥‘ç´„ãŒå¿…è¦ã§ã™ã€‚",
            "year": dt.datetime.now().year + 1,
            "q_no": "äºˆæƒ³2",
            "difficulty": 2,
            "tags": "äºˆæƒ³;å€Ÿåœ°å€Ÿå®¶æ³•",
        },
    ]
    buffer = io.StringIO()
    pd.DataFrame(sample_rows, columns=PREDICTED_TEMPLATE_COLUMNS).to_csv(buffer, index=False)
    return buffer.getvalue()


def build_sample_law_revision_csv() -> str:
    sample_rows = [
        {
            "label": "æ³•æ”¹æ­£å¯¾ç­–001",
            "law_name": "å®…å»ºæ¥­æ³•",
            "revision_year": dt.datetime.now().year,
            "effective_date": f"{dt.datetime.now().year}-04-01",
            "category": "å®…å»ºæ¥­æ³•",
            "topic": "æ”¹æ­£ãƒã‚¤ãƒ³ãƒˆ",
            "source": "å®˜å ±",
            "question": "æœ€æ–°ã®å®…å»ºæ¥­æ³•æ”¹æ­£ã§è¿½åŠ ã•ã‚ŒãŸèª¬æ˜ç¾©å‹™ã«ã¤ã„ã¦æ­£ã—ã„ã‚‚ã®ã¯ã©ã‚Œã‹ã€‚",
            "choice1": "é‡è¦äº‹é …èª¬æ˜æ›¸ã«æ”¹æ­£å†…å®¹ã‚’è¿½è¨˜ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚",
            "choice2": "è²·ä¸»ãŒå¸Œæœ›ã™ã‚Œã°çœç•¥ã§ãã‚‹ã€‚",
            "choice3": "å®…å»ºå£«è¨¼ã®æç¤ºç¾©å‹™ãŒå…é™¤ã•ã‚ŒãŸã€‚",
            "choice4": "å®…åœ°å»ºç‰©ä»¥å¤–ã®å–å¼•ã«é™ã‚Šé©ç”¨ã•ã‚Œã‚‹ã€‚",
            "correct": 1,
            "explanation": "æ”¹æ­£æ¡æ–‡ã®ãƒã‚¤ãƒ³ãƒˆã‚’è¨˜è¼‰ã—ã¾ã™ã€‚",
            "difficulty": DIFFICULTY_DEFAULT,
            "tags": "æ³•æ”¹æ­£;ç›´å‰å¯¾ç­–",
            "auto_summary": "å®…å»ºæ¥­æ³•ã®æ”¹æ­£ã«ã‚ˆã‚Šé‡è¦äº‹é …èª¬æ˜æ›¸ã¸æ”¹æ­£å†…å®¹ã®è¿½è¨˜ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ã€‚",
            "auto_cloze": "å®…å»ºæ¥­æ³•ã®æ”¹æ­£ã«ã‚ˆã‚Šé‡è¦äº‹é …èª¬æ˜æ›¸ã«ï¼¿ï¼¿ï¼¿ã‚’è¿½è¨˜ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚",
            "review_status": "approved",
            "reviewed_at": dt.datetime.now().isoformat(timespec="seconds"),
            "generated_from": "ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿",
            "fetched_at": dt.datetime.now().isoformat(timespec="seconds"),
        }
    ]
    buffer = io.StringIO()
    pd.DataFrame(sample_rows, columns=LAW_REVISION_TEMPLATE_COLUMNS).to_csv(buffer, index=False)
    return buffer.getvalue()


def merge_questions_answers(
    questions: pd.DataFrame,
    answers: pd.DataFrame,
    policy: Dict[str, str],
) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    merged = questions.copy()
    if "correct" not in merged.columns:
        merged["correct"] = np.nan
    rejects_q = []
    rejects_a = []

    answer_map = {}
    for _, row in answers.iterrows():
        key = (row["year"], row["q_no"])
        answer_map[key] = row

    def determine_correct(row: pd.Series, ans_row: Optional[pd.Series]) -> Tuple[Optional[int], Optional[str], Optional[str]]:
        if ans_row is None:
            return None, None, None
        correct_number = ans_row.get("correct_number")
        if pd.notna(correct_number):
            try:
                correct_number = int(correct_number)
                if correct_number in [1, 2, 3, 4]:
                    return correct_number, ans_row.get("explanation"), ans_row.get("tags")
            except ValueError:
                pass
        label = ans_row.get("correct_label")
        if pd.notna(label):
            label = str(label).strip().upper()
            mapping = {"ï¼¡": 1, "A": 1, "ï¼¢": 2, "B": 2, "ï¼£": 3, "C": 3, "ï¼¤": 4, "D": 4}
            if label in mapping:
                return mapping[label], ans_row.get("explanation"), ans_row.get("tags")
        text_answer = ans_row.get("correct_text")
        if pd.notna(text_answer) and text_answer:
            choices = [row.get(f"choice{i}", "") for i in range(1, 5)]
            for idx, choice in enumerate(choices, start=1):
                if str(choice).strip() == str(text_answer).strip():
                    return idx, ans_row.get("explanation"), ans_row.get("tags")
            ratios = [fuzz.ratio(str(choice), str(text_answer)) for choice in choices]
            max_ratio = max(ratios)
            if max_ratio >= 90:
                idx = ratios.index(max_ratio) + 1
                return idx, ans_row.get("explanation"), ans_row.get("tags")
            else:
                rejects_a.append({**ans_row.to_dict(), "reason": "é¸æŠè‚¢ã¨ä¸€è‡´ã›ãš"})
                return None, None, None
        rejects_a.append({**ans_row.to_dict(), "reason": "æ­£ç­”æƒ…å ±ãŒä¸è¶³"})
        return None, None, None

    conflicts = []
    for idx, row in merged.iterrows():
        key = (row["year"], row["q_no"])
        ans_row = answer_map.get(key)
        correct, exp_override, tags_new = determine_correct(row, ans_row)
        if correct is not None:
            if pd.notna(row.get("correct")) and row.get("correct") != correct:
                conflicts.append({
                    "id": row["id"],
                    "year": row["year"],
                    "q_no": row["q_no"],
                    "existing": row.get("correct"),
                    "incoming": correct,
                })
            merged.at[idx, "correct"] = correct
        if ans_row is not None:
            if policy.get("explanation", "overwrite") == "overwrite" and pd.notna(ans_row.get("explanation")):
                merged.at[idx, "explanation"] = ans_row.get("explanation")
            elif policy.get("explanation") == "append":
                merged.at[idx, "explanation"] = (str(row.get("explanation", "")) + "\n" + str(ans_row.get("explanation", ""))).strip()
            if tags_new:
                if policy.get("tags", "merge") == "merge" and row.get("tags"):
                    tags_combined = set(str(row.get("tags", "")).split(";")) | set(str(tags_new).split(";"))
                    merged.at[idx, "tags"] = ";".join(sorted({t.strip() for t in tags_combined if t.strip()}))
                else:
                    merged.at[idx, "tags"] = tags_new
            if pd.notna(ans_row.get("difficulty")):
                merged.at[idx, "difficulty"] = int(ans_row.get("difficulty"))
    merged["correct"] = merged["correct"].fillna(0).astype(int).replace(0, np.nan)
    rejects_q_df = pd.DataFrame(rejects_q)
    rejects_a_df = pd.DataFrame(rejects_a)
    conflicts_df = pd.DataFrame(conflicts)
    return merged, rejects_q_df, rejects_a_df, conflicts_df


def normalize_category(value: str) -> str:
    if not value:
        return CATEGORY_CHOICES[0]
    value = str(value).strip()
    if value in CATEGORY_CHOICES:
        return value
    for key, target in DEFAULT_CATEGORY_MAP.items():
        if key in value:
            return target
    scores = {cat: fuzz.partial_ratio(value, cat) for cat in CATEGORY_CHOICES}
    best_cat = max(scores, key=scores.get)
    if scores[best_cat] >= 70:
        return best_cat
    return CATEGORY_CHOICES[0]


def generate_question_id(row: pd.Series) -> str:
    base = f"{row['year']}|{row['q_no']}|{str(row['question'])[:80]}"
    return hashlib.sha256(base.encode("utf-8")).hexdigest()[:16]


@dataclass
class ExamSession:
    id: Optional[int]
    name: str
    questions: List[str]
    started_at: dt.datetime
    year_mode: str
    mode: str


@dataclass
class QuestionNavigation:
    has_prev: bool = False
    has_next: bool = False
    on_prev: Optional[Callable[[], None]] = None
    on_next: Optional[Callable[[], None]] = None
    label: Optional[str] = None


def select_random_questions(
    df: pd.DataFrame,
    count: int,
    weights: Optional[Sequence[float]] = None,
) -> List[str]:
    if df.empty or count <= 0:
        return []
    ids = list(df["id"])
    population = len(ids)
    draw = min(count, population)
    if draw == 0:
        return []
    if weights is not None:
        weight_array = np.asarray(list(weights), dtype=float)
        if weight_array.shape[0] != population:
            raise ValueError("weights length must match dataframe length")
        weight_array = np.where(np.isnan(weight_array) | (weight_array < 0), 0.0, weight_array)
        if float(weight_array.sum()) <= 0.0:
            weight_array = np.ones(population, dtype=float)
        probabilities = weight_array / weight_array.sum()
        indices = np.random.choice(population, size=draw, replace=False, p=probabilities)
        return [ids[i] for i in indices]
    if draw == population:
        return ids
    return random.sample(ids, draw)


def build_question_priority(df: pd.DataFrame, attempts: pd.DataFrame) -> pd.DataFrame:
    settings = st.session_state.get("settings", {})
    low_conf_threshold = int(settings.get("review_low_confidence_threshold", 60))
    elapsed_days_threshold = max(int(settings.get("review_elapsed_days", 7)), 1)
    base = df[["id", "category", "difficulty"]].copy()
    base["difficulty"] = base["difficulty"].fillna(DIFFICULTY_DEFAULT).astype(float)
    metrics_defaults = {
        "attempts_count": 0,
        "correct_count": 0,
        "accuracy": 0.5,
        "last_confidence": float(low_conf_threshold),
        "days_since_last_attempt": float(elapsed_days_threshold),
    }
    for column, default in metrics_defaults.items():
        base[column] = default
    if not attempts.empty:
        attempts = attempts.copy()
        attempts["created_at"] = pd.to_datetime(attempts["created_at"])
        summary = (
            attempts.groupby("question_id")
            .agg(
                attempts_count=("is_correct", "count"),
                correct_count=("is_correct", "sum"),
                last_attempt_at=("created_at", "max"),
            )
            .reset_index()
        )
        last_conf = (
            attempts.sort_values("created_at")
            .groupby("question_id")
            .agg(last_confidence=("confidence", "last"))
            .reset_index()
        )
        summary = summary.merge(last_conf, on="question_id", how="left")
        summary["accuracy"] = summary["correct_count"] / summary["attempts_count"].replace(0, np.nan)
        summary["accuracy"] = summary["accuracy"].clip(lower=0.0, upper=1.0)
        now = dt.datetime.now()
        summary["days_since_last_attempt"] = (
            (now - summary["last_attempt_at"]).dt.total_seconds() / 86400.0
        )
        base = base.merge(
            summary,
            left_on="id",
            right_on="question_id",
            how="left",
            suffixes=("", "_summary"),
        )
        base.drop(
            columns=[col for col in ["question_id", "last_attempt_at"] if col in base.columns],
            inplace=True,
        )
        for column, default in metrics_defaults.items():
            summary_col = f"{column}_summary"
            if summary_col in base.columns:
                base[column] = base[summary_col]
                base.drop(columns=[summary_col], inplace=True)
        base["attempts_count"] = base["attempts_count"].fillna(0).astype(int)
        base["correct_count"] = base["correct_count"].fillna(0).astype(int)
        base["accuracy"] = base["accuracy"].fillna(0.5)
        base["last_confidence"] = pd.to_numeric(base["last_confidence"], errors="coerce")
        base["last_confidence"] = base["last_confidence"].fillna(low_conf_threshold)
        base["days_since_last_attempt"] = base["days_since_last_attempt"].fillna(float(elapsed_days_threshold))
    base["accuracy"] = base["accuracy"].clip(lower=0.0, upper=1.0)
    base["last_confidence"] = base["last_confidence"].clip(lower=0.0, upper=100.0)
    base["days_since_last_attempt"] = base["days_since_last_attempt"].clip(lower=0.0)
    accuracy_component = 1.0 + (1.0 - base["accuracy"])
    conf_gap = np.clip((low_conf_threshold - base["last_confidence"]) / max(low_conf_threshold, 1), 0.0, 1.0)
    confidence_component = 1.0 + conf_gap
    days_ratio = np.clip(base["days_since_last_attempt"] / float(elapsed_days_threshold), 0.0, 3.0)
    days_component = 1.0 + days_ratio * 0.4
    difficulty_component = 1.0 + (base["difficulty"] - 3.0) * 0.15
    base["raw_weight"] = (accuracy_component + confidence_component + days_component) * difficulty_component
    category_stats = (
        base.groupby("category")
        .agg(
            category_accuracy=("accuracy", "mean"),
            category_difficulty=("difficulty", "mean"),
        )
        .reset_index()
    )
    category_stats["category_accuracy"] = category_stats["category_accuracy"].fillna(0.5)
    category_stats["category_multiplier"] = 1.0 + (
        (1.0 - category_stats["category_accuracy"]) * 1.2
    ) + np.maximum(category_stats["category_difficulty"] - 3.0, 0.0) * 0.1
    multiplier_map = dict(zip(category_stats["category"], category_stats["category_multiplier"]))
    base["category_multiplier"] = base["category"].map(multiplier_map).fillna(1.0)
    base["weight"] = base["raw_weight"] * base["category_multiplier"]
    return base


def stratified_exam(
    df: pd.DataFrame, weight_map: Optional[Dict[str, float]] = None
) -> List[str]:
    quotas = {"å®…å»ºæ¥­æ³•": 20, "æ¨©åˆ©é–¢ä¿‚": 14, "æ³•ä»¤ä¸Šã®åˆ¶é™": 8, "ç¨ãƒ»ãã®ä»–": 8}
    selected = []
    remaining = df.copy()
    for category, quota in quotas.items():
        subset = remaining[remaining["category"] == category]
        subset_weights = None
        if weight_map is not None:
            subset_weights = [weight_map.get(qid, 1.0) for qid in subset["id"]]
        chosen = select_random_questions(subset, quota, subset_weights)
        selected.extend(chosen)
        remaining = remaining[~remaining["id"].isin(chosen)]
    if len(selected) < 50:
        additional_weights = None
        if weight_map is not None:
            additional_weights = [weight_map.get(qid, 1.0) for qid in remaining["id"]]
        additional = select_random_questions(remaining, 50 - len(selected), additional_weights)
        selected.extend(additional)
    return selected


def sm2_update(row: Optional[pd.Series], grade: int, initial_ease: float = 2.5) -> Dict[str, object]:
    today = dt.date.today()
    if row is None:
        repetition = 0
        prev_interval = 0
        ease = initial_ease
    else:
        repetition = row.get("repetition", 0) or 0
        prev_interval = row.get("interval", 0) or 0
        ease = row.get("ease", 2.5) or 2.5
    if grade >= 3:
        if repetition == 0:
            interval = 1
        elif repetition == 1:
            interval = 6
        else:
            interval = int(round(max(prev_interval, 1) * ease))
            interval = max(interval, 1)
        repetition += 1
    else:
        repetition = 0
        interval = 1
    ease = ease + (0.1 - (5 - grade) * (0.08 + (5 - grade) * 0.02))
    ease = max(ease, 1.3)
    due_date = today + dt.timedelta(days=interval)
    return {
        "repetition": repetition,
        "interval": interval,
        "ease": ease,
        "due_date": due_date,
        "last_grade": grade,
        "updated_at": dt.datetime.now(),
    }


def inject_ui_styles() -> None:
    if st.session_state.get("_ui_styles_injected"):
        return
    inject_style(
        """
.takken-choice-button {
    transition: filter 0.2s ease;
}
.takken-choice-button button {
    width: 100%;
    min-height: 56px;
    font-size: 1.05rem;
    border-radius: 0.8rem;
    display: flex;
    align-items: flex-start;
    justify-content: flex-start;
    text-align: left;
    line-height: 1.5;
    white-space: normal;
    padding: 0.75rem 1rem;
    gap: 0.75rem;
    border-width: 1.5px;
}
.takken-choice-button.is-selected:not(.is-graded) button {
    border-color: #4c6ef5 !important;
    box-shadow: 0 0 0 2px rgba(76, 110, 245, 0.18);
}
.takken-choice-button.is-correct button {
    background-color: #f0f9f4 !important;
    border-color: #2f9e44 !important;
    color: #1b4332 !important;
}
.takken-choice-button.is-incorrect button {
    background-color: #fff5f5 !important;
    border-color: #e03131 !important;
    color: #871b1b !important;
}
.takken-choice-button.is-dimmed button {
    filter: grayscale(0.25);
    opacity: 0.7;
}
.takken-choice-button.is-graded button {
    cursor: default;
}
.takken-choice-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(240px, 1fr));
    gap: 0.75rem;
    margin-bottom: 0.5rem;
}
.takken-action-bar {
    display: flex;
    flex-wrap: wrap;
    gap: 0.75rem;
    margin: 1rem 0;
}
.takken-action-item {
    flex: 1 1 160px;
}
@media (max-width: 768px) {
    .takken-choice-grid {
        grid-template-columns: 1fr;
    }
    .takken-action-bar {
        flex-direction: column;
    }
    .takken-action-item {
        width: 100%;
    }
}
.takken-inline-actions button {
    min-height: 48px;
}
[data-testid="stMarkdownContainer"] {
    text-align: left;
}
[data-testid="stMarkdownContainer"] * {
    text-align: left !important;
}
.takken-feedback-summary {
    margin-top: 0.5rem;
    padding: 0.75rem 1rem;
    background: #f5f7fb;
    border-radius: 0.75rem;
    font-weight: 500;
    color: #36435a;
    display: inline-flex;
    gap: 0.5rem;
    align-items: flex-start;
}
.takken-feedback-summary strong {
    font-weight: 600;
}
.takken-tag-group {
    display: flex;
    flex-wrap: wrap;
    gap: 0.4rem;
    margin: 0.25rem 0 0.75rem;
}
.takken-tag {
    display: inline-flex;
    align-items: center;
    gap: 0.35rem;
    padding: 0.3rem 0.65rem;
    border-radius: 999px;
    font-size: 0.85rem;
    font-weight: 600;
    letter-spacing: 0.01em;
    line-height: 1.2;
    border: 1px solid transparent;
    background-color: rgba(108, 117, 125, 0.16);
    color: #374151;
}
[data-theme="dark"] .takken-tag {
    background-color: rgba(148, 163, 184, 0.16);
    color: #e2e8f0;
}
.takken-tag-icon {
    font-size: 0.95rem;
    line-height: 1;
}
.takken-tag-label {
    line-height: 1.2;
}
.takken-tag--category-business {
    background-color: rgba(76, 110, 245, 0.18);
    border-color: rgba(76, 110, 245, 0.35);
    color: #2f4f9e;
}
[data-theme="dark"] .takken-tag--category-business {
    background-color: rgba(118, 145, 255, 0.22);
    border-color: rgba(118, 145, 255, 0.5);
    color: #dbe4ff;
}
.takken-tag--category-rights {
    background-color: rgba(34, 197, 94, 0.18);
    border-color: rgba(34, 197, 94, 0.35);
    color: #1b4332;
}
[data-theme="dark"] .takken-tag--category-rights {
    background-color: rgba(52, 211, 153, 0.22);
    border-color: rgba(52, 211, 153, 0.5);
    color: #bbf7d0;
}
.takken-tag--category-regulation {
    background-color: rgba(245, 158, 11, 0.18);
    border-color: rgba(245, 158, 11, 0.35);
    color: #854d0e;
}
[data-theme="dark"] .takken-tag--category-regulation {
    background-color: rgba(251, 191, 36, 0.22);
    border-color: rgba(251, 191, 36, 0.5);
    color: #fde68a;
}
.takken-tag--category-tax {
    background-color: rgba(236, 72, 153, 0.18);
    border-color: rgba(236, 72, 153, 0.35);
    color: #831843;
}
[data-theme="dark"] .takken-tag--category-tax {
    background-color: rgba(244, 114, 182, 0.22);
    border-color: rgba(244, 114, 182, 0.5);
    color: #fbcfe8;
}
.takken-tag--category-default {
    background-color: rgba(100, 116, 139, 0.2);
    border-color: rgba(100, 116, 139, 0.3);
    color: #1f2937;
}
[data-theme="dark"] .takken-tag--category-default {
    background-color: rgba(148, 163, 184, 0.24);
    border-color: rgba(148, 163, 184, 0.45);
    color: #e2e8f0;
}
.takken-tag--topic {
    background-color: rgba(79, 70, 229, 0.15);
    border-color: rgba(79, 70, 229, 0.3);
    color: #3730a3;
}
[data-theme="dark"] .takken-tag--topic {
    background-color: rgba(129, 140, 248, 0.22);
    border-color: rgba(129, 140, 248, 0.45);
    color: #c7d2fe;
}
.takken-table {
    width: 100%;
    border-collapse: collapse;
    margin: 0.75rem 0;
    font-size: 0.9rem;
}
.takken-table th,
.takken-table td {
    text-align: left;
    padding: 0.5rem 0.75rem;
    border-bottom: 1px solid rgba(148, 163, 184, 0.35);
    vertical-align: top;
}
[data-theme="dark"] .takken-table th,
[data-theme="dark"] .takken-table td {
    border-bottom-color: rgba(203, 213, 225, 0.2);
}
.takken-table tbody tr:last-child th,
.takken-table tbody tr:last-child td {
    border-bottom: none;
}
.takken-table thead th {
    font-weight: 700;
    color: inherit;
}
""",
        "takken-ui-styles",
    )
    st.session_state["_ui_styles_injected"] = True


def _build_tag_html(label: str, icon: Optional[str], class_name: str) -> str:
    if not label:
        return ""
    safe_label = html_module.escape(label)
    icon_html = (
        f'<span class="takken-tag-icon">{html_module.escape(icon)}</span>'
        if icon
        else ""
    )
    return (
        f'<span class="takken-tag {class_name}">{icon_html}'
        f'<span class="takken-tag-label">{safe_label}</span></span>'
    )


def render_category_tag(category: Optional[str]) -> str:
    if category is None or (isinstance(category, float) and pd.isna(category)):
        return ""
    normalized = str(category).strip()
    if not normalized:
        return ""
    canonical = DEFAULT_CATEGORY_MAP.get(normalized, normalized)
    style = CATEGORY_BADGE_STYLE.get(canonical, CATEGORY_BADGE_DEFAULT)
    style_class = style.get("class", CATEGORY_BADGE_DEFAULT["class"])
    icon = style.get("icon", CATEGORY_BADGE_DEFAULT["icon"])
    return _build_tag_html(canonical, icon, style_class)


def render_topic_tag(topic: Optional[str]) -> str:
    if topic is None or (isinstance(topic, float) and pd.isna(topic)):
        return ""
    normalized = str(topic).strip()
    if not normalized:
        return ""
    return _build_tag_html(normalized, "ğŸ§ ", "takken-tag--topic")


def render_category_topic_tags(
    category: Optional[str], topic: Optional[str]
) -> str:
    inject_ui_styles()
    tags: List[str] = []
    category_tag = render_category_tag(category)
    if category_tag:
        tags.append(category_tag)
    topic_tag = render_topic_tag(topic)
    if topic_tag:
        tags.append(topic_tag)
    if not tags:
        return ""
    return f'<div class="takken-tag-group">{"".join(tags)}</div>'


def render_table_with_category_tags(
    df: pd.DataFrame,
    column_order: Sequence[str],
    rename_map: Optional[Dict[str, str]] = None,
    index_column: Optional[str] = None,
    table_classes: str = "takken-table",
) -> None:
    inject_ui_styles()
    rename_map = rename_map or {}
    if df.empty:
        st.markdown("<p>è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚</p>", unsafe_allow_html=True)
        return
    display = df.loc[:, column_order].copy()
    if "category" in display.columns:
        category_pos = list(display.columns).index("category")
        category_tags = display["category"].apply(render_category_tag)
        display = display.drop(columns=["category"])
        display.insert(category_pos, "_category_tag", category_tags)
    if index_column and index_column in display.columns:
        display = display.set_index(index_column)
        display.index.name = rename_map.get(index_column, index_column)
    rename_columns: Dict[str, str] = {}
    for original, new_name in rename_map.items():
        if original == index_column:
            continue
        if original in display.columns:
            rename_columns[original] = new_name
    if "_category_tag" in display.columns:
        rename_columns["_category_tag"] = rename_map.get("category", "åˆ†é‡")
    display = display.rename(columns=rename_columns)
    html_table = display.to_html(
        escape=False,
        classes=table_classes,
        border=0,
        na_rep="",
    )
    st.markdown(html_table, unsafe_allow_html=True)


def confidence_to_grade(is_correct: bool, confidence: int) -> int:
    confidence = max(0, min(100, confidence))
    if is_correct:
        if confidence >= 90:
            return 5
        if confidence >= 70:
            return 4
        if confidence >= 50:
            return 3
        return 2
    if confidence >= 70:
        return 1
    return 0


def get_offline_attempts_df() -> pd.DataFrame:
    records = st.session_state.get("offline_attempts", [])
    if not records:
        return pd.DataFrame()
    return pd.DataFrame(records)


def persist_offline_attempts(df: pd.DataFrame) -> None:
    if df.empty:
        return
    OFFLINE_EXPORT_DIR.mkdir(exist_ok=True)
    csv_path = OFFLINE_EXPORT_DIR / "attempts_latest.csv"
    df.to_csv(csv_path, index=False, encoding="utf-8-sig")
    parquet_path = OFFLINE_EXPORT_DIR / "attempts_latest.parquet"
    try:
        df.to_parquet(parquet_path, index=False)
        st.session_state["_offline_parquet_error"] = None
    except Exception as exc:
        st.session_state["_offline_parquet_error"] = str(exc)
        if parquet_path.exists():
            parquet_path.unlink()


def log_offline_attempt(entry: Dict[str, object]) -> None:
    attempts = st.session_state.setdefault("offline_attempts", [])
    attempts.append(entry)
    df = get_offline_attempts_df()
    persist_offline_attempts(df)


def render_offline_downloads(key_prefix: str) -> None:
    df = get_offline_attempts_df()
    if df.empty:
        return
    with st.expander("å­¦ç¿’çµæœãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", expanded=False):
        csv_buffer = io.StringIO()
        df.to_csv(csv_buffer, index=False)
        st.download_button(
            "CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv_buffer.getvalue(),
            file_name="takken_learning_log.csv",
            mime="text/csv",
            key=f"{key_prefix}_csv",
        )
        parquet_buffer = io.BytesIO()
        parquet_error = st.session_state.get("_offline_parquet_error")
        if parquet_error:
            st.warning(f"Parquetã®è‡ªå‹•ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {parquet_error}")
        try:
            parquet_buffer.seek(0)
            df.to_parquet(parquet_buffer, index=False)
            st.download_button(
                "Parquetã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=parquet_buffer.getvalue(),
                file_name="takken_learning_log.parquet",
                mime="application/octet-stream",
                key=f"{key_prefix}_parquet",
            )
        except Exception as exc:
            st.warning(f"Parquetã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")
        st.caption(f"ãƒ•ã‚¡ã‚¤ãƒ«ã¯ {OFFLINE_EXPORT_DIR.as_posix()} ã«ã‚‚è‡ªå‹•ä¿å­˜ã•ã‚Œã¾ã™ã€‚")


def get_review_candidate_ids(db: DBManager) -> Set[str]:
    review_ids: Set[str] = set()
    attempts = db.get_attempt_stats()
    if not attempts.empty:
        attempts["created_at"] = pd.to_datetime(attempts["created_at"])
        last_attempts = (
            attempts.sort_values("created_at").groupby("question_id", as_index=False).tail(1)
        )
        review_ids.update(last_attempts[last_attempts["is_correct"] == 0]["question_id"].tolist())
        low_conf = int(st.session_state["settings"].get("review_low_confidence_threshold", 60))
        if "confidence" in last_attempts.columns:
            confidence_series = last_attempts["confidence"].fillna(101)
            review_ids.update(
                last_attempts[confidence_series <= low_conf]["question_id"].tolist()
            )
        days_threshold = int(st.session_state["settings"].get("review_elapsed_days", 7))
        cutoff = dt.datetime.now() - dt.timedelta(days=days_threshold)
        review_ids.update(
            last_attempts[last_attempts["created_at"] <= cutoff]["question_id"].tolist()
        )
    srs_due = db.get_due_srs()
    if not srs_due.empty:
        review_ids.update(srs_due["question_id"].tolist())
    return {str(qid) for qid in review_ids if pd.notna(qid)}


def parse_explanation_sections(text: str) -> Tuple[str, List[Tuple[str, str]]]:
    if not text:
        return "", []
    lines = [line.strip() for line in str(text).splitlines() if line.strip()]
    sections: List[Tuple[str, str]] = []
    summary = ""
    for line in lines:
        match = re.match(r"^ã€([^ã€‘]+)ã€‘(.*)$", line)
        if match:
            label = match.group(1).strip()
            content = match.group(2).strip()
        else:
            label = "è£œè¶³"
            content = line.strip()
        sections.append((label, content))
        if not summary and label in ("è¦ç‚¹", "çµè«–") and content:
            summary = content
    if not summary and lines:
        summary = lines[0]
    summary = summary.strip()
    if len(summary) > 80:
        summary = summary[:77] + "â€¦"
    return summary, sections


def normalize_law_reference_label(value: object) -> Optional[str]:
    if not isinstance(value, str):
        return None
    text = value.strip()
    if not text:
        return None
    text = text.replace("ã€€", " ")
    text = re.sub(r"\s+", " ", text)
    text = text.strip("ã€,.;:ï¼š")
    match = LAW_NAME_PATTERN.search(text)
    candidate: Optional[str] = None
    if match:
        candidate = match.group("law")
    else:
        for keyword in LAW_NAME_KEYWORDS:
            if keyword in text:
                candidate = keyword
                break
        if candidate is None:
            for suffix in LAW_NAME_SUFFIXES:
                if text.endswith(suffix):
                    candidate = text
                    break
    if not candidate:
        return None
    candidate = candidate.replace("ã€€", " ").strip()
    return candidate


def parse_reference_list(value: object) -> List[Dict[str, str]]:
    if isinstance(value, list):
        return [ref for ref in value if isinstance(ref, dict)]
    if isinstance(value, str):
        try:
            parsed = json.loads(value)
        except json.JSONDecodeError:
            return []
        if isinstance(parsed, list):
            return [ref for ref in parsed if isinstance(ref, dict)]
    return []


def collect_law_reference_terms(
    row: pd.Series, analyzer: Optional[LawRevisionAnalyzer] = None
) -> List[str]:
    analyzer = analyzer or get_law_revision_analyzer()
    candidates: List[str] = []

    def append_candidate(value: object) -> None:
        if value is None:
            return
        if isinstance(value, (list, tuple, set)):
            for item in value:
                append_candidate(item)
            return
        text = str(value).strip()
        if not text:
            return
        tokens = [tok.strip() for tok in re.split(r"[;ï¼/,ã€]+", text) if tok.strip()]
        if not tokens:
            tokens = [text]
        for token in tokens:
            if token:
                candidates.append(token)
                parts = [part.strip() for part in re.split(r"\s+", token) if part.strip()]
                for part in parts:
                    if part != token:
                        candidates.append(part)

    tags_value = row.get("tags")
    append_candidate(tags_value)
    append_candidate(row.get("topic"))
    append_candidate(row.get("category"))
    append_candidate(row.get("law_name"))

    question_text = str(row.get("question", "") or "")
    append_candidate(question_text)
    if question_text:
        append_candidate(LAW_NAME_PATTERN.findall(question_text))

    if isinstance(tags_value, str):
        append_candidate(LAW_NAME_PATTERN.findall(tags_value))

    combined_parts: List[str] = []
    if question_text:
        combined_parts.append(question_text)
    if isinstance(tags_value, str):
        combined_parts.append(tags_value.replace(";", " "))
    combined_text = " ".join(part for part in combined_parts if part).strip()
    if combined_text:
        keywords = analyzer.extract_keywords(combined_text, limit=8)
        append_candidate(keywords)

    normalized: List[str] = []
    seen: Set[str] = set()
    for raw in candidates:
        normalized_label = normalize_law_reference_label(raw)
        if not normalized_label:
            continue
        if normalized_label in seen:
            continue
        seen.add(normalized_label)
        normalized.append(normalized_label)
    return normalized


def get_outline_insight(row: pd.Series) -> Dict[str, object]:
    cache: Dict[str, Dict[str, object]] = st.session_state.setdefault(OUTLINE_CACHE_KEY, {})
    question_id = str(row.get("id", "") or "")
    if question_id and question_id in cache:
        return cache[question_id]
    analyzer = get_law_revision_analyzer()
    question_text = str(row.get("question", "") or "")
    tags_text = str(row.get("tags", "") or "")
    combined = " ".join(
        part for part in [question_text, tags_text.replace(";", " ")] if part.strip()
    ).strip()
    summary = ""
    if combined:
        summary = analyzer.summarize(combined, max_sentences=2)
    if not summary:
        explanation = row.get("explanation")
        if pd.notna(explanation):
            explanation_summary, _ = parse_explanation_sections(str(explanation))
            summary = explanation_summary
    summary = (summary or "").strip()
    if len(summary) > 120:
        summary = summary[:117] + "â€¦"
    law_terms = collect_law_reference_terms(row, analyzer=analyzer)
    references = [
        {
            "label": term,
            "url": LAW_REFERENCE_BASE_URL.format(query=quote_plus(term)),
        }
        for term in law_terms
    ]
    insight = {"summary": summary, "terms": law_terms, "references": references}
    if question_id:
        cache[question_id] = insight
    return insight


def render_explanation_content(row: pd.Series, db: Optional[DBManager] = None) -> None:
    explanation = row.get("explanation", "")
    explanation_summary, sections = parse_explanation_sections(explanation)
    outline = get_outline_insight(row)
    outline_summary = outline.get("summary") or explanation_summary
    references: List[Dict[str, str]] = outline.get("references", [])  # type: ignore[arg-type]

    if outline_summary or references:
        st.markdown("##### ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã‚µãƒãƒªãƒ¼")
        if outline_summary:
            st.write(outline_summary)
        else:
            st.caption("è¦ç´„ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        if references:
            st.markdown("###### é–¢é€£æ¡æ–‡å€™è£œ")
            for ref in references:
                label = ref.get("label")
                url = ref.get("url")
                if not label or not url:
                    continue
                st.markdown(f"- [{label}]({url})")

    saved_notes_df = pd.DataFrame()
    if db is not None:
        question_id = str(row.get("id", "") or "")
        label_value = str(row.get("label", "") or "").strip()
        if not label_value:
            year_display = format_year_value(row.get("year"))
            q_no_display = format_qno_value(row.get("q_no"))
            if year_display and q_no_display:
                label_value = f"{year_display} å•{q_no_display}"
            elif year_display:
                label_value = year_display
            elif q_no_display:
                label_value = f"å•{q_no_display}"
            else:
                label_value = question_id
        tags_value = str(row.get("tags") or "") or None
        can_save = bool(outline_summary or references)
        if st.button(
            "ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«ä¿å­˜",
            key=f"outline_save_{question_id}",
            disabled=not can_save,
            help="ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã¨é–¢é€£ãƒªãƒ³ã‚¯ã‚’ãƒãƒ¼ãƒˆã¨ã—ã¦ä¿å­˜ã—ã€å­¦ç¿’ãƒ­ã‚°ã¨ã‚ã‚ã›ã¦æŒ¯ã‚Šè¿”ã‚Œã¾ã™ã€‚"
            if can_save
            else "ä¿å­˜ã™ã‚‹å†…å®¹ãŒã‚ã‚Šã¾ã›ã‚“ã€‚",
        ):
            summary_to_save = outline_summary or explanation_summary or "è¦ç´„ãªã—"
            db.save_outline_note(
                question_id=question_id,
                summary=summary_to_save,
                references=references,
                question_label=label_value,
                tags=tags_value,
            )
            st.success("ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
        if question_id:
            saved_notes_df = db.fetch_outline_notes(question_id)
        if not saved_notes_df.empty:
            with st.expander("ä¿å­˜æ¸ˆã¿ãƒãƒ¼ãƒˆ", expanded=False):
                for _, note in saved_notes_df.iterrows():
                    note_summary = str(note.get("summary", "") or "")
                    updated_at = note.get("updated_at")
                    timestamp = ""
                    if pd.notna(updated_at):
                        try:
                            timestamp = pd.to_datetime(updated_at).strftime("%Y-%m-%d %H:%M")
                        except Exception:
                            timestamp = str(updated_at)
                    st.markdown(f"**{note_summary}**")
                    if timestamp:
                        st.caption(f"æ›´æ–°: {timestamp}")
                    note_refs = parse_reference_list(note.get("law_references"))
                    links = [
                        f"[{ref.get('label', '')}]({ref.get('url', '')})"
                        for ref in note_refs
                        if ref.get("label") and ref.get("url")
                    ]
                    if links:
                        st.caption(f"é–¢é€£: {' / '.join(links)}")
                    note_tags = str(note.get("tags", "") or "").strip()
                    if note_tags:
                        st.caption(f"ã‚¿ã‚°: {note_tags}")

    if not explanation:
        st.write("è§£èª¬ãŒæœªç™»éŒ²ã§ã™ã€‚ã€è¨­å®š ï¼ ãƒ‡ãƒ¼ã‚¿å…¥å‡ºåŠ›ã€ã‹ã‚‰è§£ç­”ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šè¾¼ã¿ã¾ã—ã‚‡ã†ã€‚")
        return

    st.markdown(f"**è¦ç‚¹ç‰ˆ**ï¼š{explanation_summary}")
    with st.expander("è©³ç´°è§£èª¬ã‚’ã²ã‚‰ã", expanded=False):
        for label, content in sections:
            if not content:
                continue
            if label == "ãƒŸãƒ‹å›³":
                st.markdown(f"**{label}**")
                st.markdown(content, unsafe_allow_html=True)
            else:
                st.markdown(f"- **{label}**ï¼š{content}")
        similar = compute_similarity(row["id"])
        if not similar.empty:
            st.markdown("#### é¡ä¼¼å•é¡Œ")
            st.dataframe(similar, use_container_width=True)
            questions_df = load_questions_df()
            similar_ids = [qid for qid in similar["id"] if pd.notna(qid)]
            if similar_ids:
                selected_similar_id = st.selectbox(
                    "é¡ä¼¼å•é¡Œã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼",
                    similar_ids,
                    format_func=lambda x: format_question_label(questions_df, x),
                    key=f"similar_preview_{row['id']}",
                )
                preview_row = questions_df[questions_df["id"] == selected_similar_id]
                if preview_row.empty:
                    st.info("é¸æŠã—ãŸå•é¡ŒãŒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                else:
                    render_question_preview(preview_row.iloc[0], db=db)


def estimate_theta(attempts: pd.DataFrame, df: pd.DataFrame) -> Optional[float]:
    if attempts.empty:
        return None
    merged = attempts.merge(
        df[["id", "difficulty"]], left_on="question_id", right_on="id", how="left"
    )
    merged = merged.dropna(subset=["difficulty"])
    if merged.empty:
        return None
    difficulties = (merged["difficulty"].astype(float) - 3.0) * 0.7
    responses = merged["is_correct"].astype(float)
    theta = 0.0
    for _ in range(10):
        logits = theta - difficulties
        probs = 1.0 / (1.0 + np.exp(-logits))
        gradient = np.sum(responses - probs)
        hessian = -np.sum(probs * (1 - probs))
        if abs(hessian) < 1e-6:
            break
        theta -= gradient / hessian
        if abs(gradient) < 1e-4:
            break
    return float(theta)


def recommend_adaptive_questions(
    df: pd.DataFrame,
    attempts: pd.DataFrame,
    theta: float,
    limit: int = 10,
    low_conf_threshold: int = 70,
) -> pd.DataFrame:
    candidates = df.copy()
    candidates["difficulty"] = candidates["difficulty"].fillna(DIFFICULTY_DEFAULT)
    candidates["difficulty_scaled"] = (candidates["difficulty"].astype(float) - 3.0) * 0.7
    candidates["priority"] = np.where(
        candidates["difficulty_scaled"] >= theta,
        candidates["difficulty_scaled"] - theta,
        (theta - candidates["difficulty_scaled"]) * 1.5,
    )
    if not attempts.empty:
        attempts["created_at"] = pd.to_datetime(attempts["created_at"])
        last_attempts = attempts.sort_values("created_at").groupby("question_id").tail(1)
        if "confidence" in last_attempts:
            confidence_series = last_attempts["confidence"].fillna(0)
        else:
            confidence_series = pd.Series(0, index=last_attempts.index)
        mastered_ids = last_attempts[
            (last_attempts["is_correct"] == 1)
            & (confidence_series >= low_conf_threshold)
        ]["question_id"].tolist()
        if mastered_ids:
            candidates = candidates[~candidates["id"].isin(mastered_ids)]
    ranked = candidates.sort_values(["priority", "difficulty"], ascending=[True, False])
    return ranked.head(limit)


def compute_tricky_vocab_heatmap(
    attempts: pd.DataFrame, df: pd.DataFrame, top_n: int = 12
) -> pd.DataFrame:
    wrong = attempts[attempts["is_correct"] == 0]
    if wrong.empty:
        return pd.DataFrame()
    merged = wrong.merge(
        df[["id", "question", "category", "tags"]],
        left_on="question_id",
        right_on="id",
        how="left",
    )
    records: List[Dict[str, object]] = []
    pattern = re.compile(r"[ä¸€-é¾ ã-ã‚“ã‚¡-ãƒ³A-Za-z0-9]{2,}")
    for _, row in merged.iterrows():
        text = f"{row.get('question', '')} {row.get('tags', '')}"
        words = {w for w in pattern.findall(str(text)) if len(w) >= 2}
        for word in list(words)[:20]:
            records.append({"word": word, "category": row.get("category", "æœªåˆ†é¡")})
    if not records:
        return pd.DataFrame()
    freq = pd.DataFrame(records)
    counts = freq.groupby(["word", "category"]).size().reset_index(name="count")
    totals = counts.groupby("word")["count"].sum().reset_index(name="total")
    top_words = totals.nlargest(top_n, "total")["word"]
    heatmap_df = counts[counts["word"].isin(top_words)]
    return heatmap_df


def compute_most_improved_topic(attempts: pd.DataFrame, df: pd.DataFrame) -> Optional[Dict[str, object]]:
    if "topic" not in df.columns:
        return None
    merged = attempts.merge(
        df[["id", "topic"]], left_on="question_id", right_on="id", how="left"
    )
    if "topic" not in merged.columns:
        return None
    merged = merged.dropna(subset=["topic"])
    if merged.empty:
        return None
    improvements: List[Dict[str, object]] = []
    for topic, group in merged.groupby("topic"):
        if len(group) < 4:
            continue
        group = group.sort_values("created_at")
        window = max(1, len(group) // 3)
        early = group.head(window)["is_correct"].mean()
        late = group.tail(window)["is_correct"].mean()
        improvements.append(
            {
                "topic": topic,
                "delta": late - early,
                "early": early,
                "late": late,
                "attempts": len(group),
            }
        )
    if not improvements:
        return None
    best = max(improvements, key=lambda x: x["delta"])
    if best["delta"] <= 0:
        return None
    return best


def build_notion_summaries(attempts: pd.DataFrame, days: int = 7) -> List[Dict[str, object]]:
    if attempts.empty:
        return []
    working = attempts.copy()
    working["created_at"] = pd.to_datetime(working["created_at"])
    cutoff = pd.Timestamp.utcnow() - pd.Timedelta(days=days)
    working = working[working["created_at"] >= cutoff]
    if working.empty:
        return []
    working["is_correct"] = working["is_correct"].fillna(0).astype(int)
    summary = (
        working
        .groupby(working["created_at"].dt.date)
        .agg(
            attempts=("question_id", "count"),
            correct=("is_correct", "sum"),
            avg_seconds=("seconds", "mean"),
        )
        .reset_index()
        .rename(columns={"created_at": "date"})
    )
    summary["accuracy"] = summary.apply(
        lambda row: (row["correct"] / row["attempts"]) if row["attempts"] else 0.0,
        axis=1,
    )
    summary["avg_seconds"] = summary["avg_seconds"].fillna(0.0)
    results: List[Dict[str, object]] = []
    for row in summary.itertuples(index=False):
        date_value = row.date if hasattr(row, "date") else row[0]
        if isinstance(date_value, dt.datetime):
            date_value = date_value.date()
        results.append(
            {
                "date": date_value,
                "attempts": int(row.attempts),
                "accuracy": float(row.accuracy),
                "avg_seconds": float(row.avg_seconds),
            }
        )
    return results


def parse_external_attempt_logs(
    file: "UploadedFile", questions_df: pd.DataFrame
) -> Tuple[List[Dict[str, object]], List[str]]:
    suffix = Path(file.name).suffix.lower()
    raw_bytes = file.getvalue()
    errors: List[str] = []
    if not raw_bytes:
        return [], [f"{file.name}: ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™ã€‚"]
    try:
        decoded = raw_bytes.decode("utf-8")
    except UnicodeDecodeError:
        try:
            decoded = raw_bytes.decode("utf-8-sig")
        except UnicodeDecodeError:
            return [], [f"{file.name}: UTF-8ã§ãƒ‡ã‚³ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"]
    if suffix == ".csv":
        data_df = pd.read_csv(io.StringIO(decoded))
    elif suffix == ".json":
        try:
            payload = json.loads(decoded)
        except json.JSONDecodeError as exc:
            return [], [f"{file.name}: JSONã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ ({exc})"]
        if isinstance(payload, dict):
            if "records" in payload and isinstance(payload["records"], list):
                payload = payload["records"]
            elif "data" in payload and isinstance(payload["data"], list):
                payload = payload["data"]
            else:
                payload = [payload]
        data_df = pd.DataFrame(payload)
    else:
        return [], [f"{file.name}: å¯¾å¿œã—ã¦ã„ãªã„å½¢å¼ã§ã™ã€‚CSVã¾ãŸã¯JSONã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"]
    if data_df.empty:
        return [], [f"{file.name}: å–ã‚Šè¾¼ã¿å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"]
    normalized_columns = {col.lower(): col for col in data_df.columns}
    if "seconds" not in normalized_columns:
        return [], [f"{file.name}: seconds åˆ—ãŒå¿…è¦ã§ã™ã€‚"]
    seconds_col = normalized_columns["seconds"]
    question_id_col = normalized_columns.get("question_id")
    timestamp_col = normalized_columns.get("timestamp") or normalized_columns.get("created_at")
    year_col = normalized_columns.get("year")
    qno_col = normalized_columns.get("q_no") or normalized_columns.get("qno")
    topic_col = normalized_columns.get("topic")
    mode_col = normalized_columns.get("mode")
    selected_col = normalized_columns.get("selected")
    correct_col = normalized_columns.get("is_correct")
    confidence_col = normalized_columns.get("confidence")
    grade_col = normalized_columns.get("grade")

    resolved: List[Dict[str, object]] = []
    question_index = questions_df.set_index("id") if "id" in questions_df.columns else pd.DataFrame()
    for idx, row in data_df.iterrows():
        question_id = None
        if question_id_col and pd.notna(row.get(question_id_col)):
            candidate = str(row.get(question_id_col)).strip()
            if not question_index.empty and candidate in question_index.index:
                question_id = candidate
        if not question_id and year_col and qno_col and pd.notna(row.get(year_col)) and pd.notna(row.get(qno_col)):
            try:
                year_val = int(row.get(year_col))
                qno_val = int(row.get(qno_col))
            except (TypeError, ValueError):
                year_val = qno_val = None
            if year_val is not None and qno_val is not None:
                matches = questions_df[
                    (questions_df["year"] == year_val) & (questions_df["q_no"] == qno_val)
                ]
                if not matches.empty:
                    question_id = matches.iloc[0]["id"]
        if not question_id and topic_col and pd.notna(row.get(topic_col)):
            topic_val = str(row.get(topic_col)).strip()
            matches = questions_df[questions_df["topic"] == topic_val]
            if not matches.empty:
                question_id = matches.iloc[0]["id"]
        if not question_id:
            errors.append(f"{file.name} è¡Œ{idx + 1}: å¯¾å¿œã™ã‚‹å•é¡ŒIDã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            continue
        try:
            seconds = int(float(row.get(seconds_col, 0)))
        except (TypeError, ValueError):
            errors.append(f"{file.name} è¡Œ{idx + 1}: seconds åˆ—ãŒæ•°å€¤ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            continue
        timestamp_value = row.get(timestamp_col) if timestamp_col else None
        if pd.notna(timestamp_value):
            try:
                created_at = pd.to_datetime(timestamp_value)
            except Exception:
                created_at = pd.Timestamp.utcnow()
        else:
            created_at = pd.Timestamp.utcnow()
        payload: Dict[str, object] = {
            "question_id": question_id,
            "seconds": seconds,
            "mode": str(row.get(mode_col, "external_log")) if mode_col else "external_log",
            "created_at": created_at.to_pydatetime() if hasattr(created_at, "to_pydatetime") else created_at,
        }
        if selected_col and pd.notna(row.get(selected_col)):
            try:
                payload["selected"] = int(row.get(selected_col))
            except (TypeError, ValueError):
                payload["selected"] = None
        if correct_col and pd.notna(row.get(correct_col)):
            value = row.get(correct_col)
            try:
                payload["is_correct"] = int(bool(int(value)))
            except (TypeError, ValueError):
                payload["is_correct"] = None
        if confidence_col and pd.notna(row.get(confidence_col)):
            try:
                payload["confidence"] = int(float(row.get(confidence_col)))
            except (TypeError, ValueError):
                payload["confidence"] = None
        if grade_col and pd.notna(row.get(grade_col)):
            try:
                payload["grade"] = int(float(row.get(grade_col)))
            except (TypeError, ValueError):
                payload["grade"] = None
        resolved.append(payload)
    return resolved, errors


def register_keyboard_shortcuts(mapping: Dict[str, str]) -> None:
    if not mapping:
        return
    st_html(
        """
        <script>
        (function() {
            const mapping = %s;
            document.addEventListener('keydown', function(event) {
                const active = document.activeElement;
                if (active && ['input', 'textarea', 'select'].includes(active.tagName.toLowerCase())) {
                    return;
                }
                const key = event.key ? event.key.toLowerCase() : '';
                const label = mapping[key];
                if (!label) {
                    return;
                }
                const doc = window.parent ? window.parent.document : document;
                const buttons = doc.querySelectorAll('button');
                for (const btn of buttons) {
                    if (!btn.innerText) {
                        continue;
                    }
                    if (btn.innerText.trim().startsWith(label.trim())) {
                        event.preventDefault();
                        btn.click();
                        break;
                    }
                }
            }, true);
        })();
        </script>
        """ % json.dumps({k.lower(): v for k, v in mapping.items()}, ensure_ascii=False),
        height=0,
    )
def decode_uploaded_file(file: "UploadedFile") -> List[Tuple[str, pd.DataFrame]]:
    filename = file.name
    suffix = Path(filename).suffix.lower()
    dataframes = []
    bytes_data = file.getvalue()
    if suffix == ".zip":
        with zipfile.ZipFile(io.BytesIO(bytes_data)) as z:
            for inner in z.infolist():
                if inner.is_dir():
                    continue
                inner_suffix = Path(inner.filename).suffix.lower()
                with z.open(inner) as f:
                    df = read_tabular(f.read(), inner_suffix)
                    dataframes.append((inner.filename, df))
    else:
        df = read_tabular(bytes_data, suffix)
        dataframes.append((filename, df))
    return dataframes


def read_tabular(data: bytes, suffix: str) -> pd.DataFrame:
    encoding_options = ["utf-8", "cp932"]
    if suffix in [".csv", ".txt", ".tsv", ""]:
        for enc in encoding_options:
            try:
                return pd.read_csv(io.BytesIO(data), encoding=enc)
            except Exception:
                continue
        return pd.read_csv(io.BytesIO(data))
    elif suffix in [".xlsx", ".xlsm", ".xls"]:
        return pd.read_excel(io.BytesIO(data))
    else:
        raise ValueError("ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™")


def guess_dataset_kind(df: pd.DataFrame) -> str:
    cols = set(df.columns.str.lower())
    if {"choice1", "choice2", "choice3", "choice4"}.issubset(cols):
        return MAPPING_KIND_QUESTIONS
    if "correct_number" in cols or "correct_label" in cols or "correct_text" in cols:
        return MAPPING_KIND_ANSWERS
    return MAPPING_KIND_QUESTIONS


def describe_dataset_name(raw_name: str) -> Tuple[str, Optional[str]]:
    base_name = Path(raw_name).name
    stem = Path(base_name).stem or base_name
    suffix = Path(base_name).suffix.lower()
    normalized = stem.strip() or base_name
    lower = normalized.lower()
    name_map = {
        "questions": "è¨­å•ãƒ‡ãƒ¼ã‚¿",
        "answers": "æ­£ç­”ãƒ‡ãƒ¼ã‚¿",
        "predicted": "äºˆæƒ³å•é¡Œãƒ‡ãƒ¼ã‚¿",
        "law_revision": "æ³•æ”¹æ­£äºˆæƒ³å•é¡Œãƒ‡ãƒ¼ã‚¿",
    }
    if lower in name_map:
        return name_map[lower], base_name
    hint: Optional[str] = None
    if suffix in {".csv", ".tsv", ".txt"}:
        hint = "CSVãƒ‡ãƒ¼ã‚¿"
    elif suffix in {".xlsx", ".xls", ".xlsm"}:
        hint = "Excelã‚·ãƒ¼ãƒˆ"
    elif any(keyword in normalized for keyword in ["ãƒ†ãƒ¼ãƒ–ãƒ«", "table", "Table"]):
        hint = "è¡¨ãƒ‡ãƒ¼ã‚¿"
    elif any(keyword in normalized for keyword in ["ã‚°ãƒ©ãƒ•", "chart", "Chart"]):
        hint = "ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿"
    if hint:
        return f"{normalized}ï¼ˆ{hint}ï¼‰", base_name
    return normalized, base_name if normalized != base_name else None


def store_uploaded_file(file: "UploadedFile", timestamp: str) -> Path:
    target_dir = UPLOAD_DIR / timestamp
    target_dir.mkdir(parents=True, exist_ok=True)
    path = target_dir / file.name
    with open(path, "wb") as f:
        f.write(file.getbuffer())
    return path


def init_session_state() -> None:
    defaults = {
        "nav": "ãƒ›ãƒ¼ãƒ ",
        "current_question": None,
        "attempt_start": None,
        "exam_session": None,
        "import_state": {},
        "settings": {
            "shuffle_choices": True,
            "theme": "ã‚»ãƒ”ã‚¢",
            "font_size": "æ¨™æº–",
            "timer": True,
            "sm2_initial_ease": 2.5,
            "auto_advance": False,
            "review_low_confidence_threshold": 60,
            "review_elapsed_days": 7,
            "integrations": {
                "google_calendar": {
                    "client_id": "",
                    "client_secret": "",
                    "redirect_uri": "",
                    "access_token": "",
                    "refresh_token": "",
                    "calendar_id": "primary",
                },
                "notion": {
                    "integration_token": "",
                    "database_id": "",
                    "notion_version": "2022-06-28",
                },
            },
        },
        "_nav_widget": "ãƒ›ãƒ¼ãƒ ",
        "integration_status": {
            "google_calendar": {
                "last_synced": None,
                "message": "æœªåŒæœŸ",
                "success": False,
            },
            "notion": {
                "last_synced": None,
                "message": "æœªåŒæœŸ",
                "success": False,
            },
        },
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value


def main() -> None:
    st.set_page_config(page_title="å®…å»º10å¹´ãƒ‰ãƒªãƒ«", layout="wide")
    init_session_state()
    apply_user_preferences()
    engine = get_engine()
    db = DBManager(engine)
    db.initialize_from_csv()
    df = load_questions_df()

    sidebar = st.sidebar
    sidebar.title("å®…å»º10å¹´ãƒ‰ãƒªãƒ«")
    if st.session_state.get("_nav_widget") != st.session_state.get("nav"):
        st.session_state["_nav_widget"] = st.session_state.get("nav", "ãƒ›ãƒ¼ãƒ ")
    menu_options = ["ãƒ›ãƒ¼ãƒ ", "å­¦ç¿’", "æ¨¡è©¦", "çµ±è¨ˆ", "è¨­å®š"]
    current_nav = st.session_state.get("nav", "ãƒ›ãƒ¼ãƒ ")
    if current_nav not in menu_options:
        current_nav = "ãƒ›ãƒ¼ãƒ "
        st.session_state["nav"] = current_nav
        st.session_state["_nav_widget"] = current_nav
    sidebar.radio(
        "ãƒ¡ãƒ‹ãƒ¥ãƒ¼",
        menu_options,
        index=menu_options.index(current_nav),
        key="_nav_widget",
        on_change=with_rerun(handle_nav_change),
    )
    nav = st.session_state.get("nav", "ãƒ›ãƒ¼ãƒ ")
    sidebar.divider()
    with sidebar.expander("ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰", expanded=False):
        st.markdown(
            "\n".join(
                [
                    "- **ãƒ›ãƒ¼ãƒ **ï¼šé€²æ—ã‚µãƒãƒªãƒ¼ã¨æœ€è¿‘ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå±¥æ­´ã‚’ç¢ºèªã§ãã¾ã™ã€‚",
                    "- **å­¦ç¿’**ï¼šæ¼”ç¿’ãƒ—ãƒ©ãƒ³ãƒ»ç‰¹åˆ¥å¯¾ç­–ãƒ»å¼±ç‚¹ã‚±ã‚¢ã®ã‚¿ãƒ–ã‹ã‚‰ç›®çš„ã«å¿œã˜ã¦å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¾ã™ã€‚",
                    "- **æ¨¡è©¦**ï¼šå¹´åº¦ã‚„å‡ºé¡Œæ–¹å¼ã‚’æŒ‡å®šã—ã¦æœ¬ç•ªåŒæ§˜ã®æ¨¡è©¦ã‚’é–‹å§‹ã—ã¾ã™ã€‚",
                    "- **çµ±è¨ˆ**ï¼šåˆ†é‡åˆ¥ã®æˆç¸¾ã‚„æ™‚é–“åˆ†æã‚’æŠŠæ¡ã§ãã¾ã™ã€‚",
                    "- **è¨­å®š**ï¼šè¡¨ç¤ºè¨­å®šã®èª¿æ•´ã¨ã€è¨­å®š ï¼ ãƒ‡ãƒ¼ã‚¿å…¥å‡ºåŠ›ã€ã‚¿ãƒ–ã§ã®CSV/ZIPå–ã‚Šè¾¼ã¿ã‚’ã¾ã¨ã‚ã¦ã„ã¾ã™ã€‚",
                ]
            )
        )

    if nav == "ãƒ›ãƒ¼ãƒ ":
        render_home(db, df)
    elif nav == "å­¦ç¿’":
        render_learning(db, df)
    elif nav == "æ¨¡è©¦":
        render_mock_exam(db, df)
    elif nav == "çµ±è¨ˆ":
        render_stats(db, df)
    elif nav == "è¨­å®š":
        render_settings(db)


def render_home(db: DBManager, df: pd.DataFrame) -> None:
    st.markdown(
        """
        <style>
        .home-dropzone-card {
            background: rgba(64, 138, 255, 0.08);
            border: 1px dashed rgba(64, 138, 255, 0.35);
            border-radius: 1rem;
            padding: 1.25rem 1.5rem;
            margin-bottom: 1.2rem;
        }
        .home-dropzone-card strong {
            display: block;
            font-size: 1.05rem;
            margin-bottom: 0.25rem;
        }
        .home-data-card {
            background: rgba(0, 0, 0, 0.03);
            border: 1px solid rgba(49, 51, 63, 0.08);
            border-radius: 0.9rem;
            padding: 1.2rem 1.4rem;
            margin-bottom: 1.5rem;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )

    st.title("ãƒ›ãƒ¼ãƒ ")
    dropzone_files = st.file_uploader(
        "questions.csv / answers.csv ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—",
        type=["csv"],
        accept_multiple_files=True,
        key="home_dropzone",
        label_visibility="collapsed",
        help="ãƒšãƒ¼ã‚¸å…¨ä½“ãŒãƒ‰ãƒ­ãƒƒãƒ—ã‚¾ãƒ¼ãƒ³ã¨ã—ã¦æ©Ÿèƒ½ã—ã¾ã™ã€‚questions.csv ã¨ answers.csv ã‚’ã¾ã¨ã‚ã¦è¿½åŠ ã§ãã¾ã™ã€‚",
    )
    st.markdown(
        """
        <div class="home-dropzone-card">
            <strong>CSVã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—</strong>
            ãƒšãƒ¼ã‚¸å…¨ä½“ãŒãƒ‰ãƒ­ãƒƒãƒ—ã‚¾ãƒ¼ãƒ³ã¨ã—ã¦æ©Ÿèƒ½ã—ã¾ã™ã€‚ã“ã“ã«è¿½åŠ ã—ãŸ questions.csv / answers.csv ã¯ä¸‹ã®ã‚¯ã‚¤ãƒƒã‚¯ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«è‡ªå‹•ã§åæ˜ ã•ã‚Œã¾ã™ã€‚
        </div>
        """,
        unsafe_allow_html=True,
    )

    attempts = db.get_attempt_stats()
    st.markdown("### ã‚µãƒãƒªãƒ¼")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("è¨­å•æ•°", len(df))
    with col2:
        st.metric("å­¦ç¿’å±¥æ­´", len(attempts))
    with col3:
        coverage = attempts["year"].nunique() / max(df["year"].nunique(), 1) * 100 if not attempts.empty else 0
        st.metric("å¹´åº¦ã‚«ãƒãƒ¬ãƒƒã‚¸", f"{coverage:.0f}%")

    st.markdown(
        """
        <div class="home-data-card">
            <strong>ãƒ‡ãƒ¼ã‚¿ã®å–ã‚Šè¾¼ã¿ã«ã¤ã„ã¦</strong><br>
            ä¸Šéƒ¨ã®ãƒ‰ãƒ­ãƒƒãƒ—ã‚¾ãƒ¼ãƒ³ã« CSV ã‚’é…ç½®ã™ã‚‹ã¨ã€ã“ã®ãƒšãƒ¼ã‚¸ã®ã€Œãƒ‡ãƒ¼ã‚¿å…¥å‡ºåŠ›ã€ã§å³åº§ã«ã‚¯ã‚¤ãƒƒã‚¯ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã¾ã™ã€‚åˆ—ãƒãƒƒãƒ”ãƒ³ã‚°ã‚„è©³ç´°è¨­å®šã¯ã€è¨­å®š ï¼ ãƒ‡ãƒ¼ã‚¿å…¥å‡ºåŠ›ã€ã§å¾“æ¥é€šã‚Šèª¿æ•´ã§ãã¾ã™ã€‚
        </div>
        """,
        unsafe_allow_html=True,
    )

    st.markdown("### ãƒ‡ãƒ¼ã‚¿å…¥å‡ºåŠ›")
    st.caption("questions.csv / answers.csv ã®èª­ã¿è¾¼ã¿ã¨å­¦ç¿’å±¥æ­´ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚’ãƒ›ãƒ¼ãƒ ã‹ã‚‰ç›´æ¥æ“ä½œã§ãã¾ã™ã€‚")
    render_quick_import_controls(
        db,
        key_prefix="home",
        heading="#### ã‚¯ã‚¤ãƒƒã‚¯ã‚¤ãƒ³ãƒãƒ¼ãƒˆ (questions.csv / answers.csv)",
        initial_files=dropzone_files or None,
    )
    render_history_export_controls(
        db,
        heading="#### å­¦ç¿’å±¥æ­´ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ",
    )

    st.markdown("### æœ€è¿‘ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
    with db.engine.connect() as conn:
        logs = pd.read_sql(select(import_logs_table).order_by(import_logs_table.c.id.desc()).limit(5), conn)
    if logs.empty:
        st.write("ã‚¤ãƒ³ãƒãƒ¼ãƒˆå±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        st.dataframe(logs)


def render_learning(db: DBManager, df: pd.DataFrame) -> None:
    st.title("å­¦ç¿’")
    if df.empty:
        st.warning("è¨­å•ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã€è¨­å®š ï¼ ãƒ‡ãƒ¼ã‚¿å…¥å‡ºåŠ›ã€ã‹ã‚‰ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return
    primary_tabs = st.tabs(["æ¼”ç¿’ãƒ—ãƒ©ãƒ³", "ç‰¹åˆ¥å¯¾ç­–", "å¼±ç‚¹ã‚±ã‚¢"])
    with primary_tabs[0]:
        plan_tabs = st.tabs(["æœ¬è©¦é¨“ãƒ¢ãƒ¼ãƒ‰", "é©å¿œå­¦ç¿’", "åˆ†é‡åˆ¥ãƒ‰ãƒªãƒ«", "å¹´åº¦åˆ¥æ¼”ç¿’"])
        with plan_tabs[0]:
            render_full_exam_lane(db, df)
        with plan_tabs[1]:
            render_adaptive_lane(db, df)
        with plan_tabs[2]:
            render_subject_drill_lane(db, df)
        with plan_tabs[3]:
            render_year_drill_lane(db, df)
    with primary_tabs[1]:
        special_tabs = st.tabs(["æ³•æ”¹æ­£å¯¾ç­–", "äºˆæƒ³å•é¡Œæ¼”ç¿’"])
        with special_tabs[0]:
            render_law_revision_lane(db, parent_nav="å­¦ç¿’")
        with special_tabs[1]:
            render_predicted_lane(db, parent_nav="å­¦ç¿’")
    with primary_tabs[2]:
        review_tabs = st.tabs(["å¼±ç‚¹åˆ†æ", "SRSå¾©ç¿’"])
        with review_tabs[0]:
            render_weakness_lane(db, df)
        with review_tabs[1]:
            render_srs(db, parent_nav="å­¦ç¿’")
    st.divider()
    render_outline_notes_overview(db, df)


def render_full_exam_lane(db: DBManager, df: pd.DataFrame) -> None:
    st.subheader("æœ¬è©¦é¨“ãƒ¢ãƒ¼ãƒ‰")
    st.caption("50å•ãƒ»120åˆ†ã®æœ¬è©¦é¨“åŒç­‰ç’°å¢ƒã§å¾—ç‚¹åŠ›ã¨æ™‚é–“é…åˆ†ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚")
    if len(df) < 50:
        st.info("50å•ã®å‡ºé¡Œã«ã¯æœ€ä½50å•ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
        return
    attempts = db.get_attempt_stats()
    priority_df = build_question_priority(df, attempts)
    weight_map = dict(zip(priority_df["id"], priority_df["weight"]))
    if not attempts.empty:
        category_focus = (
            priority_df.groupby("category")["weight"].mean().sort_values(ascending=False)
        )
        if not category_focus.empty:
            highlights = [
                f"{category} (å„ªå…ˆåº¦ {score:.2f})"
                for category, score in category_focus.head(2).items()
            ]
            st.caption(
                "æœ€è¿‘ã®å¼±ç‚¹å‚¾å‘ã‚’è¸ã¾ãˆã€ä»¥ä¸‹ã®åˆ†é‡ãŒå„ªå…ˆçš„ã«å‡ºé¡Œã•ã‚Œã¾ã™: "
                + "ã€".join(highlights)
            )
    session: Optional[ExamSession] = st.session_state.get("exam_session")
    error_key = "_full_exam_error"
    error_message = st.session_state.pop(error_key, None)
    if error_message:
        st.warning(error_message)

    def start_full_exam_session() -> None:
        questions = stratified_exam(df, weight_map if weight_map else None)
        if not questions:
            st.session_state[error_key] = "å‡ºé¡Œå¯èƒ½ãªå•é¡ŒãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            return
        st.session_state.pop("exam_result_æœ¬è©¦é¨“ãƒ¢ãƒ¼ãƒ‰", None)
        st.session_state["exam_session"] = ExamSession(
            id=None,
            name=f"æœ¬è©¦é¨“ãƒ¢ãƒ¼ãƒ‰ {dt.datetime.now():%Y%m%d-%H%M}",
            questions=questions,
            started_at=dt.datetime.now(),
            year_mode="å±¤åŒ–ãƒ©ãƒ³ãƒ€ãƒ 50",
            mode="æœ¬è©¦é¨“ãƒ¢ãƒ¼ãƒ‰",
        )

    if session is None or session.mode != "æœ¬è©¦é¨“ãƒ¢ãƒ¼ãƒ‰":
        st.button(
            "50å•æ¨¡è©¦ã‚’é–‹å§‹",
            key="start_full_exam",
            help="æœ¬è©¦é¨“ã¨åŒã˜50å•ãƒ»120åˆ†æ§‹æˆã§ä¸€æ°—ã«æ¼”ç¿’ã—ã¾ã™ã€‚çµæœã¯çµ±è¨ˆã«åæ˜ ã•ã‚Œã¾ã™ã€‚",
            on_click=with_rerun(start_full_exam_session),
        )
    session = st.session_state.get("exam_session")
    if session and session.mode == "æœ¬è©¦é¨“ãƒ¢ãƒ¼ãƒ‰":
        render_exam_session_body(db, df, session, key_prefix="main_exam")
    result = st.session_state.get("exam_result_æœ¬è©¦é¨“ãƒ¢ãƒ¼ãƒ‰")
    if result:
        display_exam_result(result)


def render_outline_notes_overview(db: DBManager, df: pd.DataFrame) -> None:
    st.subheader("ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
    notes_df = db.fetch_outline_notes()
    if notes_df.empty:
        st.info("ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¯ã¾ã ä¿å­˜ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è§£èª¬ç”»é¢ã®ä¿å­˜ãƒœã‚¿ãƒ³ã‹ã‚‰ä½œæˆã§ãã¾ã™ã€‚")
        return
    notes_df = notes_df.copy()
    notes_df["updated_at"] = pd.to_datetime(notes_df.get("updated_at"), errors="coerce")
    attempts = db.get_attempt_stats()
    if not attempts.empty and "question_id" in attempts.columns:
        attempt_counts = attempts.groupby("question_id").size().rename("attempts")
        notes_df = notes_df.merge(
            attempt_counts,
            left_on="question_id",
            right_index=True,
            how="left",
        )
    else:
        notes_df["attempts"] = 0
    notes_df["attempts"] = notes_df["attempts"].fillna(0).astype(int)
    meta_cols = ["id", "year", "q_no", "category", "topic"]
    available_meta = [col for col in meta_cols if col in df.columns]
    if available_meta:
        metadata = df[available_meta].copy()
        metadata = metadata.rename(columns={"id": "question_id"})
        notes_df = notes_df.merge(metadata, on="question_id", how="left")
    for missing in ["year", "q_no", "category", "topic"]:
        if missing not in notes_df.columns:
            notes_df[missing] = pd.NA
    notes_df["links_display"] = notes_df["law_references"].apply(
        lambda value: " / ".join(
            ref.get("label", "")
            for ref in parse_reference_list(value)
            if ref.get("label")
        )
    )
    notes_df = notes_df.sort_values("updated_at", ascending=False)
    notes_df["updated_at_display"] = notes_df["updated_at"].dt.strftime("%Y-%m-%d %H:%M")
    display_columns = {
        "question_id": "è¨­å•ID",
        "year": "å¹´åº¦",
        "q_no": "å•ç•ªå·",
        "category": "åˆ†é‡",
        "topic": "è«–ç‚¹",
        "summary": "è¦ç´„",
        "links_display": "é–¢é€£ãƒªãƒ³ã‚¯",
        "attempts": "å­¦ç¿’å›æ•°",
        "updated_at_display": "æ›´æ–°æ—¥æ™‚",
    }
    display_df = notes_df[list(display_columns.keys())].rename(columns=display_columns)
    st.dataframe(display_df, use_container_width=True)
    st.caption("å­¦ç¿’å±¥æ­´ã®å–ã‚Šçµ„ã¿å›æ•°ã‚’ä½µè¨˜ã—ã¦ã„ã¾ã™ã€‚ãƒãƒ¼ãƒˆã¨ãƒ­ã‚°ã®æ•´åˆã‚’ç¢ºèªã§ãã¾ã™ã€‚")
    export_df = notes_df.copy()
    export_df["law_references"] = export_df["law_references"].apply(
        lambda value: json.dumps(parse_reference_list(value), ensure_ascii=False)
    )
    export_df["updated_at"] = export_df["updated_at"].dt.strftime("%Y-%m-%d %H:%M:%S")
    buffer = io.StringIO()
    export_df.to_csv(buffer, index=False)
    st.download_button(
        "ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ",
        data=buffer.getvalue(),
        file_name="outline_notes.csv",
        mime="text/csv",
    )


def render_adaptive_lane(db: DBManager, df: pd.DataFrame) -> None:
    st.subheader("é©å¿œå­¦ç¿’")
    st.caption("å›ç­”å±¥æ­´ã‹ã‚‰èƒ½åŠ›Î¸ã‚’æ¨å®šã—ã€ä¼¸ã³ã—ã‚ã®å¤§ãã„é›£åº¦ã‚’å„ªå…ˆå‡ºé¡Œã—ã¾ã™ã€‚")
    attempts = db.get_attempt_stats()
    if attempts.empty:
        st.info("å­¦ç¿’å±¥æ­´ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚æœ¬è©¦é¨“ãƒ¢ãƒ¼ãƒ‰ã‚„ãƒ‰ãƒªãƒ«ã§å–ã‚Šçµ„ã‚“ã§ã¿ã¾ã—ã‚‡ã†ã€‚")
        return
    theta = estimate_theta(attempts, df)
    if theta is None:
        st.info("æ¨å®šã«å¿…è¦ãªé›£æ˜“åº¦ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚å•é¡Œã«é›£æ˜“åº¦ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return
    metric_col, help_col = st.columns([1, 2])
    metric_col.metric("æ¨å®šèƒ½åŠ›Î¸", f"{theta:.2f}")
    help_col.caption(
        "å›ç­”ã®æ­£èª¤ãƒ»é›£æ˜“åº¦ãƒ»æœ€æ–°ã®å–ã‚Šçµ„ã¿å±¥æ­´ã‚’å…ƒã«æ¨å®šã—ã¦ã„ã¾ã™ã€‚"
        " æ–°ã—ã„å›ç­”ã‚’è¨˜éŒ²ã™ã‚‹ãŸã³ã«è‡ªå‹•ã§æ›´æ–°ã•ã‚Œã¾ã™ã€‚"
    )
    low_conf = int(st.session_state["settings"].get("review_low_confidence_threshold", 60))
    recommended = recommend_adaptive_questions(df, attempts, theta, low_conf_threshold=low_conf)
    if recommended.empty:
        st.info("ãŠã™ã™ã‚ã§ãã‚‹å•é¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã€‚æ¡ä»¶ã‚’è¦‹ç›´ã™ã‹ã€æ–°ã—ã„å•é¡Œã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
        return
    st.markdown("#### æ¨å¥¨å•é¡Œ (ä¸Šä½10ä»¶)")
    recommended_ids = recommended["id"].tolist()
    session_key = "adaptive_question_select"
    if not recommended_ids:
        st.warning("æ¨å¥¨å•é¡Œã®ä¸€è¦§ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return
    if session_key not in st.session_state or st.session_state[session_key] not in recommended_ids:
        st.session_state[session_key] = recommended_ids[0]
    selected_id = st.session_state[session_key]

    def select_adaptive_question(question_id: str) -> None:
        st.session_state[session_key] = question_id

    for _, rec in recommended.iterrows():
        qid = rec["id"]
        label = format_question_label(df, qid)
        difficulty_value = rec.get("difficulty")
        if pd.isna(difficulty_value):
            difficulty_display = "ä¸æ˜"
        elif isinstance(difficulty_value, (int, np.integer)):
            difficulty_display = str(int(difficulty_value))
        else:
            difficulty_display = f"{float(difficulty_value):.1f}"
        priority_value = rec.get("priority")
        priority_display = f"{priority_value:.2f}" if pd.notna(priority_value) else "N/A"
        button_label = f"{label}ï½œæ¨å¥¨åº¦ {priority_display}ï½œé›£æ˜“åº¦ {difficulty_display}"
        button_type = "primary" if qid == selected_id else "secondary"
        if st.button(
            button_label,
            key=f"adaptive_jump_{qid}",
            type=button_type,
            help="ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ä¸‹ã®è©³ç´°ã¨å‡ºé¡Œç”»é¢ãŒãã®å•é¡Œã«åˆ‡ã‚Šæ›¿ã‚ã‚Šã¾ã™ã€‚",
        ):
            select_adaptive_question(qid)
            selected_id = qid

    with st.expander("æ¨å¥¨å•é¡Œã®è©³ç´°ä¸€è¦§", expanded=False):
        display = recommended[["id", "year", "q_no", "category", "difficulty", "priority"]].copy()
        render_table_with_category_tags(
            display,
            column_order=["id", "category", "year", "q_no", "difficulty", "priority"],
            rename_map={
                "id": "å•é¡ŒID",
                "category": "åˆ†é‡",
                "year": "å¹´åº¦",
                "q_no": "å•ç•ª",
                "difficulty": "é›£æ˜“åº¦",
                "priority": "æ¨å¥¨åº¦",
            },
            index_column="id",
        )

    selected_id = st.selectbox(
        "å–ã‚Šçµ„ã‚€å•é¡Œ",
        recommended["id"],
        format_func=lambda x: format_question_label(df, x),
        key="adaptive_question_select",
    )
    row = df[df["id"] == selected_id].iloc[0]
    render_question_interaction(db, row, attempt_mode="adaptive", key_prefix="adaptive")


def render_subject_drill_lane(db: DBManager, df: pd.DataFrame) -> None:
    st.subheader("åˆ†é‡åˆ¥ãƒ‰ãƒªãƒ«")
    st.caption(
        "æ°‘æ³•ãƒ»å€Ÿåœ°å€Ÿå®¶æ³•ãƒ»éƒ½å¸‚è¨ˆç”»æ³•ãƒ»å»ºç¯‰åŸºæº–æ³•ãƒ»ç¨ãƒ»é‘‘å®šè©•ä¾¡ãƒ»å®…å»ºæ¥­æ³•ã¨ã„ã£ãŸãƒ†ãƒ¼ãƒã‚’ãƒ”ãƒ³ãƒã‚¤ãƒ³ãƒˆã§é›ãˆã¾ã™ã€‚"
        " å±¥æ­´ã«åŸºã¥ãå„ªå…ˆåº¦ã‚¹ã‚³ã‚¢ã‚’å‚ç…§ã—ã¦å¼±ç‚¹å¼·åŒ–ã«ã‚‚å¯¾å¿œã—ã¾ã™ã€‚"
    )
    attempts = db.get_attempt_stats()
    priority_df = build_question_priority(df, attempts)
    priority_columns = priority_df[
        [
            "id",
            "weight",
            "accuracy",
            "last_confidence",
            "days_since_last_attempt",
            "attempts_count",
        ]
    ].rename(columns={"weight": "priority_score"})
    settings = st.session_state.get("settings", {})
    default_confidence = int(settings.get("review_low_confidence_threshold", 60))
    default_elapsed = int(settings.get("review_elapsed_days", 7))
    mode_options = ["æ‰‹å‹•é¸æŠ"]
    if not attempts.empty:
        mode_options.append("å¼±ç‚¹å„ªå…ˆ")
    mode = st.radio(
        "å‡ºé¡Œãƒ¢ãƒ¼ãƒ‰",
        mode_options,
        horizontal=True,
        key="subject_mode",
        help="å±¥æ­´ã‹ã‚‰ç®—å‡ºã—ãŸå„ªå…ˆåº¦ã‚’ã‚‚ã¨ã«æ‰‹å‹•é¸æŠã¾ãŸã¯è‡ªå‹•ã‚­ãƒ¥ãƒ¼ã‚’åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚",
    )
    with st.expander("å‡ºé¡Œæ¡ä»¶", expanded=True):
        preset = st.selectbox(
            "ã‚¯ã‚¤ãƒƒã‚¯ãƒ—ãƒªã‚»ãƒƒãƒˆ",
            list(SUBJECT_PRESETS.keys()),
            help="ä»£è¡¨çš„ãªçµã‚Šè¾¼ã¿æ¡ä»¶ã‚’ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§é©ç”¨ã§ãã¾ã™ã€‚",
            key="subject_preset",
        )
        def apply_subject_preset() -> None:
            config = SUBJECT_PRESETS[preset]
            st.session_state["subject_categories"] = config["categories"]
            st.session_state["subject_difficulty"] = config["difficulty"]
            st.session_state["subject_review_only"] = config["review_only"]
            st.session_state["subject_topics"] = config.get("topics", [])
            st.session_state["subject_keyword"] = ""

        st.button(
            "ãƒ—ãƒªã‚»ãƒƒãƒˆã‚’é©ç”¨",
            key="subject_apply_preset",
            on_click=with_rerun(apply_subject_preset),
        )
        categories = st.multiselect(
            "åˆ†é‡",
            CATEGORY_CHOICES,
            default=CATEGORY_CHOICES,
            key="subject_categories",
        )
        topic_options = sorted({t for t in df["topic"].dropna().unique() if str(t).strip()})
        selected_topics = st.multiselect(
            "ãƒ†ãƒ¼ãƒ",
            topic_options,
            default=[],
            key="subject_topics",
        )
        difficulties = st.slider(
            "é›£æ˜“åº¦",
            1,
            5,
            (1, 5),
            key="subject_difficulty",
            help="1ã¯æ˜“ã—ã„ã€œ5ã¯é›£ã—ã„å•é¡Œã§ã™ã€‚",
        )
        keyword = st.text_input(
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§çµã‚Šè¾¼ã¿ (å•é¡Œæ–‡/ã‚¿ã‚°)",
            key="subject_keyword",
            help="èªå¥ã‚’å…¥åŠ›ã™ã‚‹ã¨å•é¡Œæ–‡ã¨ã‚¿ã‚°ã‹ã‚‰éƒ¨åˆ†ä¸€è‡´ã§æ¤œç´¢ã—ã¾ã™ã€‚",
        )
        review_only = st.checkbox(
            "å¾©ç¿’ã ã‘è¡¨ç¤º (èª¤ç­”ãƒ»ä½ç¢ºä¿¡ãƒ»çµŒéæ—¥æ•°)",
            value=st.session_state.get("subject_review_only", False),
            key="subject_review_only",
        )
    filtered = df[
        df["category"].isin(categories)
        & df["difficulty"].between(difficulties[0], difficulties[1])
    ]
    if selected_topics:
        filtered = filtered[filtered["topic"].isin(selected_topics)]
    if keyword:
        keyword_lower = keyword.lower()
        filtered = filtered[
            filtered["question"].str.lower().str.contains(keyword_lower)
            | filtered["tags"].fillna("").str.lower().str.contains(keyword_lower)
        ]
    if review_only:
        review_ids = get_review_candidate_ids(db)
        if not review_ids:
            st.info("å¾©ç¿’å¯¾è±¡ã®å•é¡Œã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å­¦ç¿’å±¥æ­´ã‚’å¢—ã‚„ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚")
            return
        filtered = filtered[filtered["id"].isin(review_ids)]
    if filtered.empty:
        st.warning("æ¡ä»¶ã«åˆè‡´ã™ã‚‹å•é¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚£ãƒ«ã‚¿ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
        return
    filtered = filtered.merge(priority_columns, on="id", how="left")
    filtered["priority_score"] = filtered["priority_score"].fillna(0.0)
    filtered["accuracy"] = filtered["accuracy"].fillna(0.5)
    filtered["last_confidence"] = filtered["last_confidence"].fillna(float(default_confidence))
    filtered["days_since_last_attempt"] = filtered["days_since_last_attempt"].fillna(float(default_elapsed))
    filtered["attempts_count"] = filtered["attempts_count"].fillna(0).astype(int)
    st.caption(
        f"ç¾åœ¨ã®æ¡ä»¶ã«åˆè‡´ã™ã‚‹å•é¡Œã¯ {len(filtered)} ä»¶ã§ã™ã€‚"
        "å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢ã¯æ­£ç­”ç‡ãƒ»ç¢ºä¿¡åº¦ãƒ»çµŒéæ—¥æ•°ã‚’çµ„ã¿åˆã‚ã›ã¦ç®—å‡ºã—ã¦ã„ã¾ã™ã€‚"
    )
    with st.expander("å„ªå…ˆåº¦ä»˜ãä¸€è¦§", expanded=False):
        display = filtered[[
            "id",
            "category",
            "difficulty",
            "priority_score",
            "accuracy",
            "last_confidence",
            "days_since_last_attempt",
            "attempts_count",
        ]].copy()
        display["accuracy"] = (display["accuracy"] * 100).round(0)
        display["last_confidence"] = display["last_confidence"].round(0)
        display["days_since_last_attempt"] = display["days_since_last_attempt"].round(1)
        render_table_with_category_tags(
            display,
            column_order=[
                "id",
                "category",
                "difficulty",
                "priority_score",
                "accuracy",
                "last_confidence",
                "days_since_last_attempt",
                "attempts_count",
            ],
            rename_map={
                "id": "å•é¡ŒID",
                "category": "åˆ†é‡",
                "difficulty": "é›£æ˜“åº¦",
                "priority_score": "å„ªå…ˆåº¦",
                "accuracy": "ç›´è¿‘æ­£ç­”ç‡(%)",
                "last_confidence": "ç›´è¿‘ç¢ºä¿¡åº¦(%)",
                "days_since_last_attempt": "çµŒéæ—¥æ•°",
                "attempts_count": "æŒ‘æˆ¦å›æ•°",
            },
            index_column="id",
        )
    if mode == "å¼±ç‚¹å„ªå…ˆ":
        prioritized = filtered.sort_values(
            ["priority_score", "accuracy"], ascending=[False, True]
        ).reset_index(drop=True)
        signature = (
            tuple(sorted(categories)),
            tuple(sorted(selected_topics)),
            tuple(difficulties),
            keyword,
            bool(review_only),
        )
        queue_key = "subject_priority_queue"
        signature_key = "subject_priority_signature"
        if st.session_state.get(signature_key) != signature:
            st.session_state[signature_key] = signature
            st.session_state[queue_key] = prioritized["id"].tolist()
        queue: List[str] = st.session_state.get(queue_key, [])
        if not queue:
            st.info("å„ªå…ˆåº¦æ¡ä»¶ã«åˆè‡´ã™ã‚‹å•é¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚£ãƒ«ã‚¿ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")
            return
        current_id = queue[0]
        current_row = prioritized[prioritized["id"] == current_id].iloc[0]
        summary_parts = [f"å„ªå…ˆåº¦ {current_row['priority_score']:.2f}"]
        if not pd.isna(current_row.get("accuracy")):
            summary_parts.append(f"æ­£ç­”ç‡ {current_row['accuracy'] * 100:.0f}%")
        if not pd.isna(current_row.get("last_confidence")):
            summary_parts.append(f"ç¢ºä¿¡åº¦ {current_row['last_confidence']:.0f}%")
        if not pd.isna(current_row.get("days_since_last_attempt")):
            summary_parts.append(
                f"çµŒé {current_row['days_since_last_attempt']:.0f}æ—¥"
            )
        st.info(" / ".join(summary_parts))

        def advance_priority_queue() -> None:
            queue_inner = st.session_state.get(queue_key, [])
            if queue_inner:
                queue_inner.pop(0)
            st.session_state[queue_key] = queue_inner
            safe_rerun()

        with st.expander("å„ªå…ˆå‡ºé¡Œã‚­ãƒ¥ãƒ¼", expanded=False):
            preview = prioritized.head(10)[["id", "priority_score", "accuracy"]]
            preview["accuracy"] = (preview["accuracy"] * 100).round(0)
            st.dataframe(
                preview.rename(
                    columns={
                        "id": "å•é¡ŒID",
                        "priority_score": "å„ªå…ˆåº¦",
                        "accuracy": "æ­£ç­”ç‡(%)",
                    }
                ).set_index("å•é¡ŒID"),
                use_container_width=True,
            )
        current_row = filtered[filtered["id"] == current_id].iloc[0]
        render_question_interaction(
            db,
            current_row,
            attempt_mode="subject_drill",
            key_prefix="subject",
        )
        st.button(
            "æ¬¡ã®å„ªå…ˆå•é¡Œã«é€²ã‚€",
            key="subject_priority_next",
            help="ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ç¾åœ¨ã®å•é¡Œã‚’é™¤å¤–ã—ã€æ¬¡ã®å„ªå…ˆå•é¡Œã‚’è¡¨ç¤ºã—ã¾ã™ã€‚",
            on_click=with_rerun(advance_priority_queue),
        )
        return

    def format_priority_label(question_id: str) -> str:
        label = format_question_label(filtered, question_id)
        row = filtered[filtered["id"] == question_id]
        if row.empty:
            return label
        score = row.iloc[0].get("priority_score")
        if pd.notna(score):
            return f"{label}ï½œå„ªå…ˆåº¦ {score:.2f}"
        return label

    question_id = st.selectbox(
        "å‡ºé¡Œå•é¡Œ",
        filtered["id"],
        format_func=format_priority_label,
        key="subject_question_select",
    )
    row = filtered[filtered["id"] == question_id].iloc[0]
    render_question_interaction(db, row, attempt_mode="subject_drill", key_prefix="subject")


def render_year_drill_lane(db: DBManager, df: pd.DataFrame) -> None:
    st.subheader("å¹´åº¦åˆ¥æ¼”ç¿’")
    st.caption("å¹´åº¦ã”ã¨ã®å‡ºé¡Œã‚’é€šã—æ¼”ç¿’ã—ã€æœ¬è©¦é¨“æœ¬ç•ªã¨åŒã˜æµã‚Œã§çŸ¥è­˜ã‚’å®šç€ã•ã›ã¾ã™ã€‚")
    years = sorted(df["year"].unique(), reverse=True)
    if not years:
        st.info("å¹´åº¦æƒ…å ±ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return
    selected_year = st.selectbox("å¹´åº¦", years, key="year_drill_year")
    subset = df[df["year"] == selected_year].sort_values("q_no")
    if subset.empty:
        st.warning("é¸æŠã—ãŸå¹´åº¦ã®å•é¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    total = len(subset)
    progress_key = "year_drill_index"
    stored_year_key = "year_drill_current_year"
    if st.session_state.get(stored_year_key) != selected_year:
        st.session_state[stored_year_key] = selected_year
        st.session_state[progress_key] = 0
    index = st.session_state.get(progress_key, 0)
    index = max(0, min(index, total - 1))
    current_row = subset.iloc[index]
    st.progress((index + 1) / total)

    def go_prev() -> None:
        st.session_state[progress_key] = max(0, index - 1)

    def go_next() -> None:
        st.session_state[progress_key] = min(total - 1, index + 1)

    navigation = QuestionNavigation(
        has_prev=index > 0,
        has_next=index < total - 1,
        on_prev=go_prev,
        on_next=go_next,
        label=f"{index + 1}/{total} å•ã‚’å­¦ç¿’ä¸­",
    )
    render_question_interaction(
        db,
        current_row,
        attempt_mode="year_drill",
        key_prefix="year",
        navigation=navigation,
    )


def render_weakness_lane(db: DBManager, df: pd.DataFrame) -> None:
    st.subheader("å¼±ç‚¹å…‹æœãƒ¢ãƒ¼ãƒ‰")
    st.caption("èª¤ç­”ãƒ»ä½æ­£ç­”ç‡ãƒ»æ™‚é–“è¶…éãŒç›®ç«‹ã¤å•é¡Œã‚’å„ªå…ˆçš„ã«å‡ºé¡Œã—ã€å¾—ç‚¹ã®åº•ä¸Šã’ã‚’å›³ã‚Šã¾ã™ã€‚")
    attempts = db.get_attempt_stats()
    if attempts.empty:
        st.info("å­¦ç¿’å±¥æ­´ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚æœ¬è©¦é¨“ãƒ¢ãƒ¼ãƒ‰ã‚„ãƒ‰ãƒªãƒ«ã§å–ã‚Šçµ„ã‚“ã§ã¿ã¾ã—ã‚‡ã†ã€‚")
        return
    summary = (
        attempts.groupby(["question_id", "category"])
        .agg(
            attempts_count=("is_correct", "count"),
            correct_count=("is_correct", "sum"),
            avg_seconds=("seconds", "mean"),
        )
        .reset_index()
    )
    summary["accuracy"] = summary["correct_count"] / summary["attempts_count"].replace(0, np.nan)
    summary["accuracy"] = summary["accuracy"].fillna(0)
    summary["avg_seconds"] = summary["avg_seconds"].fillna(0)
    summary["priority"] = (1 - summary["accuracy"]) * summary["attempts_count"] + np.where(
        summary["avg_seconds"] > 90,
        1,
        0,
    )
    merged = summary.merge(df[["id", "year", "q_no", "question"]], left_on="question_id", right_on="id", how="left")
    merged = merged.sort_values(["priority", "accuracy"], ascending=[False, True])
    st.markdown("#### å„ªå…ˆå‡ºé¡Œãƒªã‚¹ãƒˆ")
    with st.expander("ä¸¦ã³æ›¿ãˆãƒ»ãƒ•ã‚£ãƒ«ã‚¿", expanded=False):
        category_options = sorted({str(cat) for cat in merged["category"].dropna()})
        selected_categories = st.multiselect(
            "åˆ†é‡",
            category_options,
            default=category_options,
            help="é‡ç‚¹çš„ã«å¾©ç¿’ã—ãŸã„åˆ†é‡ã‚’é¸ã³ã¾ã™ã€‚",
            key="weakness_categories",
        )
        max_attempts = int(merged["attempts_count"].max()) if not merged.empty else 1
        min_attempts = int(merged["attempts_count"].min()) if not merged.empty else 0
        if min_attempts == max_attempts:
            attempts_threshold = max_attempts
            st.caption(f"æŒ‘æˆ¦å›æ•°ãƒ•ã‚£ãƒ«ã‚¿: {max_attempts} å›ã®ã¿ã®ãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚")
        else:
            attempts_threshold = st.slider(
                "æœ€ä½æŒ‘æˆ¦å›æ•°",
                min_attempts,
                max_attempts,
                min(min_attempts + 1, max_attempts),
                help="æŒ‡å®šå›æ•°ä»¥ä¸Šå–ã‚Šçµ„ã‚“ã å•é¡Œã‚’å¯¾è±¡ã«ã—ã¾ã™ã€‚",
                key="weakness_attempts_threshold",
            )
        accuracy_ceiling = st.slider(
            "æ­£ç­”ç‡ã®ä¸Šé™ (%)",
            0,
            100,
            70,
            step=5,
            help="ã“ã®å€¤ã‚ˆã‚Šæ­£ç­”ç‡ãŒé«˜ã„å•é¡Œã¯ãƒªã‚¹ãƒˆã‹ã‚‰é™¤å¤–ã—ã¾ã™ã€‚",
            key="weakness_accuracy_ceiling",
        )
        sort_option = st.selectbox(
            "ä¸¦ã³é †",
            ["å„ªå…ˆåº¦ãŒé«˜ã„é †", "æ­£ç­”ç‡ãŒä½ã„é †", "æŒ‘æˆ¦å›æ•°ãŒå¤šã„é †", "å¹´åº¦ãŒæ–°ã—ã„é †"],
            help="å¾©ç¿’ãƒªã‚¹ãƒˆã®ä¸¦ã³æ›¿ãˆåŸºæº–ã‚’å¤‰æ›´ã—ã¾ã™ã€‚",
            key="weakness_sort",
        )
    filtered = merged.copy()
    if selected_categories:
        filtered = filtered[filtered["category"].isin(selected_categories)]
    if attempts_threshold:
        filtered = filtered[filtered["attempts_count"] >= attempts_threshold]
    filtered = filtered[filtered["accuracy"] * 100 <= accuracy_ceiling]
    if sort_option == "æ­£ç­”ç‡ãŒä½ã„é †":
        filtered = filtered.sort_values(["accuracy", "attempts_count"], ascending=[True, False])
    elif sort_option == "æŒ‘æˆ¦å›æ•°ãŒå¤šã„é †":
        filtered = filtered.sort_values(["attempts_count", "accuracy"], ascending=[False, True])
    elif sort_option == "å¹´åº¦ãŒæ–°ã—ã„é †":
        filtered = filtered.sort_values(["year", "priority"], ascending=[False, False])
    else:
        filtered = filtered.sort_values(["priority", "accuracy"], ascending=[False, True])
    if filtered.empty:
        st.info("æ¡ä»¶ã«åˆè‡´ã™ã‚‹å¼±ç‚¹å€™è£œãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚£ãƒ«ã‚¿è¨­å®šã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")
        return
    display_df = filtered.head(15)[
        [
            "question_id",
            "category",
            "year",
            "q_no",
            "accuracy",
            "attempts_count",
            "avg_seconds",
        ]
    ].copy()
    display_df["accuracy"] = (display_df["accuracy"].astype(float) * 100).round(0)
    display_df["avg_seconds"] = display_df["avg_seconds"].astype(float).round(1)
    render_table_with_category_tags(
        display_df,
        column_order=[
            "question_id",
            "category",
            "year",
            "q_no",
            "accuracy",
            "attempts_count",
            "avg_seconds",
        ],
        rename_map={
            "question_id": "å•é¡ŒID",
            "category": "åˆ†é‡",
            "year": "å¹´åº¦",
            "q_no": "å•",
            "accuracy": "æ­£ç­”ç‡(%)",
            "attempts_count": "æŒ‘æˆ¦å›æ•°",
            "avg_seconds": "å¹³å‡è§£ç­”æ™‚é–“(ç§’)",
        },
        index_column="question_id",
    )
    candidates = filtered[~filtered["id"].isna()]
    if candidates.empty:
        st.info("å¼±ç‚¹å€™è£œã®å•é¡Œã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å±¥æ­´ã‚’å¢—ã‚„ã—ã¾ã—ã‚‡ã†ã€‚")
        return
    selected_qid = st.selectbox(
        "å¾©ç¿’ã™ã‚‹å•é¡Œ",
        candidates["id"],
        format_func=lambda x: format_question_label(df, x),
        key="weakness_question",
    )
    row = df[df["id"] == selected_qid].iloc[0]
    render_question_interaction(db, row, attempt_mode="weakness", key_prefix="weakness")


def render_law_revision_lane(db: DBManager, parent_nav: str = "å­¦ç¿’") -> None:
    render_specialized_header(parent_nav, "æ³•æ”¹æ­£å¯¾ç­–", "law_revision")
    st.subheader("æ³•æ”¹æ­£å¯¾ç­–")
    law_df = db.load_law_revision_questions()
    sync_logs = db.load_law_revision_sync_logs(limit=5)
    if law_df.empty:
        st.info(
            "æ³•æ”¹æ­£äºˆæƒ³å•é¡Œãƒ‡ãƒ¼ã‚¿ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã€è¨­å®š ï¼ ãƒ‡ãƒ¼ã‚¿å…¥å‡ºåŠ›ã€ã‹ã‚‰ law_revision.csv ã‚’å–ã‚Šè¾¼ã¿ã¾ã—ã‚‡ã†ã€‚"
        )
        return
    st.caption(
        "æœ€æ–°ã®æ³•æ”¹æ­£ãƒã‚¤ãƒ³ãƒˆã‚’é‡ç‚¹çš„ã«æ¼”ç¿’ã§ãã¾ã™ã€‚æ­£ç­”ãŒæœªè¨­å®šã®å ´åˆã¯è‡ªå·±æ¡ç‚¹ã—ã¦ãã ã•ã„ã€‚"
    )
    total_questions = len(law_df)
    pending_count = int((law_df.get("review_status") == "pending").sum())
    summary_cols = st.columns(4)
    with summary_cols[0]:
        st.metric("ç™»éŒ²æ•°", total_questions)
    with summary_cols[1]:
        unique_laws = law_df["law_name"].replace("", pd.NA).dropna().nunique()
        st.metric("å¯¾è±¡æ³•ä»¤", int(unique_laws) if not pd.isna(unique_laws) else 0)
    with summary_cols[2]:
        recent_years = law_df["revision_year"].dropna()
        if recent_years.empty:
            st.metric("æœ€æ–°æ”¹æ­£å¹´åº¦", "æœªè¨­å®š")
        else:
            st.metric("æœ€æ–°æ”¹æ­£å¹´åº¦", f"{int(recent_years.max())}å¹´")
    with summary_cols[3]:
        st.metric("æœªãƒ¬ãƒ“ãƒ¥ãƒ¼", pending_count)
    if not sync_logs.empty:
        latest = sync_logs.iloc[0]
        status = latest.get("status", "-")
        timestamp = latest.get("fetched_at")
        status_text = f"{status}"
        if pd.notna(timestamp):
            status_text += f" / {pd.to_datetime(timestamp).strftime('%Y-%m-%d %H:%M')}"
        st.caption(f"æœ€çµ‚æ›´æ–°: {status_text}")
    else:
        st.caption("è‡ªå‹•æ›´æ–°ãƒ­ã‚°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã€ãƒ‡ãƒ¼ã‚¿å…¥å‡ºåŠ›ã€ã§å–å¾—ã‚’é–‹å§‹ã§ãã¾ã™ã€‚")
    with st.expander("è‡ªå‹•æ›´æ–°çŠ¶æ³", expanded=False):
        if sync_logs.empty:
            st.info("ã¾ã è‡ªå‹•å–å¾—å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            display = sync_logs.copy()
            display["fetched_at"] = pd.to_datetime(display["fetched_at"]).dt.strftime("%Y-%m-%d %H:%M")
            st.dataframe(
                display[["fetched_at", "source", "status", "revisions_detected", "questions_generated", "message"]],
                use_container_width=True,
            )
    with st.expander("å‡ºé¡Œæ¡ä»¶", expanded=True):
        law_names = sorted(
            {
                str(name).strip()
                for name in law_df.get("law_name", pd.Series(dtype="object")).dropna()
                if str(name).strip()
            }
        )
        if law_names:
            selected_laws = st.multiselect(
                "å¯¾è±¡æ³•ä»¤",
                law_names,
                default=law_names,
                key="law_revision_laws",
            )
        else:
            selected_laws = []
        category_candidates = sorted(
            {
                str(cat).strip()
                for cat in law_df.get("category", pd.Series(dtype="object")).dropna()
                if str(cat).strip()
            }
        )
        if category_candidates:
            selected_categories = st.multiselect(
                "åˆ†é‡ã‚¿ã‚°",
                category_candidates,
                default=category_candidates,
                key="law_revision_categories",
            )
        else:
            selected_categories = []
        year_series = law_df.get("revision_year")
        include_unknown_year = st.checkbox(
            "æ”¹æ­£å¹´æœªè¨­å®šã®å•é¡Œã‚‚å«ã‚ã‚‹",
            value=True,
            key="law_revision_include_unknown",
        )
        year_range = None
        if year_series is not None and year_series.dropna().size > 0:
            min_year = int(year_series.dropna().min())
            max_year = int(year_series.dropna().max())
            if min_year == max_year:
                default_range = (min_year, max_year)
            else:
                default_range = (max(min_year, max_year - 4), max_year)
            year_range = st.slider(
                "æ”¹æ­£å¹´åº¦",
                min_year,
                max_year,
                default_range,
                key="law_revision_year_range",
            )
        status_options = ["ã™ã¹ã¦", "pending", "approved", "rejected"]
        review_status = st.selectbox(
            "ãƒ¬ãƒ“ãƒ¥ãƒ¼çŠ¶æ…‹",
            status_options,
            format_func=lambda value: {
                "ã™ã¹ã¦": "ã™ã¹ã¦",
                "pending": "è¦ãƒ¬ãƒ“ãƒ¥ãƒ¼",
                "approved": "æ‰¿èªæ¸ˆã¿",
                "rejected": "å·®æˆ»ã—",
            }.get(value, value),
            key="law_revision_review_status",
        )
        keyword = st.text_input(
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿",
            value="",
            key="law_revision_keyword",
            help="å•é¡Œæ–‡ãƒ»ã‚¿ã‚°ãƒ»æ³•ä»¤åã‚’éƒ¨åˆ†ä¸€è‡´ã§çµã‚Šè¾¼ã¿ã¾ã™ã€‚",
        )
    filtered = law_df.copy()
    if selected_laws:
        filtered = filtered[filtered["law_name"].isin(selected_laws)]
    if selected_categories:
        filtered = filtered[filtered["category"].isin(selected_categories)]
    if year_range:
        start_year, end_year = year_range
        mask = filtered["revision_year"].between(start_year, end_year)
        if include_unknown_year:
            mask = mask | filtered["revision_year"].isna()
        filtered = filtered[mask]
    elif not include_unknown_year:
        filtered = filtered[filtered["revision_year"].notna()]
    if review_status != "ã™ã¹ã¦" and "review_status" in filtered.columns:
        filtered = filtered[filtered["review_status"].fillna("pending") == review_status]
    if keyword:
        keyword = keyword.strip()
        if keyword:
            contains_mask = (
                filtered.get("question", pd.Series(dtype="object")).fillna("").str.contains(keyword, case=False)
                | filtered.get("tags", pd.Series(dtype="object")).fillna("").str.contains(keyword, case=False)
                | filtered.get("law_name", pd.Series(dtype="object")).fillna("").str.contains(keyword, case=False)
                | filtered.get("topic", pd.Series(dtype="object")).fillna("").str.contains(keyword, case=False)
            )
            filtered = filtered[contains_mask]
    if filtered.empty:
        st.warning("æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹æ³•æ”¹æ­£å•é¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚£ãƒ«ã‚¿ã‚’ç·©å’Œã—ã¦ãã ã•ã„ã€‚")
        return
    with st.expander("ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ»æ‰¿èª", expanded=False):
        pending_df = filtered[filtered.get("review_status") == "pending"]
        if pending_df.empty:
            st.info("æœªãƒ¬ãƒ“ãƒ¥ãƒ¼ã®å•é¡Œã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            review_selection = st.multiselect(
                "æ‰¿èªå¯¾è±¡ã®å•é¡Œ",
                pending_df["id"],
                format_func=lambda qid: format_question_label(law_df, qid),
                key="law_revision_review_selection",
            )
            col_a, col_b = st.columns(2)
            with col_a:
                if st.button("é¸æŠã—ãŸå•é¡Œã‚’æ‰¿èª", key="law_revision_approve"):
                    db.update_law_revision_review_status(review_selection, "approved")
                    st.success("æ‰¿èªã—ã¾ã—ãŸã€‚")
                    st.experimental_rerun()
            with col_b:
                if st.button("é¸æŠã—ãŸå•é¡Œã‚’å·®æˆ»ã—", key="law_revision_reject"):
                    db.update_law_revision_review_status(review_selection, "rejected")
                    st.warning("å·®æˆ»ã—ã¾ã—ãŸã€‚")
                    st.experimental_rerun()
    with st.expander("æ³•æ”¹æ­£å•é¡Œä¸€è¦§", expanded=False):
        preview_cols = [
            "law_name",
            "revision_year",
            "effective_date",
            "label",
            "category",
            "question",
        ]
        available_cols = [col for col in preview_cols if col in filtered.columns]
        st.dataframe(filtered[available_cols].head(20))
        st.caption("20ä»¶ã¾ã§è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚CSVã§è©³ç´°ã‚’ç¢ºèªã§ãã¾ã™ã€‚")
    max_questions = max(1, len(filtered))
    default_count = min(10, max_questions)
    col1, col2 = st.columns(2)
    with col1:
        question_count = st.slider(
            "å‡ºé¡Œæ•°",
            1,
            max_questions,
            default_count,
            key="law_revision_question_count",
        )
    with col2:
        order_option = st.radio(
            "å‡ºé¡Œé †",
            ["ãƒ©ãƒ³ãƒ€ãƒ ", "æ”¹æ­£å¹´ãŒæ–°ã—ã„é †", "ç™»éŒ²é †"],
            key="law_revision_order",
            horizontal=True,
        )

    def start_law_revision_session() -> None:
        selection = filtered
        if order_option == "ãƒ©ãƒ³ãƒ€ãƒ ":
            selection = selection.sample(question_count)
        elif order_option == "æ”¹æ­£å¹´ãŒæ–°ã—ã„é †":
            selection = selection.sort_values(
                ["revision_year", "created_at"], ascending=[False, False]
            ).head(question_count)
        else:
            selection = selection.head(question_count)
        selection = selection.reset_index(drop=True)
        st.session_state["law_revision_session"] = {
            "questions": selection.to_dict(orient="records"),
            "index": 0,
            "started_at": dt.datetime.now().isoformat(),
            "run_id": hashlib.sha256(f"lawrev|{time.time()}".encode("utf-8")).hexdigest()[:8],
        }

    st.button(
        "æ³•æ”¹æ­£å•é¡Œã‚’é–‹å§‹",
        key="law_revision_start",
        type="primary",
        on_click=with_rerun(start_law_revision_session),
    )

    session = st.session_state.get("law_revision_session")
    if not session:
        return
    questions = session.get("questions", [])
    if not questions:
        st.warning("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«å•é¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã€‚å†åº¦é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")
        return
    index = session.get("index", 0)
    total = len(questions)
    index = max(0, min(index, total - 1))
    st.progress((index + 1) / total)

    def set_index(new_index: int) -> None:
        current = st.session_state.get("law_revision_session", {})
        current["index"] = new_index
        st.session_state["law_revision_session"] = current

    row_series = pd.Series(questions[index])
    navigation = QuestionNavigation(
        has_prev=index > 0,
        has_next=index < total - 1,
        on_prev=with_rerun(set_index, max(0, index - 1)),
        on_next=with_rerun(set_index, min(total - 1, index + 1)),
        label=f"{index + 1}/{total} å•ã‚’å­¦ç¿’ä¸­",
    )
    render_law_revision_metadata(row_series)
    render_question_interaction(
        db,
        row_series,
        attempt_mode="law_revision",
        key_prefix=f"law_revision_{session.get('run_id', 'session')}",
        navigation=navigation,
        enable_srs=False,
        log_attempts=False,
    )
    action_cols = st.columns([1, 1, 2])
    with action_cols[0]:
        st.button(
            "å‰ã®å•é¡Œ",
            use_container_width=True,
            disabled=index <= 0,
            on_click=with_rerun(set_index, max(0, index - 1)),
            key="law_revision_prev_button",
        )
    with action_cols[1]:
        st.button(
            "æ¬¡ã®å•é¡Œ",
            use_container_width=True,
            disabled=index >= total - 1,
            on_click=with_rerun(set_index, min(total - 1, index + 1)),
            key="law_revision_next_button",
        )
    with action_cols[2]:
        st.caption(f"æ¼”ç¿’ä¸­ {index + 1}/{total} å•")
    st.button(
        "ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’çµ‚äº†",
        key="law_revision_end_session",
        on_click=with_rerun(lambda: st.session_state.pop("law_revision_session", None)),
    )


def render_predicted_lane(db: DBManager, parent_nav: str = "å­¦ç¿’") -> None:
    render_specialized_header(parent_nav, "äºˆæƒ³å•é¡Œæ¼”ç¿’", "predicted")
    st.subheader("äºˆæƒ³å•é¡Œæ¼”ç¿’")
    predicted_df = db.load_predicted_questions()
    if predicted_df.empty:
        st.info("äºˆæƒ³å•é¡Œãƒ‡ãƒ¼ã‚¿ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã€è¨­å®š ï¼ ãƒ‡ãƒ¼ã‚¿å…¥å‡ºåŠ›ã€ã‹ã‚‰CSVã‚’å–ã‚Šè¾¼ã‚“ã§ãã ã•ã„ã€‚")
        return
    st.caption("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸäºˆæƒ³å•é¡Œã‚’ä½¿ã£ã¦ç›´å‰å¯¾ç­–ã®æ¼”ç¿’ã‚’è¡Œã„ã¾ã™ã€‚æ­£ç­”ãŒæœªè¨­å®šã®å ´åˆã¯è‡ªå·±æ¡ç‚¹ã¨ãªã‚Šã¾ã™ã€‚")
    total_questions = len(predicted_df)
    summary_cols = st.columns(3)
    with summary_cols[0]:
        st.metric("ç™»éŒ²æ•°", total_questions)
    with summary_cols[1]:
        available_correct = predicted_df["correct"].notna().sum()
        st.metric("æ­£ç­”ä»˜ã", int(available_correct))
    with summary_cols[2]:
        categories = predicted_df["category"].replace("", pd.NA).dropna().nunique()
        st.metric("ã‚«ãƒ†ã‚´ãƒªæ•°", int(categories) if not pd.isna(categories) else 0)
    with st.expander("äºˆæƒ³å•é¡Œä¸€è¦§", expanded=False):
        preview_cols = [col for col in ["label", "category", "topic", "source"] if col in predicted_df.columns]
        if preview_cols:
            st.dataframe(predicted_df[preview_cols + ["question"]].head(20))
        else:
            st.dataframe(predicted_df.head(20))
        st.caption("20ä»¶ã¾ã§è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚è©³ç´°ã¯CSVã‚’ç·¨é›†ã—ã¦ã”ç¢ºèªãã ã•ã„ã€‚")
    max_questions = max(1, total_questions)
    default_count = min(10, max_questions)
    col1, col2 = st.columns(2)
    with col1:
        question_count = st.slider("å‡ºé¡Œæ•°", 1, max_questions, default_count, key="predicted_question_count")
    with col2:
        order_option = st.radio("å‡ºé¡Œé †", ["ãƒ©ãƒ³ãƒ€ãƒ ", "ç™»éŒ²é †"], key="predicted_order", horizontal=True)

    def start_predicted_session() -> None:
        if order_option == "ãƒ©ãƒ³ãƒ€ãƒ ":
            selection = predicted_df.sample(question_count).reset_index(drop=True)
        else:
            selection = predicted_df.head(question_count).reset_index(drop=True)
        st.session_state["predicted_session"] = {
            "questions": selection.to_dict(orient="records"),
            "index": 0,
            "started_at": dt.datetime.now().isoformat(),
            "run_id": hashlib.sha256(f"predicted|{time.time()}".encode("utf-8")).hexdigest()[:8],
        }

    st.button("äºˆæƒ³å•é¡Œã‚’é–‹å§‹", key="predicted_start", type="primary", on_click=with_rerun(start_predicted_session))

    session = st.session_state.get("predicted_session")
    if not session:
        return
    questions = session.get("questions", [])
    if not questions:
        st.warning("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«å•é¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã€‚å†åº¦é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")
        return
    index = session.get("index", 0)
    total = len(questions)
    index = max(0, min(index, total - 1))
    st.progress((index + 1) / total)

    def set_index(new_index: int) -> None:
        current = st.session_state.get("predicted_session", {})
        current["index"] = new_index
        st.session_state["predicted_session"] = current

    row_series = pd.Series(questions[index])
    navigation = QuestionNavigation(
        has_prev=index > 0,
        has_next=index < total - 1,
        on_prev=with_rerun(set_index, max(0, index - 1)),
        on_next=with_rerun(set_index, min(total - 1, index + 1)),
        label=f"{index + 1}/{total} å•ã‚’å­¦ç¿’ä¸­",
    )
    render_question_interaction(
        db,
        row_series,
        attempt_mode="predicted",
        key_prefix=f"predicted_{session.get('run_id', 'session')}",
        navigation=navigation,
        enable_srs=False,
        log_attempts=False,
    )
    action_cols = st.columns([1, 1, 2])
    with action_cols[0]:
        disabled = index <= 0
        st.button(
            "å‰ã®å•é¡Œ",
            use_container_width=True,
            disabled=disabled,
            on_click=with_rerun(set_index, max(0, index - 1)),
            key="predicted_prev_button",
        )
    with action_cols[1]:
        disabled = index >= total - 1
        st.button(
            "æ¬¡ã®å•é¡Œ",
            use_container_width=True,
            disabled=disabled,
            on_click=with_rerun(set_index, min(total - 1, index + 1)),
            key="predicted_next_button",
        )
    with action_cols[2]:
        st.caption(f"æ¼”ç¿’ä¸­ {index + 1}/{total} å•")
    st.button(
        "ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’çµ‚äº†",
        key="predicted_end_session",
        type="secondary",
        on_click=with_rerun(lambda: st.session_state.pop("predicted_session", None)),
    )


def render_exam_session_body(
    db: DBManager,
    df: pd.DataFrame,
    session: ExamSession,
    key_prefix: str,
    pass_line: float = 0.7,
) -> None:
    st.subheader(session.name)
    if st.session_state["settings"].get("timer", True):
        elapsed = dt.datetime.now() - session.started_at
        remaining = max(0, 120 * 60 - int(elapsed.total_seconds()))
        minutes, seconds = divmod(remaining, 60)
        st.info(f"æ®‹ã‚Šæ™‚é–“: {minutes:02d}:{seconds:02d}")
    responses: Dict[str, int] = {}
    choice_labels = ["â‘ ", "â‘¡", "â‘¢", "â‘£"]
    for qid in session.questions:
        row_df = df[df["id"] == qid]
        if row_df.empty:
            continue
        row = row_df.iloc[0]
        st.markdown(f"### {row['year']}å¹´ å•{row['q_no']}")
        st.markdown(f"**{row['category']} / {row['topic']}**")
        render_law_reference(row, db=db)
        st.markdown(row["question"], unsafe_allow_html=True)
        options = [row.get(f"choice{i}", "") for i in range(1, 5)]
        option_map = {
            idx + 1: f"{choice_labels[idx]} {options[idx]}" if options[idx] else choice_labels[idx]
            for idx in range(4)
        }
        choice = st.radio(
            f"å›ç­” ({qid})",
            list(option_map.keys()),
            format_func=lambda opt: option_map.get(opt, str(opt)),
            key=f"{key_prefix}_exam_{qid}",
            horizontal=True,
            index=None,
        )
        if choice is not None:
            responses[qid] = choice
    if st.button(
        "æ¡ç‚¹ã™ã‚‹",
        key=f"{key_prefix}_grade",
        help="ç¾åœ¨ã®å›ç­”ã‚’ä¿å­˜ã—ã€æ­£ç­”ç‡ã‚„åˆ†é‡åˆ¥çµ±è¨ˆã‚’è¡¨ç¤ºã—ã¾ã™ã€‚",
    ):
        evaluate_exam_attempt(db, df, session, responses, pass_line)


def evaluate_exam_attempt(
    db: DBManager,
    df: pd.DataFrame,
    session: ExamSession,
    responses: Dict[str, int],
    pass_line: float,
) -> None:
    total_questions = len(session.questions)
    correct = 0
    per_category: Dict[str, Dict[str, int]] = {}
    wrong_choices: List[Dict[str, object]] = []
    attempt_records: List[Tuple[str, int, bool]] = []
    duration = max((dt.datetime.now() - session.started_at).total_seconds(), 1)
    avg_seconds = duration / max(len(responses), 1)
    for qid in session.questions:
        row_df = df[df["id"] == qid]
        if row_df.empty:
            continue
        row = row_df.iloc[0]
        correct_choice = int(row.get("correct") or 0)
        choice = responses.get(qid)
        is_correct = choice is not None and correct_choice == choice
        if is_correct:
            correct += 1
        category = row.get("category", "ãã®ä»–")
        stats = per_category.setdefault(category, {"total": 0, "correct": 0})
        stats["total"] += 1
        if is_correct:
            stats["correct"] += 1
        attempt_records.append((qid, choice, is_correct))
        if not is_correct and correct_choice in range(1, 5):
            wrong_choices.append(
                {
                    "question": f"{row['year']}å¹´ å•{row['q_no']}",
                    "selected": choice,
                    "correct": correct_choice,
                    "category": category,
                }
            )
    finished_at = dt.datetime.now()
    exam_id = db.log_exam_result(
        {
            "name": session.name,
            "started_at": session.started_at,
            "finished_at": finished_at,
            "year_mode": session.year_mode,
            "score": correct,
        }
    )
    for qid, choice, is_correct in attempt_records:
        db.record_attempt(
            qid,
            choice,
            is_correct,
            seconds=int(avg_seconds),
            mode=session.mode,
            exam_id=exam_id,
            confidence=None,
            grade=None,
        )
    accuracy = correct / max(total_questions, 1)
    remaining_time = max(0, 120 * 60 - int(duration))
    answered = len(responses)
    unanswered = total_questions - answered
    expected_final = correct + unanswered * (correct / max(answered, 1)) if answered else 0
    result_payload = {
        "score": correct,
        "total": total_questions,
        "accuracy": accuracy,
        "pass_line": pass_line,
        "per_category": per_category,
        "wrong_choices": wrong_choices,
        "remaining_time": remaining_time,
        "expected_final": expected_final,
        "mode": session.mode,
        "exam_id": exam_id,
    }
    st.session_state[f"exam_result_{session.mode}"] = result_payload
    st.session_state["exam_session"] = None


def display_exam_result(result: Dict[str, object]) -> None:
    score = result["score"]
    total = result["total"]
    accuracy = result["accuracy"]
    pass_line = result["pass_line"]
    status = "âœ… åˆæ ¼ãƒ©ã‚¤ãƒ³åˆ°é”" if accuracy >= pass_line else "âš ï¸ åˆæ ¼ãƒ©ã‚¤ãƒ³æœªé”"
    st.markdown(f"### æ¡ç‚¹çµæœ â€” {status}")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("å¾—ç‚¹", f"{score} / {total}")
    with col2:
        st.metric("æ­£ç­”ç‡", f"{accuracy * 100:.1f}%")
    with col3:
        threshold = int(total * pass_line)
        st.metric("åˆæ ¼ãƒ©ã‚¤ãƒ³", f"{threshold} ç‚¹")
    st.progress(min(accuracy / max(pass_line, 1e-6), 1.0))
    remaining_minutes, remaining_seconds = divmod(int(result["remaining_time"]), 60)
    st.metric(
        "æ®‹ã‚Šæ™‚é–“ Ã— æƒ³å®šåˆ°é”ç‚¹",
        f"{remaining_minutes:02d}:{remaining_seconds:02d} / {result['expected_final']:.1f} ç‚¹",
    )
    if result["per_category"]:
        radar_df = pd.DataFrame(
            [
                {
                    "category": category,
                    "accuracy": stats["correct"] / max(stats["total"], 1),
                }
                for category, stats in result["per_category"].items()
            ]
        )
        if not radar_df.empty:
            import altair as alt

            radar_df = pd.concat([radar_df, radar_df.iloc[[0]]], ignore_index=True)
            chart = (
                alt.Chart(radar_df)
                .mark_line()
                .encode(
                    theta=alt.Theta("category", sort=None),
                    radius=alt.Radius("accuracy", scale=alt.Scale(domain=[0, 1])),
                )
                .properties(title="åˆ†é‡åˆ¥ã‚¹ã‚³ã‚¢ãƒ¬ãƒ¼ãƒ€ãƒ¼")
            )
            points = (
                alt.Chart(radar_df)
                .mark_point(size=80)
                .encode(
                    theta=alt.Theta("category", sort=None),
                    radius=alt.Radius("accuracy", scale=alt.Scale(domain=[0, 1])),
                )
            )
            st.altair_chart(chart + points, use_container_width=True)
    wrong_choices = result.get("wrong_choices", [])
    if wrong_choices:
        st.markdown("#### èª¤ç­”ã®ä»£æ›¿æ­£è§£è‚¢å‚¾å‘")
        wrong_df = pd.DataFrame(wrong_choices)
        option_map = {1: "â‘ ", 2: "â‘¡", 3: "â‘¢", 4: "â‘£"}
        wrong_df["é¸æŠè‚¢"] = wrong_df["selected"].map(option_map).fillna("æœªå›ç­”")
        wrong_df["æ­£è§£è‚¢"] = wrong_df["correct"].map({1: "â‘ ", 2: "â‘¡", 3: "â‘¢", 4: "â‘£"})
        st.dataframe(
            wrong_df[["question", "category", "é¸æŠè‚¢", "æ­£è§£è‚¢"]],
            use_container_width=True,
        )


def render_question_interaction(
    db: DBManager,
    row: pd.Series,
    attempt_mode: str,
    key_prefix: str,
    navigation: Optional[QuestionNavigation] = None,
    enable_srs: bool = True,
    log_attempts: bool = True,
) -> None:
    inject_ui_styles()
    last_question_key = f"{key_prefix}_last_question"
    feedback_key = f"{key_prefix}_feedback"
    selected_key = f"{key_prefix}_selected_{row['id']}"
    order_key = f"{key_prefix}_order_{row['id']}"
    explanation_key = f"{key_prefix}_explanation_{row['id']}"
    confidence_key = f"{key_prefix}_confidence_{row['id']}"
    help_state_key = f"{key_prefix}_help_visible"
    if st.session_state.get(last_question_key) != row["id"]:
        st.session_state[last_question_key] = row["id"]
        st.session_state.pop(feedback_key, None)
        st.session_state[selected_key] = None
        st.session_state[confidence_key] = 50
        st.session_state[order_key] = None
        st.session_state[explanation_key] = False
    feedback = st.session_state.get(feedback_key)
    if feedback and feedback.get("question_id") != row["id"]:
        feedback = None
    choices = [row.get(f"choice{i}", "") for i in range(1, 5)]
    base_order = list(range(4))
    if st.session_state["settings"].get("shuffle_choices", True):
        random.seed(f"{row['id']}_{attempt_mode}")
        random.shuffle(base_order)
    if st.session_state.get(order_key) is None:
        st.session_state[order_key] = base_order.copy()
    order = st.session_state.get(order_key, base_order)
    choice_labels = ["â‘ ", "â‘¡", "â‘¢", "â‘£"]
    label_value = str(row.get("label", "")).strip()
    if label_value:
        header = label_value
    else:
        year_display = format_year_value(row.get("year"))
        q_no_display = format_qno_value(row.get("q_no"))
        if year_display and q_no_display:
            header = f"{year_display} å•{q_no_display}"
        elif year_display:
            header = year_display
        elif q_no_display:
            header = f"å•{q_no_display}"
        else:
            header = "äºˆæƒ³å•é¡Œ"
    st.markdown(f"### {header}")
    category_value = str(row.get("category", "") or "").strip()
    topic_value = str(row.get("topic", "") or "").strip()
    tag_html = render_category_topic_tags(category_value, topic_value)
    if tag_html:
        st.markdown(tag_html, unsafe_allow_html=True)
    render_law_reference(row, db=db)
    st.markdown(row["question"], unsafe_allow_html=True)
    selected_choice = st.session_state.get(selected_key)
    graded_selected_choice: Optional[int] = None
    correct_choice_idx: Optional[int] = None
    explanation_summary = ""
    explanation_value = row.get("explanation")
    if pd.notna(explanation_value) and str(explanation_value).strip():
        explanation_summary, _ = parse_explanation_sections(explanation_value)
    if feedback:
        graded_selected_choice = feedback.get("selected_choice")
        correct_choice = feedback.get("correct_choice")
        if isinstance(correct_choice, int):
            correct_choice_idx = correct_choice - 1
    display_selected_choice = (
        graded_selected_choice
        if graded_selected_choice is not None
        else selected_choice
    )
    is_graded = feedback is not None and feedback.get("question_id") == row["id"]
    button_labels: List[str] = []
    for idx in range(0, len(order), 2):
        cols = st.columns(2)
        for col_idx in range(2):
            pos = idx + col_idx
            if pos >= len(order):
                continue
            actual_idx = order[pos]
            label_text = choices[actual_idx]
            display_label = f"{choice_labels[actual_idx]} {label_text}".strip()
            button_labels.append(display_label or choice_labels[actual_idx])
            button_key = f"{key_prefix}_choice_{row['id']}_{actual_idx}"
            wrapper_classes = ["takken-choice-button"]
            if is_graded:
                wrapper_classes.append("is-graded")
                if actual_idx == correct_choice_idx:
                    wrapper_classes.append("is-correct")
                elif graded_selected_choice == actual_idx:
                    wrapper_classes.append("is-incorrect")
                else:
                    wrapper_classes.append("is-dimmed")
            if display_selected_choice == actual_idx and not is_graded:
                wrapper_classes.append("is-selected")
            button_type = (
                "primary" if display_selected_choice == actual_idx and not is_graded else "secondary"
            )
            with cols[col_idx]:
                st.markdown(
                    f'<div class="{" ".join(wrapper_classes)}">',
                    unsafe_allow_html=True,
                )
                if st.button(
                    display_label or choice_labels[actual_idx],
                    key=button_key,
                    use_container_width=True,
                    type=button_type,
                ):
                    if not is_graded:
                        st.session_state[selected_key] = actual_idx
                        selected_choice = actual_idx
                        safe_rerun()
                st.markdown("</div>", unsafe_allow_html=True)
    st.caption("1ã€œ4ã‚­ãƒ¼ã§é¸æŠè‚¢ã‚’å³ç­”ã§ãã¾ã™ã€‚E:è§£èª¬ F:ãƒ•ãƒ©ã‚° N/P:ç§»å‹• H:ãƒ˜ãƒ«ãƒ— R:SRSãƒªã‚»ãƒƒãƒˆ")
    confidence_value = st.session_state.get(confidence_key)
    if confidence_value is None:
        confidence_value = 50
    else:
        confidence_value = int(confidence_value)
    confidence_value = st.slider(
        "ç¢ºä¿¡åº¦ï¼ˆãœã‚“ãœã‚“è‡ªä¿¡ãªã— â†” å®Œç’§ï¼‰",
        0,
        100,
        value=confidence_value,
        key=confidence_key,
    )
    show_explanation = st.session_state.get(explanation_key, False)
    flagged = row["id"] in set(st.session_state.get("review_flags", []))
    grade_label = "æ¡ç‚¹"
    explanation_label = "è§£èª¬ã‚’éš ã™" if show_explanation else "è§£èª¬ã‚’è¡¨ç¤º"
    flag_label = "ãƒ•ãƒ©ã‚°è§£é™¤" if flagged else "å¾©ç¿’ãƒ•ãƒ©ã‚°"
    help_label = "ãƒ˜ãƒ«ãƒ—"
    auto_advance_enabled = st.session_state["settings"].get("auto_advance", False)
    grade_clicked = False
    needs_rerun_after_grade = False
    help_visible = st.session_state.get(help_state_key, False)
    action_buttons = [
        {
            "id": "grade",
            "label": grade_label,
            "key": f"{key_prefix}_grade_{row['id']}",
            "type": "primary",
        },
        {
            "id": "toggle_explanation",
            "label": explanation_label,
            "key": f"{key_prefix}_toggle_explanation_{row['id']}",
        },
        {
            "id": "flag",
            "label": flag_label,
            "key": f"{key_prefix}_flag_{row['id']}",
        },
        {
            "id": "help",
            "label": help_label,
            "key": f"{key_prefix}_help_{row['id']}",
        },
    ]
    if enable_srs:
        action_buttons.append(
            {
                "id": "srs_reset",
                "label": "SRSãƒªã‚»ãƒƒãƒˆ",
                "key": f"{key_prefix}_srs_reset_{row['id']}",
            }
        )
    with st.container():
        st.markdown('<div class="takken-action-bar">', unsafe_allow_html=True)
        for action in action_buttons:
            st.markdown('<div class="takken-action-item">', unsafe_allow_html=True)
            button_kwargs = {
                "key": action["key"],
                "use_container_width": True,
            }
            if "type" in action:
                button_kwargs["type"] = action["type"]
            clicked = st.button(action["label"], **button_kwargs)
            if action["id"] == "grade" and clicked:
                grade_clicked = True
            elif action["id"] == "toggle_explanation" and clicked:
                show_explanation = not show_explanation
                st.session_state[explanation_key] = show_explanation
            elif action["id"] == "flag" and clicked:
                flags = set(st.session_state.get("review_flags", []))
                if flagged:
                    flags.discard(row["id"])
                else:
                    flags.add(row["id"])
                st.session_state["review_flags"] = list(flags)
            elif action["id"] == "help" and clicked:
                help_visible = not help_visible
                st.session_state[help_state_key] = help_visible
            elif action["id"] == "srs_reset" and clicked and enable_srs:
                db.upsert_srs(
                    row["id"],
                    {
                        "repetition": 0,
                        "interval": 1,
                        "ease": st.session_state["settings"].get("sm2_initial_ease", 2.5),
                        "due_date": dt.date.today(),
                        "last_grade": None,
                        "updated_at": dt.datetime.now(),
                    },
                )
                st.success("SRSã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸã€‚æ˜æ—¥ã‹ã‚‰å¾©ç¿’ã«å†æŠ•å…¥ã•ã‚Œã¾ã™ã€‚")
            st.markdown('</div>', unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)
    flagged = row["id"] in set(st.session_state.get("review_flags", []))
    help_visible = st.session_state.get(help_state_key, help_visible)
    if auto_advance_enabled and navigation and navigation.has_next:
        st.caption("æ¡ç‚¹å¾Œ0.8ç§’ã§æ¬¡å•ã«è‡ªå‹•é·ç§»ã—ã¾ã™ã€‚")
    if flagged:
        st.caption("ã“ã®å•é¡Œã¯å¾©ç¿’ãƒ•ãƒ©ã‚°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚")
    feedback = st.session_state.get(feedback_key)
    if grade_clicked:
        if selected_choice is None:
            st.warning("é¸æŠè‚¢ã‚’é¸ã‚“ã§ã‹ã‚‰æ¡ç‚¹ã—ã¦ãã ã•ã„ã€‚")
        else:
            correct_choice = row.get("correct")
            if pd.isna(correct_choice):
                st.warning("æ­£ç­”ãŒæœªç™»éŒ²ã®å•é¡Œã§ã™ã€‚è§£ç­”ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šè¾¼ã‚“ã§ãã ã•ã„ã€‚")
            else:
                correct_choice = int(correct_choice)
                is_correct = (selected_choice + 1) == correct_choice
                initial_ease = st.session_state["settings"].get("sm2_initial_ease", 2.5)
                grade_value = confidence_to_grade(is_correct, confidence_value)
                if enable_srs:
                    srs_row = db.fetch_srs(row["id"])
                    payload = sm2_update(srs_row, grade=grade_value, initial_ease=initial_ease)
                    db.upsert_srs(row["id"], payload)
                log_offline_attempt(
                    {
                        "timestamp": dt.datetime.now().isoformat(),
                        "question_id": row["id"],
                        "year": row.get("year"),
                        "q_no": row.get("q_no"),
                        "category": row.get("category"),
                        "topic": row.get("topic"),
                        "selected": selected_choice + 1,
                        "correct": correct_choice,
                        "is_correct": is_correct,
                        "mode": attempt_mode,
                        "confidence": confidence_value,
                        "srs_grade": grade_value,
                    }
                )
                st.session_state[feedback_key] = {
                    "is_correct": is_correct,
                    "correct_choice": correct_choice,
                    "question_id": row["id"],
                    "confidence": confidence_value,
                    "grade": grade_value,
                    "selected_choice": selected_choice,
                }
                feedback = st.session_state[feedback_key]
                if log_attempts:
                    db.record_attempt(
                        row["id"],
                        selected_choice + 1,
                        is_correct,
                        seconds=0,
                        mode=attempt_mode,
                        confidence=confidence_value,
                        grade=grade_value,
                    )
                if (
                    auto_advance_enabled
                    and navigation is not None
                    and navigation.has_next
                    and navigation.on_next is not None
                ):
                    time.sleep(0.8)
                    navigation.on_next()
                    safe_rerun()
                    needs_rerun_after_grade = False
                else:
                    needs_rerun_after_grade = True
    if grade_clicked and needs_rerun_after_grade:
        safe_rerun()
    if feedback and feedback.get("question_id") == row["id"]:
        correct_msg = choice_labels[feedback["correct_choice"] - 1]
        message = "æ­£è§£ã§ã™ï¼" if feedback["is_correct"] else f"ä¸æ­£è§£ã€‚æ­£ç­”ã¯ {correct_msg}"
        (st.success if feedback["is_correct"] else st.error)(message)
        if explanation_summary:
            summary_html = (
                f'<div class="takken-feedback-summary">ğŸ’¡ <span>{html_module.escape(explanation_summary)}</span></div>'
            )
            st.markdown(summary_html, unsafe_allow_html=True)
        st.caption(
            f"ç¢ºä¿¡åº¦ {feedback.get('confidence', confidence_value)}% â†’ å¾©ç¿’ã‚°ãƒ¬ãƒ¼ãƒ‰ {feedback.get('grade', '')}"
        )
    if show_explanation:
        st.markdown("#### è§£èª¬")
        render_explanation_content(row, db=db)
    if help_visible:
        st.info(
            """ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆä¸€è¦§\n- 1ã€œ4: é¸æŠè‚¢ã‚’é¸ã¶\n- E: è§£èª¬ã®è¡¨ç¤º/éè¡¨ç¤º\n- F: å¾©ç¿’ãƒ•ãƒ©ã‚°ã®åˆ‡ã‚Šæ›¿ãˆ\n- N/P: æ¬¡ã¸ãƒ»å‰ã¸\n- H: ã“ã®ãƒ˜ãƒ«ãƒ—"""
        )
    nav_prev_label = "å‰ã¸"
    nav_next_label = "æ¬¡ã¸"
    if navigation:
        nav_cols = st.columns([1, 1, 2])
        prev_kwargs = {
            "use_container_width": True,
            "disabled": not navigation.has_prev,
            "key": f"{key_prefix}_prev_{row['id']}",
        }
        next_kwargs = {
            "use_container_width": True,
            "disabled": not navigation.has_next,
            "key": f"{key_prefix}_next_{row['id']}",
        }
        if navigation.on_prev:
            prev_kwargs["on_click"] = navigation.on_prev
        if navigation.on_next:
            next_kwargs["on_click"] = navigation.on_next
        with nav_cols[0]:
            st.button(nav_prev_label, **prev_kwargs)
        with nav_cols[1]:
            st.button(nav_next_label, **next_kwargs)
        with nav_cols[2]:
            if navigation.label:
                st.caption(navigation.label)
    render_offline_downloads(f"{key_prefix}_{row['id']}")
    shortcut_map: Dict[str, str] = {}
    for idx, label in enumerate(button_labels[:4]):
        shortcut_map[str(idx + 1)] = label
    shortcut_map["e"] = explanation_label
    shortcut_map["f"] = flag_label
    shortcut_map["h"] = help_label
    if enable_srs:
        shortcut_map["r"] = "SRSãƒªã‚»ãƒƒãƒˆ"
    if navigation:
        shortcut_map["n"] = nav_next_label
        shortcut_map["p"] = nav_prev_label
    register_keyboard_shortcuts(shortcut_map)


def format_year_value(value: object) -> str:
    if value is None:
        return ""
    if isinstance(value, float) and np.isnan(value):
        return ""
    text = str(value).strip()
    if not text:
        return ""
    if text.isdigit():
        return f"{int(text)}å¹´"
    return text


def format_qno_value(value: object) -> str:
    if value is None:
        return ""
    if isinstance(value, float) and np.isnan(value):
        return ""
    text = str(value).strip()
    if not text:
        return ""
    if text.isdigit():
        return str(int(text))
    return text


def format_question_label(df: pd.DataFrame, question_id: str) -> str:
    if df.empty:
        return str(question_id)
    matches = df[df["id"] == question_id]
    if matches.empty:
        return f"æœªç™»éŒ²ã®å•é¡Œ ({question_id})"
    row = matches.iloc[0]
    year_value = row.get("year")
    if pd.isna(year_value):
        year_display = "?"
    elif isinstance(year_value, (int, np.integer)):
        year_display = int(year_value)
    elif isinstance(year_value, float):
        year_display = int(year_value)
    else:
        year_display = year_value
    q_no_value = row.get("q_no")
    if pd.isna(q_no_value):
        q_no_display = "?"
    elif isinstance(q_no_value, (int, np.integer)):
        q_no_display = int(q_no_value)
    elif isinstance(q_no_value, float):
        q_no_display = int(q_no_value)
    else:
        q_no_display = q_no_value
    category_value = row.get("category")
    if pd.isna(category_value):
        category_display = "ä¸æ˜"
    else:
        category_display = str(category_value).strip() or "ä¸æ˜"
    return f"{year_display}å¹´ å•{q_no_display} ({category_display})"


def build_law_reference_query(row: pd.Series) -> Optional[str]:
    insight = get_outline_insight(row)
    terms = insight.get("terms", [])
    if not terms:
        return None
    return " ".join(str(term) for term in terms if term)


def render_law_reference(row: pd.Series, db: Optional[DBManager] = None) -> None:
    insight = get_outline_insight(row)
    terms = insight.get("terms", [])
    query: Optional[str] = " ".join(terms) if terms else None
    caption_parts: List[str] = []
    if query:
        url = LAW_REFERENCE_BASE_URL.format(query=quote_plus(query))
        caption_parts.append(f"[æ¡æ–‡æ¤œç´¢]({url})")
    if caption_parts:
        st.caption(" ï½œ ".join(caption_parts))


def render_law_revision_metadata(row: pd.Series) -> None:
    details: List[str] = []
    law_name = row.get("law_name")
    if pd.notna(law_name) and str(law_name).strip():
        details.append(f"**æ³•ä»¤**: {str(law_name).strip()}")
    revision_year = row.get("revision_year")
    if pd.notna(revision_year) and str(revision_year).strip():
        try:
            details.append(f"**æ”¹æ­£å¹´åº¦**: {int(revision_year)}å¹´")
        except Exception:
            details.append(f"**æ”¹æ­£å¹´åº¦**: {revision_year}")
    effective_date = row.get("effective_date")
    if pd.notna(effective_date) and str(effective_date).strip():
        details.append(f"**æ–½è¡Œæ—¥**: {str(effective_date).strip()}")
    source = row.get("source")
    if pd.notna(source) and str(source).strip():
        details.append(f"**å‡ºå…¸**: {str(source).strip()}")
    tags = row.get("tags")
    if pd.notna(tags) and str(tags).strip():
        details.append(f"**ã‚¿ã‚°**: {str(tags).strip()}")
    if details:
        st.caption(" ï½œ ".join(details))


def render_question_preview(row: pd.Series, db: Optional[DBManager] = None) -> None:
    render_law_reference(row, db=db)
    question_text = row.get("question", "")
    if pd.isna(question_text):
        question_text = ""
    st.markdown(str(question_text), unsafe_allow_html=True)
    choice_labels = ["â‘ ", "â‘¡", "â‘¢", "â‘£"]
    for idx, label in enumerate(choice_labels, start=1):
        choice_text = row.get(f"choice{idx}")
        if pd.isna(choice_text):
            continue
        choice_text = str(choice_text)
        if not choice_text.strip():
            continue
        st.markdown(f"{label} {choice_text}", unsafe_allow_html=True)


def render_mock_exam(db: DBManager, df: pd.DataFrame) -> None:
    st.title("æ¨¡è©¦")
    if df.empty:
        st.warning("è¨­å•ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    with st.form("mock_exam_form"):
        year_mode = st.selectbox(
            "å‡ºé¡Œæ–¹å¼",
            ["æœ€æ–°å¹´åº¦", "å¹´åº¦é¸æŠ", "å±¤åŒ–ãƒ©ãƒ³ãƒ€ãƒ 50"],
            help="æœ€æ–°å¹´åº¦ã®å…¨å•ã€ä»»æ„å¹´åº¦ã®ã¿ã€ã¾ãŸã¯åˆ†é‡ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã£ãŸ50å•ã‹ã‚‰é¸ã¹ã¾ã™ã€‚",
        )
        if year_mode == "å¹´åº¦é¸æŠ":
            selected_year = st.selectbox(
                "å¹´åº¦",
                sorted(df["year"].unique(), reverse=True),
                help="æ¨¡è©¦ã«ä½¿ç”¨ã™ã‚‹å¹´åº¦ã‚’é¸æŠã—ã¾ã™ã€‚",
            )
            subset = df[df["year"] == selected_year]
            questions = list(subset["id"])
        elif year_mode == "æœ€æ–°å¹´åº¦":
            latest_year = df["year"].max()
            subset = df[df["year"] == latest_year]
            questions = list(subset["id"])
        else:
            questions = stratified_exam(df)
        submit = st.form_submit_button("æ¨¡è©¦é–‹å§‹", help="é¸æŠã—ãŸæ¡ä»¶ã§æ¨¡è©¦ã‚’é–‹å§‹ã—ã€å³åº§ã«è©¦é¨“ç”»é¢ã¸ç§»å‹•ã—ã¾ã™ã€‚")
    if submit:
        st.session_state.pop("exam_result_æ¨¡è©¦", None)
        st.session_state["exam_session"] = ExamSession(
            id=None,
            name=f"æ¨¡è©¦ {dt.datetime.now():%Y%m%d-%H%M}",
            questions=questions,
            started_at=dt.datetime.now(),
            year_mode=year_mode,
            mode="æ¨¡è©¦",
        )
    session: Optional[ExamSession] = st.session_state.get("exam_session")
    if session and session.mode == "æ¨¡è©¦":
        render_exam_session_body(db, df, session, key_prefix="mock")
    result = st.session_state.get("exam_result_æ¨¡è©¦")
    if result:
        display_exam_result(result)


def render_srs(db: DBManager, parent_nav: str = "å­¦ç¿’") -> None:
    render_specialized_header(parent_nav, "å¼±ç‚¹å¾©ç¿’", "srs")
    st.subheader("å¼±ç‚¹å¾©ç¿’")
    due_df = db.get_due_srs(upcoming_days=1)
    sidebar_alert = st.sidebar.container()
    sidebar_alert.subheader("å¾©ç¿’ã‚¢ãƒ©ãƒ¼ãƒˆ")

    if due_df.empty:
        st.info("ä»Šæ—¥å¾©ç¿’ã™ã¹ãå•é¡Œã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        sidebar_alert.success("æœŸé™ãŒè¿«ã‚‹å¾©ç¿’ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    status_labels = {
        "overdue": "æœŸé™åˆ‡ã‚Œ",
        "due_today": "æœ¬æ—¥æœŸé™",
        "due_tomorrow": "æ˜æ—¥æœŸé™",
        "upcoming": "è¿‘æ—¥æœŸé™",
        "unscheduled": "æœªè¨­å®š",
        "scheduled": "äºˆå®šã‚ã‚Š",
    }

    status_counts = due_df["due_status"].value_counts().to_dict()
    overdue_count = int(status_counts.get("overdue", 0))
    today_count = int(status_counts.get("due_today", 0))
    tomorrow_count = int(status_counts.get("due_tomorrow", 0))

    if overdue_count:
        st.error(f"{overdue_count}ä»¶ã®å¾©ç¿’ãŒæœŸé™åˆ‡ã‚Œã§ã™ã€‚ã™ãã«å¯¾å¿œã—ã¾ã—ã‚‡ã†ã€‚")
        sidebar_alert.error(f"æœŸé™åˆ‡ã‚Œ: {overdue_count}ä»¶")
    if today_count:
        st.warning(f"æœ¬æ—¥æœŸé™ã®å¾©ç¿’ãŒ{today_count}ä»¶ã‚ã‚Šã¾ã™ã€‚")
        sidebar_alert.warning(f"æœ¬æ—¥æœŸé™: {today_count}ä»¶")
    if tomorrow_count:
        st.info(f"æ˜æ—¥ãŒæœŸé™ã®å¾©ç¿’ãŒ{tomorrow_count}ä»¶ã‚ã‚Šã¾ã™ã€‚")
        sidebar_alert.info(f"æ˜æ—¥æœŸé™: {tomorrow_count}ä»¶")
    if not any([overdue_count, today_count, tomorrow_count]):
        sidebar_alert.success("æœŸé™ãŒè¿«ã‚‹å¾©ç¿’ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

    status_order = {"overdue": 0, "due_today": 1, "due_tomorrow": 2, "upcoming": 3, "unscheduled": 4, "scheduled": 5}

    def _normalize_due_date(value: Optional[dt.date]) -> dt.date:
        if value is None or pd.isna(value):
            return dt.date.max
        if isinstance(value, pd.Timestamp):
            return value.date()
        return value

    due_df = due_df.copy()
    due_df["_status_order"] = due_df["due_status"].map(lambda s: status_order.get(s, 99))
    due_df["_due_order"] = due_df["due_date"].apply(_normalize_due_date)
    due_df = due_df.sort_values(["_status_order", "_due_order"]).drop(columns=["_status_order", "_due_order"])

    for _, row in due_df.iterrows():
        question_title = str(row.get("question", ""))
        if len(question_title) > 40:
            question_title = f"{question_title[:40]}..."
        st.markdown(f"### {question_title}")
        due_date = row.get("due_date")
        due_display = due_date if pd.notna(due_date) else "æœªè¨­å®š"
        status_label = status_labels.get(row.get("due_status"), "")
        st.write(f"åˆ†é‡: {row['category']} ï½œ æœŸé™: {due_display} ({status_label})")
        grade = st.slider(
            f"è©•ä¾¡ ({row['question_id']})",
            0,
            5,
            3,
            help="5=å®Œå…¨ã«è¦šãˆãŸã€0=å…¨ãè¦šãˆã¦ã„ãªã„ã€‚è©•ä¾¡ã«å¿œã˜ã¦æ¬¡å›å¾©ç¿’æ—¥ãŒå¤‰ã‚ã‚Šã¾ã™ã€‚",
        )
        if st.button(
            "è©•ä¾¡ã‚’ä¿å­˜",
            key=f"srs_save_{row['question_id']}",
            help="SM-2ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«åŸºã¥ãæ¬¡å›ã®å‡ºé¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’æ›´æ–°ã—ã¾ã™ã€‚",
        ):
            initial_ease = st.session_state["settings"].get("sm2_initial_ease", 2.5)
            payload = sm2_update(row, grade, initial_ease=initial_ease)
            db.upsert_srs(row["question_id"], payload)
            st.success("SRSã‚’æ›´æ–°ã—ã¾ã—ãŸ")


def render_stats(db: DBManager, df: pd.DataFrame) -> None:
    st.title("åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    attempts = db.get_attempt_stats()
    if attempts.empty:
        st.info("çµ±è¨ˆæƒ…å ±ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã—ã‚‡ã†ã€‚")
        return
    try:
        attempts["created_at"] = pd.to_datetime(attempts["created_at"])
        attempts["seconds"] = pd.to_numeric(attempts.get("seconds"), errors="coerce")
        attempts["confidence"] = pd.to_numeric(attempts.get("confidence"), errors="coerce")
    except Exception as exc:
        st.error(f"å­¦ç¿’å±¥æ­´ã®æ•´å½¢ã«å¤±æ•—ã—ã¾ã—ãŸ ({exc})")
        st.info("CSVã‚’ç›´æ¥ç·¨é›†ã—ãŸå ´åˆã¯ã€æ—¥ä»˜ã‚„ç§’æ•°ã®åˆ—ãŒæ•°å€¤ãƒ»æ—¥æ™‚å½¢å¼ã«ãªã£ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return
    question_meta_cols = ["id", "question", "category", "topic", "tags", "difficulty", "year"]
    merged = attempts.merge(
        df[question_meta_cols],
        left_on="question_id",
        right_on="id",
        how="left",
        suffixes=("", "_question"),
    )
    for col in ["category", "topic"]:
        alt_col = f"{col}_question"
        if alt_col in merged.columns:
            if col in merged.columns:
                merged[col] = merged[col].fillna(merged[alt_col])
            else:
                merged[col] = merged[alt_col]
            merged = merged.drop(columns=[alt_col])
    if merged.empty:
        st.warning("é›†è¨ˆå¯¾è±¡ã®è¨­å•ãŒç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚è¨­å•ãƒ‡ãƒ¼ã‚¿ãŒå‰Šé™¤ã•ã‚Œã¦ã„ãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.info("ã€è¨­å®š ï¼ ãƒ‡ãƒ¼ã‚¿å…¥å‡ºåŠ›ã€ã§questions.csvã‚’å†åº¦å–ã‚Šè¾¼ã¿ã€è¨­å•IDã¨å­¦ç¿’å±¥æ­´ã®å¯¾å¿œã‚’å¾©å…ƒã§ãã¾ã™ã€‚")
        return
    with st.expander("çµã‚Šè¾¼ã¿", expanded=False):
        filter_cols = st.columns(3)
        category_options = sorted([c for c in merged["category"].dropna().unique()])
        year_options_series = merged.get("year")
        if year_options_series is not None:
            year_numeric = pd.to_numeric(year_options_series, errors="coerce")
            year_options = sorted({str(int(y)) for y in year_numeric.dropna().unique()}, reverse=True)
        else:
            year_options = []
        difficulty_series_full = pd.to_numeric(merged.get("difficulty"), errors="coerce")
        difficulty_options = sorted(difficulty_series_full.dropna().unique().tolist())
        selected_categories = filter_cols[0].multiselect(
            "åˆ†é‡",
            options=category_options,
            default=category_options,
            help="åˆ†æã«å«ã‚ã‚‹åˆ†é‡ã‚’é¸æŠã—ã¾ã™ã€‚",
        )
        selected_years = filter_cols[1].multiselect(
            "å¹´åº¦",
            options=year_options,
            default=year_options,
            help="å­¦ç¿’å±¥æ­´ã‚’é›†è¨ˆã™ã‚‹å¹´åº¦ã‚’é¸ã³ã¾ã™ã€‚",
        )
        selected_difficulties = filter_cols[2].multiselect(
            "é›£æ˜“åº¦",
            options=difficulty_options,
            default=difficulty_options,
            help="å¯¾è±¡ã¨ã™ã‚‹é›£æ˜“åº¦å¸¯ã‚’é¸æŠã—ã¾ã™ã€‚",
        )
    filtered = merged.copy()
    if selected_categories:
        filtered = filtered[filtered["category"].isin(selected_categories)]
    if selected_years:
        year_series = filtered.get("year")
        if year_series is not None:
            year_numeric = pd.to_numeric(year_series, errors="coerce")
            year_labels = year_numeric.apply(lambda x: str(int(x)) if pd.notna(x) else None)
            filtered = filtered[year_labels.isin(selected_years)]
        else:
            filtered = filtered.iloc[0:0]
    if selected_difficulties:
        diff_series = pd.to_numeric(filtered.get("difficulty"), errors="coerce")
        filtered = filtered[diff_series.isin(selected_difficulties)]
    if filtered.empty:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
        return
    accuracy_series = filtered["is_correct"].dropna()
    seconds_series = filtered["seconds"].dropna()
    confidence_series = filtered["confidence"].dropna()
    accuracy = accuracy_series.mean() if not accuracy_series.empty else np.nan
    avg_seconds = seconds_series.mean() if not seconds_series.empty else np.nan
    avg_confidence = confidence_series.mean() if not confidence_series.empty else np.nan
    st.subheader("ã‚µãƒãƒªãƒ¼")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æŒ‘æˆ¦å›æ•°", f"{len(filtered)} å›")
    with col2:
        accuracy_text = f"{accuracy * 100:.1f}%" if not np.isnan(accuracy) else "--"
        st.metric("å¹³å‡æ­£ç­”ç‡", accuracy_text)
    with col3:
        st.metric("å¹³å‡è§£ç­”æ™‚é–“", f"{avg_seconds:.1f} ç§’" if not np.isnan(avg_seconds) else "--")
    if not np.isnan(avg_confidence):
        st.caption(f"å¹³å‡ç¢ºä¿¡åº¦: {avg_confidence:.1f}%")
    else:
        st.caption("å¹³å‡ç¢ºä¿¡åº¦: -- (ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“)")

    import altair as alt

    st.subheader("å­¦ç¿’æ™‚é–“ã¨æŒ‘æˆ¦å›æ•°ã®æ¨ç§»")
    freq = st.selectbox("é›†è¨ˆç²’åº¦", ["æ—¥æ¬¡", "é€±æ¬¡"], index=0, help="å­¦ç¿’æ™‚é–“ã¨æŒ‘æˆ¦å›æ•°ã®æ¨ç§»ã‚’é›†è¨ˆã™ã‚‹ç²’åº¦ã‚’åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚")
    timeline = filtered.copy()
    if freq == "é€±æ¬¡":
        timeline["period"] = timeline["created_at"].dt.to_period("W").dt.start_time
    else:
        timeline["period"] = timeline["created_at"].dt.normalize()
    timeline_grouped = (
        timeline.groupby("period")
        .agg(
            attempts_count=("is_correct", "count"),
            total_seconds=("seconds", "sum"),
        )
        .reset_index()
        .rename(columns={"period": "date"})
    )
    timeline_grouped = timeline_grouped.sort_values("date")
    timeline_grouped["å­¦ç¿’æ™‚é–“ (åˆ†)"] = timeline_grouped["total_seconds"].fillna(0) / 60
    timeline_grouped["æŒ‘æˆ¦å›æ•°"] = timeline_grouped["attempts_count"].fillna(0)
    if timeline_grouped.empty:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
    else:
        try:
            time_base = alt.Chart(timeline_grouped).encode(
                x=alt.X("date:T", title="æ—¥ä»˜"),
                tooltip=[
                    alt.Tooltip("date:T", title="æ—¥ä»˜"),
                    alt.Tooltip("æŒ‘æˆ¦å›æ•°", format=","),
                    alt.Tooltip("å­¦ç¿’æ™‚é–“ (åˆ†)", format=".1f"),
                ],
            )
            attempts_layer = time_base.mark_bar(opacity=0.5, color="#2563eb").encode(
                y=alt.Y("æŒ‘æˆ¦å›æ•°:Q", title="æŒ‘æˆ¦å›æ•°")
            )
            minutes_layer = time_base.mark_line(point=True, color="#f97316").encode(
                y=alt.Y("å­¦ç¿’æ™‚é–“ (åˆ†):Q", title="å­¦ç¿’æ™‚é–“ (åˆ†)", axis=alt.Axis(titleColor="#f97316"))
            )
            time_chart = alt.layer(attempts_layer, minutes_layer).resolve_scale(y="independent")
            st.altair_chart(time_chart, use_container_width=True)
        except Exception as exc:
            st.warning(f"å­¦ç¿’æ™‚é–“ã®æ¨ç§»ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã§ã—ãŸ ({exc})")
            st.caption("ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒé›†ã¾ã‚‹ã¨è‡ªå‹•ã§è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

    st.subheader("åˆ†é‡åˆ¥åˆ†æ")
    category_stats = (
        filtered.groupby("category")
        .agg(
            accuracy=("is_correct", "mean"),
            avg_seconds=("seconds", "mean"),
            attempts_count=("is_correct", "count"),
        )
        .reset_index()
    )
    if category_stats.empty:
        st.info("åˆ†é‡æƒ…å ±ã®ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚questions.csv ã® category åˆ—ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    else:
        try:
            accuracy_chart = (
                alt.Chart(category_stats)
                .mark_bar()
                .encode(
                    x=alt.X("category", title="åˆ†é‡"),
                    y=alt.Y("accuracy", title="æ­£ç­”ç‡", axis=alt.Axis(format="%")),
                    tooltip=["category", alt.Tooltip("accuracy", format=".2%"), "attempts_count"],
                )
                .properties(height=320)
            )
            st.altair_chart(accuracy_chart, use_container_width=True)
        except Exception as exc:
            st.warning(f"åˆ†é‡åˆ¥æ­£ç­”ç‡ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã§ã—ãŸ ({exc})")
            st.caption("ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒé›†ã¾ã‚‹ã¨è‡ªå‹•ã§è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
        try:
            time_chart = (
                alt.Chart(category_stats)
                .mark_line(point=True)
                .encode(
                    x=alt.X("category", title="åˆ†é‡"),
                    y=alt.Y("avg_seconds", title="å¹³å‡è§£ç­”æ™‚é–“ (ç§’)", scale=alt.Scale(zero=False)),
                    tooltip=["category", alt.Tooltip("avg_seconds", format=".1f"), "attempts_count"],
                )
            )
            st.altair_chart(time_chart, use_container_width=True)
        except Exception as exc:
            st.warning(f"åˆ†é‡åˆ¥æ™‚é–“ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã§ã—ãŸ ({exc})")
            st.caption("ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒé›†ã¾ã‚‹ã¨è‡ªå‹•ã§è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

    st.subheader("æ­£ç­”ç‡ãŒä½ã„è«–ç‚¹")
    topic_stats = (
        filtered.dropna(subset=["topic"])
        .groupby(["category", "topic"])
        .agg(
            accuracy=("is_correct", "mean"),
            attempts_count=("is_correct", "count"),
        )
        .reset_index()
    )
    low_accuracy = (
        topic_stats[topic_stats["attempts_count"] >= 3]
        .sort_values("accuracy")
        .head(10)
        .copy()
    )
    if low_accuracy.empty:
        st.info("ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å­¦ç¿’ã‚’é‡ã­ã¦å‚¾å‘ã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†ã€‚")
    else:
        low_accuracy["æ­£ç­”ç‡"] = (low_accuracy["accuracy"] * 100).round(1)
        display_cols = low_accuracy[["category", "topic", "attempts_count", "æ­£ç­”ç‡"]]
        display_cols = display_cols.rename(columns={"category": "åˆ†é‡", "topic": "è«–ç‚¹", "attempts_count": "æŒ‘æˆ¦å›æ•°"})
        st.dataframe(display_cols, use_container_width=True)
        if st.button("å¾©ç¿’ãƒ¢ãƒ¼ãƒ‰ã§é‡ç‚¹å¾©ç¿’", type="primary"):
            st.session_state["nav"] = "å¼±ç‚¹å¾©ç¿’"
            st.session_state["_nav_widget"] = "å¼±ç‚¹å¾©ç¿’"
            safe_rerun()

    st.subheader("ç¢ºä¿¡åº¦ã¨æ­£ç­”ã®ç›¸é–¢")
    valid_conf = filtered.dropna(subset=["confidence"])
    if valid_conf.empty:
        st.info("ç¢ºä¿¡åº¦ãƒ‡ãƒ¼ã‚¿ãŒã¾ã ååˆ†ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å­¦ç¿’æ™‚ã«ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã§è‡ªå·±è©•ä¾¡ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚")
    else:
        corr = valid_conf["confidence"].corr(valid_conf["is_correct"])
        st.metric("ç›¸é–¢ä¿‚æ•°", f"{corr:.2f}")
        try:
            scatter = (
                alt.Chart(valid_conf)
                .mark_circle(opacity=0.6)
                .encode(
                    x=alt.X("confidence", title="ç¢ºä¿¡åº¦ (%)"),
                    y=alt.Y("is_correct", title="æ­£ç­” (1=æ­£è§£)", scale=alt.Scale(domain=[-0.1, 1.1])),
                    color=alt.Color("category", legend=None),
                    tooltip=["category", "topic", "confidence", "is_correct", "seconds"],
                )
            )
            st.altair_chart(scatter, use_container_width=True)
        except Exception as exc:
            st.warning(f"ç›¸é–¢æ•£å¸ƒå›³ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã§ã—ãŸ ({exc})")
            st.caption("ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒé›†ã¾ã‚‹ã¨è‡ªå‹•ã§è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

    st.subheader("ã²ã£ã‹ã‘èªå½™ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
    heatmap_df = compute_tricky_vocab_heatmap(filtered, df)
    if heatmap_df.empty:
        st.info("èª¤ç­”èªå½™ã®ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        try:
            word_order = (
                heatmap_df.groupby("word")["count"].sum().sort_values(ascending=False).index.tolist()
            )
            heatmap = (
                alt.Chart(heatmap_df)
                .mark_rect()
                .encode(
                    x=alt.X("category", title="åˆ†é‡"),
                    y=alt.Y("word", title="èªå½™", sort=word_order),
                    color=alt.Color("count", title="èª¤ç­”å›æ•°", scale=alt.Scale(scheme="reds")),
                    tooltip=["word", "category", "count"],
                )
            )
            st.altair_chart(heatmap, use_container_width=True)
        except Exception as exc:
            st.warning(f"èªå½™ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã§ã—ãŸ ({exc})")
            st.caption("ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒé›†ã¾ã‚‹ã¨è‡ªå‹•ã§è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

    st.subheader("æœ€ã‚‚æ”¹å–„ã—ãŸè«–ç‚¹")
    improvement = compute_most_improved_topic(filtered, df)
    if improvement:
        st.success(
            f"{improvement['topic']}ï¼šæ­£ç­”ç‡ãŒ {(improvement['early'] * 100):.1f}% â†’ {(improvement['late'] * 100):.1f}% (ï¼‹{improvement['delta'] * 100:.1f}ãƒã‚¤ãƒ³ãƒˆ)"
        )
    else:
        st.info("æ”¹å–„ã®å‚¾å‘ã‚’ç¤ºã™è«–ç‚¹ã¯ã¾ã æ¤œå‡ºã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç¶™ç¶šã—ã¦å­¦ç¿’ã—ã¾ã—ã‚‡ã†ã€‚")


def select_uploaded_file_by_name(
    files: Sequence["UploadedFile"], keyword: str
) -> Optional["UploadedFile"]:
    keyword_lower = keyword.lower()
    for file in files:
        if keyword_lower in file.name.lower():
            return file
    return None


def execute_quick_import(
    db: DBManager,
    questions_file: Optional["UploadedFile"],
    answers_file: Optional["UploadedFile"],
) -> None:
    quick_errors: List[str] = []
    questions_df: Optional[pd.DataFrame] = None
    answers_df: Optional[pd.DataFrame] = None
    if questions_file is None and answers_file is None:
        st.warning("questions.csv ã‹ answers.csv ã®ã„ãšã‚Œã‹ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return

    if questions_file is not None:
        data = questions_file.getvalue()
        try:
            questions_df = pd.read_csv(io.BytesIO(data))
        except UnicodeDecodeError:
            questions_df = pd.read_csv(io.BytesIO(data), encoding="cp932")
        quick_errors.extend(validate_question_records(questions_df))

    if answers_file is not None:
        data = answers_file.getvalue()
        try:
            answers_df = pd.read_csv(io.BytesIO(data))
        except UnicodeDecodeError:
            answers_df = pd.read_csv(io.BytesIO(data), encoding="cp932")
        quick_errors.extend(validate_answer_records(answers_df))

    if quick_errors:
        for err in quick_errors:
            st.error(err)
        st.info("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®åˆ—æ§‹æˆã¨çªåˆã—ã¦ãã ã•ã„ã€‚ã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€ã‹ã‚‰æœ€æ–°ã®CSVã‚µãƒ³ãƒ—ãƒ«ã‚’å–å¾—ã§ãã¾ã™ã€‚")
        return

    policy = {"explanation": "overwrite", "tags": "merge"}
    merged_df: Optional[pd.DataFrame] = None
    rejects_q = pd.DataFrame()
    rejects_a = pd.DataFrame()
    conflicts = pd.DataFrame()
    normalization_failed = False

    if questions_df is not None:
        try:
            normalized_q = normalize_questions(questions_df)
        except Exception as exc:
            st.error(f"questions.csv ã®æ•´å½¢ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")
            normalization_failed = True
            normalized_q = None
    else:
        normalized_q = None

    if answers_df is not None:
        try:
            normalized_a = normalize_answers(answers_df)
        except Exception as exc:
            st.error(f"answers.csv ã®æ•´å½¢ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")
            normalization_failed = True
            normalized_a = None
    else:
        normalized_a = None

    if normalization_failed:
        st.warning("åˆ—åã‚„å€¤ã®å½¢å¼ã‚’è¦‹ç›´ã—ã¦ã‹ã‚‰å†åº¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚")
        return

    if normalized_q is not None and normalized_a is not None:
        merged_df, rejects_q, rejects_a, conflicts = merge_questions_answers(
            normalized_q, normalized_a, policy=policy
        )
    elif normalized_q is not None:
        merged_df = normalized_q
    elif normalized_a is not None:
        existing = load_questions_df()
        if existing.empty:
            st.error("è¨­å•ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚answers.csv ã‚’å–ã‚Šè¾¼ã‚€å‰ã« questions.csv ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
        else:
            merged_df, rejects_q, rejects_a, conflicts = merge_questions_answers(
                existing, normalized_a, policy=policy
            )

    if merged_df is None:
        return

    inserted, updated = db.upsert_questions(merged_df)
    rebuild_tfidf_cache()
    st.success(f"ã‚¯ã‚¤ãƒƒã‚¯ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚è¿½åŠ  {inserted} ä»¶ / æ›´æ–° {updated} ä»¶")

    if not rejects_q.empty or not rejects_a.empty:
        st.warning(
            f"å–ã‚Šè¾¼ã‚ãªã‹ã£ãŸãƒ¬ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã™ã€‚questions: {len(rejects_q)} ä»¶ / answers: {len(rejects_a)} ä»¶"
        )
        with st.expander("å–ã‚Šè¾¼ã‚ãªã‹ã£ãŸè¡Œã®è©³ç´°", expanded=False):
            if not rejects_q.empty:
                st.markdown("**questions.csv**")
                st.dataframe(rejects_q.head(20))
            if not rejects_a.empty:
                st.markdown("**answers.csv**")
                st.dataframe(rejects_a.head(20))
            st.caption("ç†ç”±åˆ—ã‚’å‚è€ƒã«CSVã®è©²å½“è¡Œã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚å…¨ä»¶ã¯rejects_*.csvã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚")

    if not conflicts.empty:
        st.info(f"æ­£ç­”ã®è¡çªãŒ {len(conflicts)} ä»¶ã‚ã‚Šã€ä¸Šæ›¸ãã—ã¾ã—ãŸã€‚")


def render_quick_import_controls(
    db: DBManager,
    *,
    key_prefix: str,
    heading: Optional[str] = None,
    initial_files: Optional[Sequence["UploadedFile"]] = None,
) -> None:
    if heading:
        st.markdown(heading)

    st.caption("questions.csv ã¨ answers.csv ã‚’ã¾ã¨ã‚ã¦ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—ã§ãã¾ã™ã€‚å¿…è¦ãªæ–¹ã ã‘ã§ã‚‚å–ã‚Šè¾¼ã‚ã¾ã™ã€‚")

    uploaded_files = st.file_uploader(
        "questions.csv / answers.csv ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=["csv"],
        accept_multiple_files=True,
        key=f"{key_prefix}_quick_import_files",
        help="è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åŒæ™‚ã«é¸æŠã™ã‚‹ã¨è‡ªå‹•ã§å€™è£œã«å…¥ã‚Šã¾ã™ã€‚",
    )

    combined_files: List["UploadedFile"] = []
    seen_names: Set[str] = set()

    def add_file(file: "UploadedFile") -> None:
        if file.name not in seen_names:
            combined_files.append(file)
            seen_names.add(file.name)

    if initial_files:
        for file in initial_files:
            add_file(file)
        st.caption("ãƒ‰ãƒ­ãƒƒãƒ—ã‚¾ãƒ¼ãƒ³ã«è¿½åŠ ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒå€™è£œã¨ã—ã¦è¡¨ç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚")

    if uploaded_files:
        for file in uploaded_files:
            add_file(file)

    option_files = combined_files
    question_default = select_uploaded_file_by_name(option_files, "questions") or select_uploaded_file_by_name(option_files, "question")
    answer_default = select_uploaded_file_by_name(option_files, "answers") or select_uploaded_file_by_name(option_files, "answer")

    options = ["é¸æŠã—ãªã„"] + [file.name for file in option_files]

    def get_default_index(default_file: Optional["UploadedFile"]) -> int:
        if default_file is None:
            return 0
        try:
            return option_files.index(default_file) + 1
        except ValueError:
            return 0

    question_index = get_default_index(question_default)
    answer_index = get_default_index(answer_default)

    if not option_files:
        st.caption("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã™ã‚‹ã¨ã“ã“ã«ä¸€è¦§è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚ä¸Šéƒ¨ã®ãƒ‰ãƒ­ãƒƒãƒ—ã‚¾ãƒ¼ãƒ³ã‹å³ã®ãƒœã‚¿ãƒ³ã‹ã‚‰è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")

    question_selection = st.selectbox(
        "questions.csv", options, index=question_index, key=f"{key_prefix}_quick_import_question"
    )
    answer_selection = st.selectbox(
        "answers.csv", options, index=answer_index, key=f"{key_prefix}_quick_import_answer"
    )

    def resolve_selection(selection: str) -> Optional["UploadedFile"]:
        if selection == "é¸æŠã—ãªã„":
            return None
        for file in option_files:
            if file.name == selection:
                return file
        return None

    selected_questions = resolve_selection(question_selection)
    selected_answers = resolve_selection(answer_selection)

    if st.button("ã‚¯ã‚¤ãƒƒã‚¯ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ", key=f"{key_prefix}_quick_import_button"):
        execute_quick_import(db, selected_questions, selected_answers)


def render_history_export_controls(
    db: DBManager,
    *,
    heading: Optional[str] = None,
) -> None:
    if heading:
        st.markdown(heading)

    with db.engine.connect() as conn:
        attempts_df = pd.read_sql(select(attempts_table), conn)
        exams_df = pd.read_sql(select(exams_table), conn)

    if not attempts_df.empty:
        buffer = io.StringIO()
        attempts_df.to_csv(buffer, index=False)
        st.download_button("attempts.csv ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", buffer.getvalue(), file_name="attempts.csv", mime="text/csv")
    else:
        st.caption("attempts.csvï¼šå­¦ç¿’å±¥æ­´ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã§è§£ç­”ã™ã‚‹ã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã«ãªã‚Šã¾ã™ã€‚")

    if not exams_df.empty:
        buffer = io.StringIO()
        exams_df.to_csv(buffer, index=False)
        st.download_button("exams.csv ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", buffer.getvalue(), file_name="exams.csv", mime="text/csv")
    else:
        st.caption("exams.csvï¼šæ¨¡è©¦ã®å—é¨“å±¥æ­´ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚æ¨¡è©¦ãƒ¢ãƒ¼ãƒ‰ã§æœ¬è©¦é¨“ã‚’ä½“é¨“ã—ã¾ã—ã‚‡ã†ã€‚")

    if DB_PATH.exists():
        st.download_button("SQLiteãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", DB_PATH.read_bytes(), file_name="takken.db")


def render_data_io(db: DBManager, parent_nav: str = "è¨­å®š") -> None:
    render_specialized_header(parent_nav, "ãƒ‡ãƒ¼ã‚¿å…¥å‡ºåŠ›", "data_io")
    st.subheader("ãƒ‡ãƒ¼ã‚¿å…¥å‡ºåŠ›")
    timestamp = dt.datetime.now().strftime("%Y%m%d-%H%M%S")
    import_notifications = st.session_state.setdefault("import_notifications", [])
    if import_notifications:
        st.markdown("### ã‚¤ãƒ³ãƒãƒ¼ãƒˆå±¥æ­´ (ã“ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³)")
        history_df = pd.DataFrame(import_notifications)
        ordered_columns = [
            col
            for col in ["timestamp", "inserted", "updated", "rejected", "seconds"]
            if col in history_df.columns
        ]
        display_df = history_df[ordered_columns].rename(
            columns={
                "timestamp": "å®Œäº†æ™‚åˆ»",
                "inserted": "è¿½åŠ ",
                "updated": "æ›´æ–°",
                "rejected": "ãƒªã‚¸ã‚§ã‚¯ãƒˆ",
                "seconds": "å‡¦ç†ç§’æ•°",
            }
        )
        st.dataframe(display_df, use_container_width=True)
    st.markdown("### ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«")
    st.download_button(
        "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (ZIP)",
        data=get_template_archive(),
        file_name=f"takken_templates_{timestamp}.zip",
        mime="application/zip",
    )
    st.caption("è¨­å•ãƒ»æ­£ç­”ãƒ‡ãƒ¼ã‚¿ã®CSV/XLSXãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒå«ã¾ã‚Œã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦ç·¨é›†ã—ã¦ã”åˆ©ç”¨ãã ã•ã„ã€‚")
    if SCHEMA_GUIDE_PATH.exists():
        st.markdown(
            "ğŸ“˜ ãƒ‡ãƒ¼ã‚¿åˆ—ã®è©³ç´°ä»•æ§˜ã¯ä¸‹è¨˜ã®ã‚¹ã‚­ãƒ¼ãƒã‚¬ã‚¤ãƒ‰ã§ç¢ºèªã§ãã¾ã™ã€‚ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç·¨é›†å‰ã«ã”è¦§ãã ã•ã„ã€‚"
        )
        with st.expander("questions.csv / answers.csv / law_revision.csv ã®ã‚¹ã‚­ãƒ¼ãƒã‚¬ã‚¤ãƒ‰"):
            st.markdown(SCHEMA_GUIDE_PATH.read_text(encoding="utf-8"))
    sample_cols = st.columns(4)
    with sample_cols[0]:
        st.download_button(
            "ã‚µãƒ³ãƒ—ãƒ« questions.csv",
            data=build_sample_questions_csv(),
            file_name="sample_questions.csv",
            mime="text/csv",
            help="Excelã§é–‹ã„ã¦å€¤ã‚’ä¸Šæ›¸ãã™ã‚Œã°ã€ãã®ã¾ã¾å–ã‚Šè¾¼ã¿ã§ãã¾ã™ã€‚",
        )
    with sample_cols[1]:
        st.download_button(
            "ã‚µãƒ³ãƒ—ãƒ« answers.csv",
            data=build_sample_answers_csv(),
            file_name="sample_answers.csv",
            mime="text/csv",
            help="æ­£ç­”ç•ªå·ã‚„è§£èª¬ã®è¨˜å…¥ä¾‹ã§ã™ã€‚ã‚³ãƒ”ãƒ¼ã—ã¦ã”åˆ©ç”¨ãã ã•ã„ã€‚",
        )
    with sample_cols[2]:
        st.download_button(
            "ã‚µãƒ³ãƒ—ãƒ« predicted.csv",
            data=build_sample_predicted_csv(),
            file_name="sample_predicted.csv",
            mime="text/csv",
            help="äºˆæƒ³å•é¡Œã®å…¥åŠ›ä¾‹ã§ã™ã€‚ãƒ©ãƒ™ãƒ«ã‚„å‡ºå…¸ã‚’è¨˜å…¥ã—ã¦æ´»ç”¨ãã ã•ã„ã€‚",
        )
    with sample_cols[3]:
        st.download_button(
            "ã‚µãƒ³ãƒ—ãƒ« law_revision.csv",
            data=build_sample_law_revision_csv(),
            file_name="sample_law_revision.csv",
            mime="text/csv",
            help="æœ€æ–°ã®æ³•æ”¹æ­£è«–ç‚¹ã‚’æ•´ç†ã—ãŸå•é¡Œã‚µãƒ³ãƒ—ãƒ«ã§ã™ã€‚æ”¹æ­£å¹´åº¦ã‚„æ–½è¡Œæ—¥ã‚’è¿½è¨˜ã—ã¦ã”åˆ©ç”¨ãã ã•ã„ã€‚",
        )
    st.markdown("### å¤–éƒ¨ã‚µãƒ¼ãƒ“ã‚¹åŒæœŸ")
    integrations = st.session_state["settings"].setdefault("integrations", {})
    integration_status = st.session_state.setdefault(
        "integration_status",
        {
            "google_calendar": {"last_synced": None, "message": "æœªåŒæœŸ", "success": False},
            "notion": {"last_synced": None, "message": "æœªåŒæœŸ", "success": False},
        },
    )
    google_settings = integrations.get("google_calendar", {})
    google_status = integration_status.setdefault(
        "google_calendar", {"last_synced": None, "message": "æœªåŒæœŸ", "success": False}
    )
    notion_settings = integrations.get("notion", {})
    notion_status = integration_status.setdefault(
        "notion", {"last_synced": None, "message": "æœªåŒæœŸ", "success": False}
    )
    sync_cols = st.columns(2)
    with sync_cols[0]:
        st.markdown("#### Google Calendar")
        last_synced = google_status.get("last_synced")
        message = google_status.get("message", "æœªåŒæœŸ")
        if last_synced:
            st.caption(f"æœ€çµ‚åŒæœŸ: {last_synced} / {message}")
        else:
            st.caption(f"çŠ¶æ…‹: {message}")
        allow_resync = False
        if google_status.get("success"):
            allow_resync = st.checkbox("å†åŒæœŸã‚’è¨±å¯", key="google_calendar_resync")
        google_disabled = google_status.get("success") and not allow_resync
        if st.button("ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’Google Calendarã¸åŒæœŸ", disabled=google_disabled):
            due_df = db.get_due_srs()
            if due_df.empty:
                msg = "åŒæœŸå¯¾è±¡ã®å­¦ç¿’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
                google_status.update({"message": msg, "success": False})
                st.info(msg)
            else:
                credentials = OAuthCredentials(
                    client_id=google_settings.get("client_id", ""),
                    client_secret=google_settings.get("client_secret", ""),
                    redirect_uri=google_settings.get("redirect_uri", ""),
                    access_token=google_settings.get("access_token", ""),
                    refresh_token=google_settings.get("refresh_token", ""),
                )
                client = GoogleCalendarClient(
                    GoogleCalendarConfig(credentials=credentials, calendar_id=google_settings.get("calendar_id", "primary"))
                )
                try:
                    result = client.sync_study_schedule(due_df)
                except IntegrationConfigError as exc:
                    msg = str(exc)
                    google_status.update({"message": msg, "success": False})
                    st.error(msg)
                except IntegrationError as exc:
                    msg = str(exc)
                    google_status.update({"message": msg, "success": False})
                    st.error(msg)
                else:
                    now_text = dt.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    detail = f"ã‚¤ãƒ™ãƒ³ãƒˆ {result['created']} ä»¶ã‚’åŒæœŸã—ã¾ã—ãŸã€‚"
                    if result.get("failures"):
                        detail += f" ä¸€éƒ¨å¤±æ•— {len(result['failures'])} ä»¶ã€‚"
                    google_status.update({"message": detail, "success": True, "last_synced": now_text})
                    st.success(detail)
    with sync_cols[1]:
        st.markdown("#### Notion")
        last_synced = notion_status.get("last_synced")
        message = notion_status.get("message", "æœªåŒæœŸ")
        if last_synced:
            st.caption(f"æœ€çµ‚åŒæœŸ: {last_synced} / {message}")
        else:
            st.caption(f"çŠ¶æ…‹: {message}")
        allow_resync = False
        if notion_status.get("success"):
            allow_resync = st.checkbox("å†åŒæœŸã‚’è¨±å¯", key="notion_resync")
        notion_disabled = notion_status.get("success") and not allow_resync
        notion_days = st.slider("é€ä¿¡å¯¾è±¡æ—¥æ•°", min_value=1, max_value=30, value=7, key="notion_sync_days")
        if st.button("å­¦ç¿’ãƒ­ã‚°ã‚’Notionãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸é€ä¿¡", disabled=notion_disabled):
            attempts = db.get_attempt_stats()
            summaries = build_notion_summaries(attempts, days=notion_days)
            client = NotionClient(
                NotionConfig(
                    integration_token=notion_settings.get("integration_token", ""),
                    database_id=notion_settings.get("database_id", ""),
                    notion_version=notion_settings.get("notion_version", "2022-06-28"),
                )
            )
            if not summaries:
                msg = "é€ä¿¡å¯¾è±¡ã®å­¦ç¿’ãƒ­ã‚°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
                notion_status.update({"message": msg, "success": False})
                st.info(msg)
            else:
                try:
                    result = client.sync_learning_log(summaries)
                except IntegrationConfigError as exc:
                    msg = str(exc)
                    notion_status.update({"message": msg, "success": False})
                    st.error(msg)
                except IntegrationError as exc:
                    msg = str(exc)
                    notion_status.update({"message": msg, "success": False})
                    st.error(msg)
                else:
                    now_text = dt.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    detail = f"{result['created']} æ—¥åˆ†ã®å­¦ç¿’ãƒ­ã‚°ã‚’é€ä¿¡ã—ã¾ã—ãŸã€‚"
                    if result.get("failures"):
                        detail += f" é€ä¿¡å¤±æ•— {len(result['failures'])} ä»¶ã€‚"
                    notion_status.update({"message": detail, "success": True, "last_synced": now_text})
                    st.success(detail)
    st.markdown("### å­¦ç¿’æ™‚é–“ãƒ­ã‚°å–ã‚Šè¾¼ã¿")
    st.caption("ã‚¹ãƒãƒ¼ãƒˆã‚¦ã‚©ãƒƒãƒã‚„å¤–éƒ¨è¨˜éŒ²ãƒ„ãƒ¼ãƒ«ã‹ã‚‰å‡ºåŠ›ã—ãŸCSV/JSONã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ attempts ã«åæ˜ ã—ã¾ã™ã€‚question_idã€ã¾ãŸã¯å¹´åº¦ã¨å•ç•ªå·ã§å•é¡Œã‚’ç‰¹å®šã—ã¾ã™ã€‚")
    log_files = st.file_uploader(
        "å­¦ç¿’ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
        type=["csv", "json"],
        accept_multiple_files=True,
        key="external_log_uploader",
    )
    if log_files and st.button("å­¦ç¿’ãƒ­ã‚°ã‚’ç™»éŒ²", key="external_log_apply"):
        questions_df = load_questions_df()
        total_inserted = 0
        parse_errors: List[str] = []
        for log_file in log_files:
            records, errors = parse_external_attempt_logs(log_file, questions_df)
            parse_errors.extend(errors)
            if records:
                total_inserted += db.bulk_insert_attempts(records)
        if total_inserted:
            st.success(f"{total_inserted}ä»¶ã®å­¦ç¿’ãƒ­ã‚°ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")
        if parse_errors:
            for err in parse_errors:
                st.warning(err)
    st.caption("ã‚µãƒ³ãƒ—ãƒ«CSVã¯Excelã«è²¼ã‚Šä»˜ã‘ã¦ä½¿ãˆã‚‹ã‚ˆã†åˆ—å¹…ã‚’èª¿æ•´æ¸ˆã¿ã§ã™ã€‚ã‚³ãƒ”ãƒ¼&ãƒšãƒ¼ã‚¹ãƒˆã§æ‰‹æ—©ãç™»éŒ²ã§ãã¾ã™ã€‚")
    st.markdown("### æ³•æ”¹æ­£è‡ªå‹•æ›´æ–°")
    st.caption("ä¸å‹•ç”£é©æ­£å–å¼•æ¨é€²æ©Ÿæ§‹ã‚„å°‚é–€äºˆå‚™æ ¡ã®å…¬é–‹ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’ HTTP çµŒç”±ã§å–å¾—ã—ã€è‡ªå‹•ã§æ³•æ”¹æ­£å•é¡Œã‚’ç”Ÿæˆãƒ»ç™»éŒ²ã—ã¾ã™ã€‚")
    if st.button("æœ€æ–°ã®æ³•æ”¹æ­£ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’å–å¾—", key="law_revision_sync_button"):
        service = get_law_update_service(db)
        with st.spinner("æœ€æ–°æƒ…å ±ã‚’å–å¾—ã—ã¦ã„ã¾ã™..."):
            results = service.run(db)
        success_results = [r for r in results if r.status in {"success", "empty"}]
        if any(r.status == "success" for r in success_results):
            st.success("è‡ªå‹•å–å¾—ã¨å•é¡Œç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚ã€æ³•æ”¹æ­£å¯¾ç­–ã€ã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        elif success_results:
            st.info("ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã¾ã—ãŸãŒæ–°ã—ã„å•é¡Œã¯ç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            errors = [r for r in results if r.status == "error"]
            if errors:
                st.error("å¤–éƒ¨ãƒ•ã‚£ãƒ¼ãƒ‰ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    sync_history = db.load_law_revision_sync_logs(limit=10)
    if sync_history.empty:
        st.info("è‡ªå‹•å–å¾—å±¥æ­´ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚ä¸Šã®ãƒœã‚¿ãƒ³ã‹ã‚‰åŒæœŸã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")
    else:
        history_df = sync_history.copy()
        history_df["fetched_at"] = pd.to_datetime(history_df["fetched_at"]).dt.strftime("%Y-%m-%d %H:%M")
        st.dataframe(
            history_df[["fetched_at", "source", "status", "revisions_detected", "questions_generated", "message"]],
            use_container_width=True,
        )
    render_quick_import_controls(
        db,
        key_prefix="settings",
        heading="### ã‚¯ã‚¤ãƒƒã‚¯ã‚¤ãƒ³ãƒãƒ¼ãƒˆ (questions.csv / answers.csv)",
    )

    st.markdown("### äºˆæƒ³å•é¡Œã‚¤ãƒ³ãƒãƒ¼ãƒˆ (predicted.csv)")
    predicted_file = st.file_uploader(
        "predicted.csv ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=["csv"],
        key="predicted_file_uploader",
        help="äºˆæƒ³å•é¡Œãƒ‡ãƒ¼ã‚¿ã‚’CSVå½¢å¼ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚é¸æŠè‚¢ã‚„è§£èª¬ã‚’å«ã‚ãŸãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚",
    )
    if st.button("äºˆæƒ³å•é¡Œã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ", key="predicted_import_button"):
        if predicted_file is None:
            st.warning("predicted.csv ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        else:
            data = predicted_file.getvalue()
            try:
                predicted_df = pd.read_csv(io.BytesIO(data))
            except UnicodeDecodeError:
                predicted_df = pd.read_csv(io.BytesIO(data), encoding="cp932")
            errors = validate_predicted_records(predicted_df)
            if errors:
                for err in errors:
                    st.error(err)
                st.info("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®åˆ—æ§‹æˆã«åˆã‚ã›ã¦å†åº¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            else:
                try:
                    normalized_predicted = normalize_predicted_questions(predicted_df)
                except Exception as exc:
                    st.error(f"predicted.csv ã®æ•´å½¢ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")
                else:
                    inserted, updated = db.upsert_predicted_questions(normalized_predicted)
                    st.success(f"äºˆæƒ³å•é¡Œãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šè¾¼ã¿ã¾ã—ãŸã€‚è¿½åŠ  {inserted} ä»¶ / æ›´æ–° {updated} ä»¶")
                    st.session_state.pop("predicted_session", None)
                    if not normalized_predicted.empty:
                        st.dataframe(
                            normalized_predicted.head(10)[
                                [
                                    "label",
                                    "category",
                                    "topic",
                                    "source",
                                    "question",
                                    "correct",
                                ]
                            ],
                            use_container_width=True,
                        )
                        st.caption("å–ã‚Šè¾¼ã‚“ã äºˆæƒ³å•é¡Œã®å…ˆé ­10ä»¶ã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚")
    st.markdown("### æ³•æ”¹æ­£äºˆæƒ³å•é¡Œã‚¤ãƒ³ãƒãƒ¼ãƒˆ (law_revision.csv)")
    law_revision_file = st.file_uploader(
        "law_revision.csv ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=["csv"],
        key="law_revision_file_uploader",
        help="ã“ã“æ•°å¹´ã®æ³•æ”¹æ­£ã«é–¢ã™ã‚‹äºˆæƒ³å•é¡Œãƒ‡ãƒ¼ã‚¿ã‚’CSVã§èª­ã¿è¾¼ã¿ã¾ã™ã€‚æ”¹æ­£å¹´åº¦ã‚„æ–½è¡Œæ—¥ã‚‚ç™»éŒ²ã§ãã¾ã™ã€‚",
    )
    if st.button("æ³•æ”¹æ­£äºˆæƒ³å•é¡Œã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ", key="law_revision_import_button"):
        if law_revision_file is None:
            st.warning("law_revision.csv ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        else:
            data = law_revision_file.getvalue()
            try:
                law_revision_df = pd.read_csv(io.BytesIO(data))
            except UnicodeDecodeError:
                law_revision_df = pd.read_csv(io.BytesIO(data), encoding="cp932")
            errors = validate_law_revision_records(law_revision_df)
            if errors:
                for err in errors:
                    st.error(err)
                st.info("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®åˆ—æ§‹æˆã«åˆã‚ã›ã¦å†åº¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            else:
                try:
                    normalized_law_revision = normalize_law_revision_questions(law_revision_df)
                except Exception as exc:
                    st.error(f"law_revision.csv ã®æ•´å½¢ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")
                else:
                    inserted, updated = db.upsert_law_revision_questions(normalized_law_revision)
                    st.success(
                        f"æ³•æ”¹æ­£äºˆæƒ³å•é¡Œãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šè¾¼ã¿ã¾ã—ãŸã€‚è¿½åŠ  {inserted} ä»¶ / æ›´æ–° {updated} ä»¶"
                    )
                    st.session_state.pop("law_revision_session", None)
                    if not normalized_law_revision.empty:
                        preview_cols = [
                            "label",
                            "law_name",
                            "revision_year",
                            "effective_date",
                            "question",
                            "correct",
                        ]
                        st.dataframe(
                            normalized_law_revision.head(10)[preview_cols],
                            use_container_width=True,
                        )
                        st.caption("å–ã‚Šè¾¼ã‚“ã æ³•æ”¹æ­£äºˆæƒ³å•é¡Œã®å…ˆé ­10ä»¶ã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚")
    st.markdown("### ã‚¯ã‚¤ãƒƒã‚¯ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ (questions.csv / answers.csv)")
    existing_questions = load_questions_df()
    if existing_questions.empty:
        st.info("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå¯èƒ½ãªè¨­å•ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        question_cols = QUESTION_TEMPLATE_COLUMNS.copy()
        if "id" in existing_questions.columns and "id" not in question_cols:
            question_cols.append("id")
        q_export = existing_questions[question_cols]
        q_buffer = io.StringIO()
        q_export.to_csv(q_buffer, index=False)
        st.download_button(
            "questions.csv ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            q_buffer.getvalue(),
            file_name="questions.csv",
            mime="text/csv",
            key="export_questions_csv",
        )
        answers_export = build_answers_export(existing_questions)
        a_buffer = io.StringIO()
        answers_export.to_csv(a_buffer, index=False)
        st.download_button(
            "answers.csv ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            a_buffer.getvalue(),
            file_name="answers.csv",
            mime="text/csv",
            key="export_answers_csv",
        )
    st.markdown("### (1) ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ")
    uploaded_files = st.file_uploader(
        "è¨­å•ãƒ»è§£ç­”ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ (CSV/XLSX/ZIP)",
        type=["csv", "xlsx", "xls", "zip"],
        accept_multiple_files=True,
    )
    datasets = []
    file_summaries: List[Dict[str, object]] = []
    if uploaded_files:
        for file in uploaded_files:
            file_summary = {
                "file": file.name,
                "questions": 0,
                "answers": 0,
            }
            try:
                store_uploaded_file(file, timestamp)
                for name, df in decode_uploaded_file(file):
                    kind = guess_dataset_kind(df)
                    datasets.append({"name": name, "data": df, "kind": kind})
                    if kind == MAPPING_KIND_QUESTIONS:
                        file_summary["questions"] += len(df)
                    elif kind == MAPPING_KIND_ANSWERS:
                        file_summary["answers"] += len(df)
            except Exception as e:
                st.error(f"{file.name}: èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ ({e})")
            else:
                file_summaries.append(file_summary)
                st.caption(
                    f"{file_summary['file']}: è¨­å• {file_summary['questions']} ä»¶ / æ­£ç­” {file_summary['answers']} ä»¶"
                )
    if not datasets:
        st.info("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return

    st.markdown("### (2) ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ & ãƒãƒƒãƒ”ãƒ³ã‚°")
    mapping_profiles = db.fetch_mapping_profiles()
    profile_options = ["æ–°è¦ãƒãƒƒãƒ”ãƒ³ã‚°"] + (mapping_profiles["name"].tolist() if not mapping_profiles.empty else [])
    selected_profile = st.selectbox("ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ", profile_options)
    profile_mapping: Dict[str, Dict[str, str]] = {}
    if selected_profile != "æ–°è¦ãƒãƒƒãƒ”ãƒ³ã‚°" and not mapping_profiles.empty:
        profile_row = mapping_profiles[mapping_profiles["name"] == selected_profile].iloc[0]
        mapping_data = profile_row["mapping_json"]
        if isinstance(mapping_data, str):
            try:
                profile_mapping = json.loads(mapping_data)
            except json.JSONDecodeError:
                profile_mapping = {}
        else:
            profile_mapping = mapping_data

    normalized_question_frames = []
    normalized_answer_frames = []
    conflict_resolutions: List[Dict[str, object]] = []

    policy = {
        "explanation": st.selectbox("è§£èª¬ã®å–ã‚Šæ‰±ã„", ["overwrite", "append"], format_func=lambda x: "ä¸Šæ›¸ã" if x == "overwrite" else "è¿½è¨˜"),
        "tags": st.selectbox("ã‚¿ã‚°ã®å–ã‚Šæ‰±ã„", ["merge", "overwrite"], format_func=lambda x: "çµåˆ" if x == "merge" else "ä¸Šæ›¸ã"),
    }

    for dataset in datasets:
        df = dataset["data"]
        display_name, original_name = describe_dataset_name(dataset["name"])
        st.subheader(display_name)
        if original_name and original_name != display_name:
            st.caption(f"å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«/ã‚·ãƒ¼ãƒˆå: {original_name}")
        st.dataframe(df.head())
        kind = st.selectbox(
            f"ãƒ‡ãƒ¼ã‚¿ç¨®åˆ¥ ({display_name})",
            [MAPPING_KIND_QUESTIONS, MAPPING_KIND_ANSWERS],
            index=0 if dataset["kind"] == MAPPING_KIND_QUESTIONS else 1,
            format_func=lambda value: MAPPING_KIND_LABELS.get(value, value),
            help="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸè¡¨ãŒè¨­å•ãƒ‡ãƒ¼ã‚¿ã‹æ­£ç­”ãƒ‡ãƒ¼ã‚¿ã‹ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚",
        )
        dataset["kind"] = kind
        columns = df.columns.tolist()
        lower_map = {col.lower(): col for col in columns}
        if kind == MAPPING_KIND_QUESTIONS:
            mapping_targets = {
                "year": "å¹´åº¦",
                "q_no": "å•ç•ª",
                "category": "å¤§åˆ†é¡",
                "topic": "å°åˆ†é¡",
                "question": "å•é¡Œæ–‡",
                "choice1": "é¸æŠè‚¢1",
                "choice2": "é¸æŠè‚¢2",
                "choice3": "é¸æŠè‚¢3",
                "choice4": "é¸æŠè‚¢4",
                "explanation": "è§£èª¬",
                "difficulty": "é›£æ˜“åº¦",
                "tags": "ã‚¿ã‚°",
                "id": "ID",
            }
        else:
            mapping_targets = {
                "year": "å¹´åº¦",
                "q_no": "å•ç•ª",
                "correct_number": "æ­£ç­”ç•ªå·",
                "correct_label": "æ­£ç­”ãƒ©ãƒ™ãƒ«",
                "correct_text": "æ­£ç­”ãƒ†ã‚­ã‚¹ãƒˆ",
                "explanation": "è§£èª¬",
                "difficulty": "é›£æ˜“åº¦",
                "tags": "ã‚¿ã‚°",
            }
        saved_mapping = profile_mapping.get(dataset["name"], {}) if profile_mapping else {}
        mapping = {}
        for key, label in mapping_targets.items():
            default_idx = -1
            if saved_mapping and key in saved_mapping and saved_mapping[key] in columns:
                default_idx = columns.index(saved_mapping[key])
            elif key in lower_map:
                default_idx = columns.index(lower_map[key])
            selected_col = st.selectbox(
                f"{label}",
                ["æœªè¨­å®š"] + columns,
                index=default_idx + 1 if default_idx >= 0 else 0,
                key=f"map_{dataset['name']}_{key}",
            )
            if selected_col != "æœªè¨­å®š":
                mapping[key] = selected_col
        try:
            if kind == MAPPING_KIND_QUESTIONS:
                normalized = normalize_questions(df, mapping=mapping)
                normalized_question_frames.append(normalized)
            else:
                normalized = normalize_answers(df, mapping=mapping)
                normalized_answer_frames.append(normalized)
            dataset["mapping"] = mapping
        except Exception as e:
            st.error(f"ãƒãƒƒãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")

    if st.checkbox("ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä¿å­˜"):
        profile_name = st.text_input("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå")
        if profile_name and st.button("ä¿å­˜"):
            mapping_payload = {ds["name"]: ds.get("mapping", {}) for ds in datasets}
            db.save_mapping_profile(profile_name, "mixed", mapping_payload)
            st.success("ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ")

    if not normalized_question_frames:
        st.warning("è¨­å•ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    merged_questions = pd.concat(normalized_question_frames).drop_duplicates(subset=["id"])
    merged_answers = pd.concat(normalized_answer_frames) if normalized_answer_frames else pd.DataFrame()

    if not merged_answers.empty:
        merged, rejects_q, rejects_a, conflicts = merge_questions_answers(merged_questions, merged_answers, policy)
    else:
        merged = merged_questions
        rejects_q = pd.DataFrame()
        rejects_a = pd.DataFrame()
        conflicts = pd.DataFrame()

    if not conflicts.empty:
        st.error("æ­£ç­”æƒ…å ±ã®ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆãŒã‚ã‚Šã¾ã™ã€‚è§£æ±ºæ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        with st.form("conflict_resolution_form"):
            for _, conflict in conflicts.iterrows():
                st.write(f"{int(conflict['year'])}å¹´ å•{int(conflict['q_no'])}")
                action = st.selectbox(
                    f"å‡¦ç†æ–¹æ³• ({conflict['id']})",
                    ["æ—¢å­˜ã‚’ç¶­æŒ", "è§£ç­”ã§ä¸Šæ›¸ã", "æ‰‹å‹•ä¿®æ­£"],
                    key=f"conflict_action_{conflict['id']}",
                )
                manual_value = st.number_input(
                    f"æ‰‹å‹•æ­£ç­”ç•ªå· ({conflict['id']})",
                    min_value=1,
                    max_value=4,
                    value=int(conflict["existing"]) if pd.notna(conflict["existing"]) and int(conflict["existing"]) in [1, 2, 3, 4] else 1,
                    key=f"conflict_manual_{conflict['id']}",
                )
                conflict_resolutions.append(
                    {
                        "id": conflict["id"],
                        "action": action,
                        "manual": manual_value,
                        "incoming": conflict["incoming"],
                        "existing": conflict["existing"],
                    }
                )
            applied = st.form_submit_button("è§£æ±ºã‚’é©ç”¨")
        if not applied:
            st.stop()
        for resolution in conflict_resolutions:
            if resolution["action"] == "è§£ç­”ã§ä¸Šæ›¸ã":
                merged.loc[merged["id"] == resolution["id"], "correct"] = resolution["incoming"]
            elif resolution["action"] == "æ‰‹å‹•ä¿®æ­£":
                merged.loc[merged["id"] == resolution["id"], "correct"] = resolution["manual"]
        conflicts = pd.DataFrame()

    st.markdown("### (3) æ­£è¦åŒ– & ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çµæœ")
    st.success(f"è¨­å•{len(merged)}ä»¶ã‚’å–ã‚Šè¾¼ã¿ã¾ã™ã€‚")
    if not rejects_a.empty:
        buffer = io.StringIO()
        rejects_a.to_csv(buffer, index=False)
        st.download_button("rejects_answers.csv ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", buffer.getvalue(), file_name="rejects_answers.csv", mime="text/csv")
    if not rejects_q.empty:
        buffer = io.StringIO()
        rejects_q.to_csv(buffer, index=False)
        st.download_button("rejects_questions.csv ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", buffer.getvalue(), file_name="rejects_questions.csv", mime="text/csv")

    if st.button("(4) çµ±åˆ (UPSERT) å®Ÿè¡Œ"):
        started = dt.datetime.now()
        progress = st.progress(0.0)

        def handle_progress(processed: int, total: int) -> None:
            if total <= 0:
                ratio = 1.0
            else:
                ratio = processed / total
            progress.progress(min(max(ratio, 0.0), 1.0))

        inserted, updated = db.bulk_upsert_questions(
            merged, batch_size=200, on_progress=handle_progress
        )
        finished = dt.datetime.now()
        seconds = (finished - started).total_seconds()
        policy_payload = {**policy, "conflict_resolutions": conflict_resolutions}
        db.log_import(
            {
                "started_at": started,
                "finished_at": finished,
                "files": len(uploaded_files),
                "inserted": inserted,
                "updated": updated,
                "rejected": len(rejects_a) + len(rejects_q),
                "conflicts": len(conflicts),
                "seconds": seconds,
                "policy": json.dumps(policy_payload, ensure_ascii=False),
            }
        )
        rebuild_tfidf_cache()
        progress.progress(1.0)
        rejected_total = len(rejects_a) + len(rejects_q)
        st.success(
            "ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚"
            f" è¿½åŠ  {inserted} ä»¶ / æ›´æ–° {updated} ä»¶ / ãƒªã‚¸ã‚§ã‚¯ãƒˆ {rejected_total} ä»¶ã€‚"
            " TF-IDFã‚’å†æ§‹ç¯‰ã—ã¾ã—ãŸã€‚"
        )
        notification = {
            "timestamp": finished.strftime("%Y-%m-%d %H:%M:%S"),
            "inserted": inserted,
            "updated": updated,
            "rejected": rejected_total,
            "seconds": round(seconds, 2),
        }
        import_notifications.insert(0, notification)
        if len(import_notifications) > 20:
            del import_notifications[20:]
        st.toast(
            f"è¨­å•ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†: è¿½åŠ  {inserted} ä»¶ / æ›´æ–° {updated} ä»¶ / ãƒªã‚¸ã‚§ã‚¯ãƒˆ {rejected_total} ä»¶",
            icon="âœ…",
        )
        if file_summaries:
            summary_rows = [
                {
                    "åŒºåˆ†": "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
                    "ãƒ•ã‚¡ã‚¤ãƒ«": summary["file"],
                    "è¨­å•è¡Œæ•°": summary["questions"],
                    "æ­£ç­”è¡Œæ•°": summary["answers"],
                    "è¿½åŠ ": "",
                    "æ›´æ–°": "",
                    "ãƒªã‚¸ã‚§ã‚¯ãƒˆ": "",
                }
                for summary in file_summaries
            ]
        else:
            summary_rows = []
        summary_rows.append(
            {
                "åŒºåˆ†": "DBåæ˜ ",
                "ãƒ•ã‚¡ã‚¤ãƒ«": "çµæœ",
                "è¨­å•è¡Œæ•°": "",
                "æ­£ç­”è¡Œæ•°": "",
                "è¿½åŠ ": inserted,
                "æ›´æ–°": updated,
                "ãƒªã‚¸ã‚§ã‚¯ãƒˆ": rejected_total,
            }
        )
        st.table(pd.DataFrame(summary_rows))

    render_history_export_controls(
        db,
        heading="### (5) å±¥æ­´ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ",
    )

    st.markdown("### (6) ãƒ‡ãƒ¼ã‚¿æ¶ˆå»")
    with st.form("data_reset_form"):
        reset_attempts = st.checkbox("å­¦ç¿’å±¥æ­´ (attempts) ã‚’å‰Šé™¤")
        reset_exams = st.checkbox("æ¨¡è©¦çµæœ (exams) ã‚’å‰Šé™¤")
        reset_all = st.checkbox("å…¨ãƒ‡ãƒ¼ã‚¿ã‚’åˆæœŸåŒ– (è¨­å•å«ã‚€)")
        confirmed = st.form_submit_button("å‰Šé™¤ã‚’å®Ÿè¡Œ")
    if confirmed:
        with db.engine.begin() as conn:
            if reset_all:
                for table in [attempts_table, exams_table, srs_table, questions_table]:
                    conn.execute(table.delete())
            else:
                if reset_attempts:
                    conn.execute(attempts_table.delete())
                if reset_exams:
                    conn.execute(exams_table.delete())
        rebuild_tfidf_cache()
        st.success("é¸æŠã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")

    st.markdown("### (7) ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    with open(DATA_DIR / "questions_sample.csv", "rb") as f:
        st.download_button("è¨­å•ãƒ†ãƒ³ãƒ—ãƒ¬CSV", f, file_name="questions_template.csv")
    with open(DATA_DIR / "answers_sample.csv", "rb") as f:
        st.download_button("è§£ç­”ãƒ†ãƒ³ãƒ—ãƒ¬CSV", f, file_name="answers_template.csv")


def render_settings(db: DBManager) -> None:
    st.title("è¨­å®š")
    tabs = st.tabs(["è¡¨ç¤ºãƒ»æ“ä½œè¨­å®š", "ãƒ‡ãƒ¼ã‚¿å…¥å‡ºåŠ›"])
    with tabs[0]:
        settings = st.session_state["settings"]
        st.info("å­¦ç¿’ä½“é¨“ã‚’è‡ªåˆ†å¥½ã¿ã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã¾ã™ã€‚å„é …ç›®ã®èª¬æ˜ã‚’å‚è€ƒã«èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
        theme_options = ["ãƒ©ã‚¤ãƒˆ", "ãƒ€ãƒ¼ã‚¯", "ã‚»ãƒ”ã‚¢"]
        current_theme = settings.get("theme", "ã‚»ãƒ”ã‚¢")
        theme_index = theme_options.index(current_theme) if current_theme in theme_options else 0
        settings["theme"] = st.selectbox(
            "ãƒ†ãƒ¼ãƒ",
            theme_options,
            index=theme_index,
            help="ç”»é¢ã®é…è‰²ã‚’åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚æš—ã„ç’°å¢ƒã§ã¯ãƒ€ãƒ¼ã‚¯ãƒ†ãƒ¼ãƒã€é•·æ–‡èª­è§£ã«ã¯ã‚»ãƒ”ã‚¢ãƒ†ãƒ¼ãƒãŒãŠã™ã™ã‚ã§ã™ã€‚",
        )
        size_options = list(FONT_SIZE_SCALE.keys())
        default_size = settings.get("font_size", "æ¨™æº–")
        size_index = (
            size_options.index(default_size)
            if default_size in size_options
            else size_options.index("æ¨™æº–")
        )
        settings["font_size"] = st.selectbox(
            "ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚º",
            size_options,
            index=size_index,
            help="æ–‡å­—ã‚µã‚¤ã‚ºã‚’èª¿æ•´ã—ã¦èª­ã¿ã‚„ã™ã•ã‚’æœ€é©åŒ–ã—ã¾ã™ã€‚ã€å¤§ãã„ã€ã¯å¤œé–“å­¦ç¿’ã‚„é«˜è§£åƒåº¦ãƒ¢ãƒ‹ã‚¿å‘ãã§ã™ã€‚",
        )
        settings["shuffle_choices"] = st.checkbox(
            "é¸æŠè‚¢ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«",
            value=settings.get("shuffle_choices", True),
            help="æ¯å›é¸æŠè‚¢ã®é †ç•ªã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å…¥ã‚Œæ›¿ãˆã¦ã€ä½ç½®è¨˜æ†¶ã«é ¼ã‚‰ãªã„è¨“ç·´ã‚’è¡Œã„ã¾ã™ã€‚",
        )
        settings["timer"] = st.checkbox(
            "ã‚¿ã‚¤ãƒãƒ¼ã‚’è¡¨ç¤º",
            value=settings.get("timer", True),
            help="å›ç­”ç”»é¢ã«çµŒéæ™‚é–“ã‚’è¡¨ç¤ºã—ã¦æœ¬ç•ªåŒæ§˜ã®æ™‚é–“æ„Ÿè¦šã‚’é¤Šã„ã¾ã™ã€‚",
        )
        sm2_key = "settings_sm2_initial_ease"
        current_sm2 = settings.get("sm2_initial_ease", 2.5)
        if st.session_state.get(sm2_key) != current_sm2:
            st.session_state[sm2_key] = current_sm2
        settings["sm2_initial_ease"] = st.slider(
            "SM-2åˆæœŸease",
            min_value=1.3,
            max_value=3.0,
            value=st.session_state[sm2_key],
            help="é–“éš”åå¾©ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®åˆæœŸé›£æ˜“åº¦ã§ã™ã€‚æ—¢å®šå€¤2.5ã§è¿·ã£ãŸã‚‰ãã®ã¾ã¾ã«ã—ã¾ã—ã‚‡ã†ã€‚",
            key=sm2_key,
        )
        settings["auto_advance"] = st.checkbox(
            "æ¡ç‚¹å¾Œã«è‡ªå‹•ã§æ¬¡å•ã¸é€²ã‚€ (0.8ç§’é…å»¶)",
            value=settings.get("auto_advance", False),
            help="æ­£èª¤åˆ¤å®šå¾Œã«å¾…æ©Ÿã›ãšæ¬¡ã®å•é¡Œã¸é€²ã¿ãŸã„å ´åˆã«æœ‰åŠ¹åŒ–ã—ã¾ã™ã€‚",
        )
        low_conf_key = "settings_review_low_confidence_threshold"
        current_low_conf = int(settings.get("review_low_confidence_threshold", 60))
        if st.session_state.get(low_conf_key) != current_low_conf:
            st.session_state[low_conf_key] = current_low_conf
        settings["review_low_confidence_threshold"] = st.slider(
            "ä½ç¢ºä¿¡ã¨ã—ã¦æ‰±ã†ç¢ºä¿¡åº¦ (%)",
            min_value=0,
            max_value=100,
            value=st.session_state[low_conf_key],
            help="è‡ªå·±è©•ä¾¡ã®ç¢ºä¿¡åº¦ãŒã“ã®å€¤æœªæº€ãªã‚‰å¾©ç¿’å¯¾è±¡ã«å«ã‚ã¾ã™ã€‚",
            key=low_conf_key,
        )
        elapsed_key = "settings_review_elapsed_days"
        current_elapsed = int(settings.get("review_elapsed_days", 7))
        if st.session_state.get(elapsed_key) != current_elapsed:
            st.session_state[elapsed_key] = current_elapsed
        settings["review_elapsed_days"] = st.slider(
            "å¾©ç¿’æŠ½å‡ºã®çµŒéæ—¥æ•°ã—ãã„å€¤",
            min_value=1,
            max_value=30,
            value=st.session_state[elapsed_key],
            help="æœ€çµ‚æŒ‘æˆ¦ã‹ã‚‰ã“ã®æ—¥æ•°ãŒçµŒéã—ãŸå•é¡Œã‚’å¾©ç¿’å€™è£œã«è¿½åŠ ã—ã¾ã™ã€‚",
            key=elapsed_key,
        )
        integrations = settings.setdefault("integrations", {})
        st.markdown("#### å¤–éƒ¨ã‚µãƒ¼ãƒ“ã‚¹é€£æºè¨­å®š")
        st.caption("Google Calendar ã‚„ Notion é€£æºã«å¿…è¦ãªOAuthæƒ…å ±ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚å€¤ã¯ãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã§ä¿æŒã•ã‚Œã¾ã™ã€‚")
        with st.expander("Google Calendar é€£æº"):
            google_config = integrations.setdefault(
                "google_calendar",
                {
                    "client_id": "",
                    "client_secret": "",
                    "redirect_uri": "",
                    "access_token": "",
                    "refresh_token": "",
                    "calendar_id": "primary",
                },
            )
            google_config["client_id"] = st.text_input("Client ID", value=google_config.get("client_id", ""))
            google_config["client_secret"] = st.text_input(
                "Client Secret",
                value=google_config.get("client_secret", ""),
                type="password",
            )
            google_config["redirect_uri"] = st.text_input(
                "Redirect URI",
                value=google_config.get("redirect_uri", ""),
                help="OAuthåŒæ„ç”»é¢ã§è¨­å®šã—ãŸãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆURLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
            )
            google_config["access_token"] = st.text_input(
                "Access Token",
                value=google_config.get("access_token", ""),
                type="password",
                help="æœ‰åŠ¹ãªã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å…¥åŠ›ã™ã‚‹ã¨å³æ™‚åŒæœŸã§ãã¾ã™ã€‚",
            )
            google_config["refresh_token"] = st.text_input(
                "Refresh Token",
                value=google_config.get("refresh_token", ""),
                type="password",
            )
            google_config["calendar_id"] = st.text_input(
                "å¯¾è±¡ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ID",
                value=google_config.get("calendar_id", "primary"),
                help="primary ã®ã¾ã¾ã«ã™ã‚‹ã¨ãƒ¡ã‚¤ãƒ³ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã¸æ›¸ãè¾¼ã¿ã¾ã™ã€‚",
            )
        with st.expander("Notion é€£æº"):
            notion_config = integrations.setdefault(
                "notion",
                {
                    "integration_token": "",
                    "database_id": "",
                    "notion_version": "2022-06-28",
                },
            )
            notion_config["integration_token"] = st.text_input(
                "Integration Token",
                value=notion_config.get("integration_token", ""),
                type="password",
            )
            notion_config["database_id"] = st.text_input(
                "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ID",
                value=notion_config.get("database_id", ""),
            )
            notion_config["notion_version"] = st.text_input(
                "Notion-Version",
                value=notion_config.get("notion_version", "2022-06-28"),
                help="Notion APIã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ–‡å­—åˆ—ã‚’å¿…è¦ã«å¿œã˜ã¦å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚",
            )
        if st.button(
            "TF-IDFã‚’å†å­¦ç¿’",
            help="æ¤œç´¢ç²¾åº¦ãŒæ°—ã«ãªã‚‹ã¨ãã«å†è¨ˆç®—ã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿æ›´æ–°å¾Œã®å†å®Ÿè¡ŒãŒãŠã™ã™ã‚ã§ã™ã€‚",
        ):
            rebuild_tfidf_cache()
            st.success("TF-IDFã‚’å†å­¦ç¿’ã—ã¾ã—ãŸ")
    with tabs[1]:
        render_data_io(db, parent_nav="è¨­å®š")


if __name__ == "__main__":
    main()
